{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyMVb4a4kosKcGbR5oammdOt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bZuKdmoXSTfr","executionInfo":{"status":"ok","timestamp":1746613729586,"user_tz":-180,"elapsed":24098,"user":{"displayName":"Mustafa Said KARTAL","userId":"14049951240735760192"}},"outputId":"0319d822-c654-4cc1-be1f-91bbaa93e7e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install monai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NECv8z0djRLv","executionInfo":{"status":"ok","timestamp":1746618114994,"user_tz":-180,"elapsed":7170,"user":{"displayName":"Mustafa Said KARTAL","userId":"14049951240735760192"}},"outputId":"4e0e0d01-11ff-45c7-fd7f-e266e7b4b5bb"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting monai\n","  Downloading monai-1.4.0-py3-none-any.whl.metadata (11 kB)\n","Collecting numpy<2.0,>=1.24 (from monai)\n","  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.9 in /usr/local/lib/python3.11/dist-packages (from monai) (2.6.0+cu124)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (4.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9->monai) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9->monai) (3.0.2)\n","Downloading monai-1.4.0-py3-none-any.whl (1.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m111.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy, monai\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.0.2\n","    Uninstalling numpy-2.0.2:\n","      Successfully uninstalled numpy-2.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed monai-1.4.0 numpy-1.26.4\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Liver Vessel/nnunet\n","#!git clone https://github.com/MIC-DKFZ/nnUNet.git\n","%cd nnUNet\n","!pip install SimpleITK\n","!pip install monai\n","!pip install -e ."],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"gpXVX4xQSgD0","executionInfo":{"status":"ok","timestamp":1746613857499,"user_tz":-180,"elapsed":127901,"user":{"displayName":"Mustafa Said KARTAL","userId":"14049951240735760192"}},"outputId":"268751a6-9cb1-46e5-bb82-07646d696f7a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Liver Vessel/nnunet\n","/content/drive/MyDrive/Liver Vessel/nnunet/nnUNet\n","Collecting SimpleITK\n","  Downloading simpleitk-2.5.0-cp311-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n","Downloading simpleitk-2.5.0-cp311-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: SimpleITK\n","Successfully installed SimpleITK-2.5.0\n","Obtaining file:///content/drive/MyDrive/Liver%20Vessel/nnunet/nnUNet\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n","  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.0) (2.6.0+cu124)\n","Collecting acvl-utils<0.3,>=0.2.3 (from nnunetv2==2.6.0)\n","  Downloading acvl_utils-0.2.5.tar.gz (29 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting dynamic-network-architectures<0.4,>=0.3.1 (from nnunetv2==2.6.0)\n","  Downloading dynamic_network_architectures-0.3.1.tar.gz (20 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.0) (4.67.1)\n","Collecting dicom2nifti (from nnunetv2==2.6.0)\n","  Downloading dicom2nifti-2.6.1-py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.0) (1.15.2)\n","Collecting batchgenerators>=0.25.1 (from nnunetv2==2.6.0)\n","  Downloading batchgenerators-0.25.1.tar.gz (76 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.0) (2.0.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.0) (1.6.1)\n","Requirement already satisfied: scikit-image>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.0) (0.25.2)\n","Requirement already satisfied: SimpleITK>=2.2.1 in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.0) (2.5.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.0) (2.2.2)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.0) (0.20.3)\n","Requirement already satisfied: tifffile in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.0) (2025.3.30)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.0) (2.32.3)\n","Requirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.0) (5.3.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.0) (3.10.0)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.0) (0.13.2)\n","Collecting imagecodecs (from nnunetv2==2.6.0)\n","  Downloading imagecodecs-2025.3.30-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n","Collecting yacs (from nnunetv2==2.6.0)\n","  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n","Collecting batchgeneratorsv2>=0.2 (from nnunetv2==2.6.0)\n","  Downloading batchgeneratorsv2-0.2.3.tar.gz (35 kB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.0) (0.8.1)\n","Requirement already satisfied: blosc2>=3.0.0b1 in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.0) (3.3.2)\n","Collecting connected-components-3d (from acvl-utils<0.3,>=0.2.3->nnunetv2==2.6.0)\n","  Downloading connected_components_3d-3.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (32 kB)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25.1->nnunetv2==2.6.0) (11.2.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25.1->nnunetv2==2.6.0) (1.0.0)\n","Collecting unittest2 (from batchgenerators>=0.25.1->nnunetv2==2.6.0)\n","  Downloading unittest2-1.1.0-py2.py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25.1->nnunetv2==2.6.0) (3.6.0)\n","Collecting fft-conv-pytorch (from batchgeneratorsv2>=0.2->nnunetv2==2.6.0)\n","  Downloading fft_conv_pytorch-1.2.0-py3-none-any.whl.metadata (2.8 kB)\n","Requirement already satisfied: ndindex in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2==2.6.0) (1.9.2)\n","Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2==2.6.0) (1.1.0)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2==2.6.0) (4.3.7)\n","Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2==2.6.0) (2.10.2)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2==2.6.0) (9.0.0)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.6.0) (3.4.2)\n","Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.6.0) (2.37.0)\n","Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.6.0) (24.2)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.6.0) (0.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.0) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.0) (4.13.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.0) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.0) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.1.2->nnunetv2==2.6.0)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.1.2->nnunetv2==2.6.0)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.1.2->nnunetv2==2.6.0)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.1.2->nnunetv2==2.6.0)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.1.2->nnunetv2==2.6.0)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.1.2->nnunetv2==2.6.0)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.1.2->nnunetv2==2.6.0)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.1.2->nnunetv2==2.6.0)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.1.2->nnunetv2==2.6.0)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.0) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.0) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.0) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.1.2->nnunetv2==2.6.0)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.0) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.0) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.2->nnunetv2==2.6.0) (1.3.0)\n","Collecting pydicom>=3.0.0 (from dicom2nifti->nnunetv2==2.6.0)\n","  Downloading pydicom-3.0.1-py3-none-any.whl.metadata (9.4 kB)\n","Collecting python-gdcm (from dicom2nifti->nnunetv2==2.6.0)\n","  Downloading python_gdcm-3.0.24.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2==2.6.0) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2==2.6.0) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2==2.6.0) (4.57.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2==2.6.0) (1.4.8)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2==2.6.0) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2==2.6.0) (2.9.0.post0)\n","Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel->nnunetv2==2.6.0) (6.5.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->nnunetv2==2.6.0) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->nnunetv2==2.6.0) (2025.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2==2.6.0) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2==2.6.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2==2.6.0) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2==2.6.0) (2025.4.26)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->nnunetv2==2.6.0) (1.4.2)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from yacs->nnunetv2==2.6.0) (6.0.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->nnunetv2==2.6.0) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.2->nnunetv2==2.6.0) (3.0.2)\n","Collecting argparse (from unittest2->batchgenerators>=0.25.1->nnunetv2==2.6.0)\n","  Downloading argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n","Collecting traceback2 (from unittest2->batchgenerators>=0.25.1->nnunetv2==2.6.0)\n","  Downloading traceback2-1.4.0-py2.py3-none-any.whl.metadata (1.5 kB)\n","Collecting linecache2 (from traceback2->unittest2->batchgenerators>=0.25.1->nnunetv2==2.6.0)\n","  Downloading linecache2-1.0.0-py2.py3-none-any.whl.metadata (1000 bytes)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m127.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m98.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m115.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dicom2nifti-2.6.1-py3-none-any.whl (43 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading imagecodecs-2025.3.30-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (45.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Downloading pydicom-3.0.1-py3-none-any.whl (2.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading connected_components_3d-3.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m105.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fft_conv_pytorch-1.2.0-py3-none-any.whl (6.8 kB)\n","Downloading python_gdcm-3.0.24.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m119.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading unittest2-1.1.0-py2.py3-none-any.whl (96 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n","Downloading traceback2-1.4.0-py2.py3-none-any.whl (16 kB)\n","Downloading linecache2-1.0.0-py2.py3-none-any.whl (12 kB)\n","Building wheels for collected packages: nnunetv2, acvl-utils, batchgenerators, batchgeneratorsv2, dynamic-network-architectures\n","  Building editable for nnunetv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nnunetv2: filename=nnunetv2-2.6.0-0.editable-py3-none-any.whl size=16745 sha256=03dac8aed7965a56b847909b21c15d69b3c31589175a069227b46b9d7f1ef9e8\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-zd_lp8_c/wheels/e5/8a/2c/5f4a216ac88d4e4f2aa756e3186e48f930fa68b0f709996b07\n","  Building wheel for acvl-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for acvl-utils: filename=acvl_utils-0.2.5-py3-none-any.whl size=27213 sha256=f8c27efaa2d3f4a3ec0e1e9b9f9fcdeab6c091c9c89c051a1eb43549191bc7ac\n","  Stored in directory: /root/.cache/pip/wheels/3f/8c/10/dcba79e0b2d1d463605233cec1fc6cfad47af5230b8985e464\n","  Building wheel for batchgenerators (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for batchgenerators: filename=batchgenerators-0.25.1-py3-none-any.whl size=93088 sha256=06f72ca260e7eaecb5b78bed9b0d92c015c5ae162643daba3304112ca49a2803\n","  Stored in directory: /root/.cache/pip/wheels/56/11/c7/fadca30e054c602093ffe36ba8a2f0a87dd2f86ac75191d3ed\n","  Building wheel for batchgeneratorsv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for batchgeneratorsv2: filename=batchgeneratorsv2-0.2.3-py3-none-any.whl size=47566 sha256=3642c569efcc031eda7416a74f35d93fe9956545fe7607ed2e1a38e468d9ac96\n","  Stored in directory: /root/.cache/pip/wheels/1f/68/57/3a0eceb67b9c1b630df16113639b66a843dfd6686a4ed5ae1d\n","  Building wheel for dynamic-network-architectures (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dynamic-network-architectures: filename=dynamic_network_architectures-0.3.1-py3-none-any.whl size=30048 sha256=b609543ff792e5b806fe9d2bc40aa43288e57299a1e7b1de88c0030caffc0de6\n","  Stored in directory: /root/.cache/pip/wheels/d9/8f/23/133ba252665b6f93abdbb294b323cc8fec041be83e4d22b701\n","Successfully built nnunetv2 acvl-utils batchgenerators batchgeneratorsv2 dynamic-network-architectures\n","Installing collected packages: linecache2, argparse, yacs, traceback2, python-gdcm, pydicom, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, imagecodecs, connected-components-3d, unittest2, nvidia-cusparse-cu12, nvidia-cudnn-cu12, dicom2nifti, nvidia-cusolver-cu12, batchgenerators, fft-conv-pytorch, dynamic-network-architectures, acvl-utils, batchgeneratorsv2, nnunetv2\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed acvl-utils-0.2.5 argparse-1.4.0 batchgenerators-0.25.1 batchgeneratorsv2-0.2.3 connected-components-3d-3.23.0 dicom2nifti-2.6.1 dynamic-network-architectures-0.3.1 fft-conv-pytorch-1.2.0 imagecodecs-2025.3.30 linecache2-1.0.0 nnunetv2-2.6.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pydicom-3.0.1 python-gdcm-3.0.24.1 traceback2-1.4.0 unittest2-1.1.0 yacs-0.1.8\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["argparse"]},"id":"9350a5edaeff43bbba57428eefd1b63e"}},"metadata":{}}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Liver Vessel/nnunet"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nS4Qj7XKSmxJ","executionInfo":{"status":"ok","timestamp":1746613937265,"user_tz":-180,"elapsed":22,"user":{"displayName":"Mustafa Said KARTAL","userId":"14049951240735760192"}},"outputId":"b75ae209-5b8c-49c7-b27e-da305973b077"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Liver Vessel/nnunet\n"]}]},{"cell_type":"code","source":["import SimpleITK as sitk\n","import os\n","import numpy as np\n","\n","image_path = 'data/nnUNet_raw/Dataset002_hepaticvessel/imagesTr'\n","label_path = 'data/nnUNet_raw/Dataset002_hepaticvessel/labelsTr'\n","\n","images_list = sorted(os.listdir(os.path.join(image_path)))\n","print(\"Total case:\" ,len(images_list))\n","\n","from tqdm import tqdm\n","\n","for path in tqdm(images_list):\n","  img = sitk.ReadImage(os.path.join(image_path, path))\n","  lbl = sitk.ReadImage(os.path.join(label_path, path.replace('_0000.nii.gz', '.nii.gz')))\n","  if img.GetDirection() != lbl.GetDirection():\n","    print(f\"Direction mismatch for {path}\")\n","    print(f\"Image direction: {img.GetDirection()}\")\n","    print(f\"Label direction: {lbl.GetDirection()}\\n\")\n","    os.remove(os.path.join(image_path, path))\n","    os.remove(os.path.join(label_path, path.replace('_0000.nii.gz', '.nii.gz')))\n","    print(f\"Removed {path} and its corresponding label\\n\")\n","  if img.GetSize() != lbl.GetSize():\n","    print(f\"Size mismatch for {path}\")\n","    print(f\"Image size: {img.GetSize()}\")\n","    print(f\"Label size: {lbl.GetSize()}\\n\")\n","    os.remove(os.path.join(image_path, path))\n","    os.remove(os.path.join(label_path, path.replace('_0000.nii.gz', '.nii.gz')))\n","    print(f\"Removed {path} and its corresponding label\\n\")\n","  if img.GetSpacing() != lbl.GetSpacing():\n","    print(f\"Spacing mismatch for {path}\")\n","    print(f\"Image spacing: {img.GetSpacing()}\")\n","    print(f\"Label spacing: {lbl.GetSpacing()}\\n\")\n","    os.remove(os.path.join(image_path, path))\n","    os.remove(os.path.join(label_path, path.replace('_0000.nii.gz', '.nii.gz')))\n","    print(f\"Removed {path} and its corresponding label\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GhHumsg6SqX7","executionInfo":{"status":"ok","timestamp":1746615468118,"user_tz":-180,"elapsed":202934,"user":{"displayName":"Mustafa Said KARTAL","userId":"14049951240735760192"}},"outputId":"9ac6e9ad-0543-418f-fd95-85756bdfe02f"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Total case: 322\n"]},{"output_type":"stream","name":"stderr","text":[" 52%|█████▏    | 168/322 [01:28<02:05,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Spacing mismatch for hepaticvessel_00240_0000.nii.gz\n","Image spacing: (0.796875, 0.796875, 0.8000029921531677)\n","Label spacing: (0.796875, 0.796875, 0.800002932548523)\n","\n","Removed hepaticvessel_00240_0000.nii.gz and its corresponding label\n","\n"]},{"output_type":"stream","name":"stderr","text":[" 96%|█████████▋| 310/322 [03:13<00:05,  2.14it/s]"]},{"output_type":"stream","name":"stdout","text":["Spacing mismatch for hepaticvessel_00474_0000.nii.gz\n","Image spacing: (0.791015625, 0.791015625, 2.0)\n","Label spacing: (1.0, 1.0, 1.0)\n","\n","Removed hepaticvessel_00474_0000.nii.gz and its corresponding label\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 97%|█████████▋| 311/322 [03:14<00:05,  2.11it/s]"]},{"output_type":"stream","name":"stdout","text":["Spacing mismatch for hepaticvessel_00476_0000.nii.gz\n","Image spacing: (0.68359375, 0.68359375, 1.600000023841858)\n","Label spacing: (1.0, 1.0, 1.0)\n","\n","Removed hepaticvessel_00476_0000.nii.gz and its corresponding label\n","\n"]},{"output_type":"stream","name":"stderr","text":[" 98%|█████████▊| 315/322 [03:16<00:05,  1.38it/s]"]},{"output_type":"stream","name":"stdout","text":["Spacing mismatch for hepaticvessel_00481_0000.nii.gz\n","Image spacing: (0.658203125, 0.658203125, 1.0)\n","Label spacing: (1.0, 1.0, 1.0)\n","\n","Removed hepaticvessel_00481_0000.nii.gz and its corresponding label\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 322/322 [03:22<00:00,  1.59it/s]\n"]}]},{"cell_type":"code","source":["len(os.listdir('data/nnUNet_raw/Dataset002_hepaticvessel/imagesTr')), len(os.listdir('data/nnUNet_raw/Dataset002_hepaticvessel/labelsTr'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JSUVlVYTSqVh","executionInfo":{"status":"ok","timestamp":1746615526584,"user_tz":-180,"elapsed":25,"user":{"displayName":"Mustafa Said KARTAL","userId":"14049951240735760192"}},"outputId":"12820659-d9c8-4aef-9a17-d77033bc364d"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(318, 318)"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["import os\n","\n","os.environ['nnUNet_raw'] = 'data/nnUNet_raw'\n","os.environ['nnUNet_preprocessed'] = 'data/nnUNet_preprocessed'\n","os.environ['nnUNet_results'] = 'data/nnUNet_results'"],"metadata":{"id":"xO8cQDofSqTb","executionInfo":{"status":"ok","timestamp":1746615538513,"user_tz":-180,"elapsed":17,"user":{"displayName":"Mustafa Said KARTAL","userId":"14049951240735760192"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["!nnUNetv2_plan_and_preprocess -d 2 --verify_dataset_integrity -c 3d_fullres"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lYq90MXVT-aZ","executionInfo":{"status":"ok","timestamp":1746617977516,"user_tz":-180,"elapsed":2437825,"user":{"displayName":"Mustafa Said KARTAL","userId":"14049951240735760192"}},"outputId":"b14a54fa-c702-4a5b-fa59-f95315200e7b"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Fingerprint extraction...\n","Dataset002_hepaticvessel\n","Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer\n","\n","####################\n","verify_dataset_integrity Done. \n","If you didn't see any error messages then your dataset is most likely OK!\n","####################\n","\n","Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer\n","100% 318/318 [01:10<00:00,  4.49it/s]\n","Experiment planning...\n","\n","############################\n","INFO: You are using the old nnU-Net default planner. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n","############################\n","\n","Attempting to find 3d_lowres config. \n","Current spacing: [1.545      0.81677402 0.81677402]. \n","Current patch size: (np.int64(64), np.int64(192), np.int64(192)). \n","Current median shape: [145.63106796 497.08737864 497.08737864]\n","Attempting to find 3d_lowres config. \n","Current spacing: [1.59135    0.84127724 0.84127724]. \n","Current patch size: (np.int64(64), np.int64(192), np.int64(192)). \n","Current median shape: [141.38938637 482.60910548 482.60910548]\n","Attempting to find 3d_lowres config. \n","Current spacing: [1.6390905  0.86651556 0.86651556]. \n","Current patch size: (np.int64(64), np.int64(192), np.int64(192)). \n","Current median shape: [137.2712489  468.55252959 468.55252959]\n","Attempting to find 3d_lowres config. \n","Current spacing: [1.68826322 0.89251102 0.89251102]. \n","Current patch size: (np.int64(64), np.int64(192), np.int64(192)). \n","Current median shape: [133.27305719 454.90536853 454.90536853]\n","Attempting to find 3d_lowres config. \n","Current spacing: [1.73891111 0.91928636 0.91928636]. \n","Current patch size: (np.int64(64), np.int64(192), np.int64(192)). \n","Current median shape: [129.39131766 441.6556976  441.6556976 ]\n","Attempting to find 3d_lowres config. \n","Current spacing: [1.79107844 0.94686495 0.94686495]. \n","Current patch size: (np.int64(64), np.int64(192), np.int64(192)). \n","Current median shape: [125.6226385  428.79193942 428.79193942]\n","Attempting to find 3d_lowres config. \n","Current spacing: [1.8448108  0.97527089 0.97527089]. \n","Current patch size: (np.int64(64), np.int64(192), np.int64(192)). \n","Current median shape: [121.9637267  416.30285381 416.30285381]\n","Attempting to find 3d_lowres config. \n","Current spacing: [1.90015512 1.00452902 1.00452902]. \n","Current patch size: (np.int64(64), np.int64(192), np.int64(192)). \n","Current median shape: [118.41138515 404.17752797 404.17752797]\n","Attempting to find 3d_lowres config. \n","Current spacing: [1.95715978 1.03466489 1.03466489]. \n","Current patch size: (np.int64(64), np.int64(192), np.int64(192)). \n","Current median shape: [114.96250985 392.40536696 392.40536696]\n","Attempting to find 3d_lowres config. \n","Current spacing: [2.01587457 1.06570484 1.06570484]. \n","Current patch size: (np.int64(64), np.int64(192), np.int64(192)). \n","Current median shape: [111.61408723 380.97608443 380.97608443]\n","Attempting to find 3d_lowres config. \n","Current spacing: [2.07635081 1.09767598 1.09767598]. \n","Current patch size: (np.int64(64), np.int64(192), np.int64(192)). \n","Current median shape: [108.36319149 369.87969362 369.87969362]\n","Attempting to find 3d_lowres config. \n","Current spacing: [2.13864133 1.13060626 1.13060626]. \n","Current patch size: (np.int64(64), np.int64(192), np.int64(192)). \n","Current median shape: [105.20698203 359.10649866 359.10649866]\n","Attempting to find 3d_lowres config. \n","Current spacing: [2.20280057 1.16452445 1.16452445]. \n","Current patch size: (np.int64(64), np.int64(192), np.int64(192)). \n","Current median shape: [102.142701   348.64708608 348.64708608]\n","Attempting to find 3d_lowres config. \n","Current spacing: [2.26888459 1.19946018 1.19946018]. \n","Current patch size: (np.int64(64), np.int64(192), np.int64(192)). \n","Current median shape: [ 99.16767087 338.49231658 338.49231658]\n","Attempting to find 3d_lowres config. \n","Current spacing: [2.33695112 1.23544399 1.23544399]. \n","Current patch size: (np.int64(64), np.int64(192), np.int64(192)). \n","Current median shape: [ 96.27929211 328.63331707 328.63331707]\n","Attempting to find 3d_lowres config. \n","Current spacing: [2.40705966 1.27250731 1.27250731]. \n","Current patch size: (np.int64(64), np.int64(192), np.int64(192)). \n","Current median shape: [ 93.47504088 319.06147288 319.06147288]\n","Attempting to find 3d_lowres config. \n","Current spacing: [2.47927145 1.31068253 1.31068253]. \n","Current patch size: (np.int64(64), np.int64(192), np.int64(192)). \n","Current median shape: [ 90.75246688 309.76842027 309.76842027]\n","2D U-Net configuration:\n","{'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 12, 'patch_size': (np.int64(512), np.int64(512)), 'median_image_size_in_voxels': array([512., 512.]), 'spacing': array([0.79298449, 0.79298449]), 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 8, 'features_per_stage': (32, 64, 128, 256, 512, 512, 512, 512), 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': ((3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)), 'strides': ((1, 1), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': True}\n","\n","Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer\n","3D lowres U-Net configuration:\n","{'data_identifier': 'nnUNetPlans_3d_lowres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': (np.int64(64), np.int64(192), np.int64(192)), 'median_image_size_in_voxels': (91, 310, 310), 'spacing': array([2.47927145, 1.31068253, 1.31068253]), 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 320, 320), 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': ((3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3)), 'strides': ((1, 1, 1), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2), (1, 2, 2)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': False, 'next_stage': '3d_cascade_fullres'}\n","\n","3D fullres U-Net configuration:\n","{'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': (np.int64(64), np.int64(192), np.int64(192)), 'median_image_size_in_voxels': array([150., 512., 512.]), 'spacing': array([1.5       , 0.79298449, 0.79298449]), 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 320, 320), 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': ((3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3)), 'strides': ((1, 1, 1), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2), (1, 2, 2)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': True}\n","\n","Plans were saved to data/nnUNet_preprocessed/Dataset002_hepaticvessel/nnUNetPlans.json\n","Preprocessing...\n","Preprocessing dataset Dataset002_hepaticvessel\n","Configuration: 3d_fullres...\n","100% 318/318 [37:50<00:00,  7.14s/it]\n"]}]},{"cell_type":"code","source":["!nnUNetv2_train 2 3d_fullres 0 -tr nnUNetTrainerCEclCEloss\n","#nnUNetTrainerDiceclCELoss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vt3dSbXxT_0q","executionInfo":{"status":"ok","timestamp":1746679776518,"user_tz":-180,"elapsed":60453847,"user":{"displayName":"Mustafa Said KARTAL","userId":"14049951240735760192"}},"outputId":"42363fa5-7a5e-4d55-fd8e-68a8e7e70985"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","############################\n","INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n","############################\n","\n","2025-05-07 12:02:10.646261: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2025-05-07 12:02:10.670278: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1746619330.693537  355193 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1746619330.700605  355193 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-05-07 12:02:10.727287: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","Using device: cuda:0\n","\n","#######################################################################\n","Please cite the following paper when using nnU-Net:\n","Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n","#######################################################################\n","\n","2025-05-07 12:02:14.460567: Using torch.compile...\n","2025-05-07 12:02:16.502877: do_dummy_2d_data_aug: False\n","2025-05-07 12:02:16.517351: Creating new 5-fold cross-validation split...\n","2025-05-07 12:02:16.528981: Desired fold for training: 0\n","2025-05-07 12:02:16.548105: This split has 254 training and 64 validation cases.\n","using pin_memory on device 0\n","using pin_memory on device 0\n","\n","This is the configuration used by this training:\n","Configuration name: 3d_fullres\n"," {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [64, 192, 192], 'median_image_size_in_voxels': [150.0, 512.0, 512.0], 'spacing': [1.5, 0.7929844856262207, 0.7929844856262207], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} \n","\n","These are the global plan.json settings:\n"," {'dataset_name': 'Dataset002_hepaticvessel', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [5.0, 0.7929844856262207, 0.7929844856262207], 'original_median_shape_after_transp': [49, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 138.7323455810547, 'median': 138.0, 'min': -938.0, 'percentile_00_5': -11.0, 'percentile_99_5': 264.0, 'std': 46.399627685546875}}} \n","\n","2025-05-07 12:02:22.773288: Unable to plot network architecture: nnUNet_compile is enabled!\n","2025-05-07 12:02:22.864809: \n","2025-05-07 12:02:22.898510: Epoch 0\n","2025-05-07 12:02:22.929806: Current learning rate: 0.01\n","W0507 12:02:36.441000 355193 torch/_inductor/utils.py:1137] [0/0] Not enough SMs to use max_autotune_gemm mode\n","2025-05-07 12:06:30.881085: train_loss 0.1601\n","2025-05-07 12:06:30.943897: val_loss 0.1146\n","2025-05-07 12:06:30.946824: Pseudo dice [0.0, 0.0]\n","2025-05-07 12:06:30.949544: Epoch time: 248.02 s\n","2025-05-07 12:06:30.951717: Yayy! New best EMA pseudo Dice: 0.0\n","2025-05-07 12:06:32.703006: \n","2025-05-07 12:06:32.706392: Epoch 1\n","2025-05-07 12:06:32.709067: Current learning rate: 0.00997\n","2025-05-07 12:09:38.129643: train_loss 0.1211\n","2025-05-07 12:09:38.133573: val_loss 0.117\n","2025-05-07 12:09:38.135947: Pseudo dice [0.0, 0.0]\n","2025-05-07 12:09:38.139401: Epoch time: 185.43 s\n","2025-05-07 12:09:39.507231: \n","2025-05-07 12:09:39.510248: Epoch 2\n","2025-05-07 12:09:39.512570: Current learning rate: 0.00994\n","2025-05-07 12:12:46.184187: train_loss 0.1108\n","2025-05-07 12:12:46.187573: val_loss 0.1002\n","2025-05-07 12:12:46.206278: Pseudo dice [0.0, 0.0]\n","2025-05-07 12:12:46.208873: Epoch time: 186.68 s\n","2025-05-07 12:12:47.579599: \n","2025-05-07 12:12:47.582924: Epoch 3\n","2025-05-07 12:12:47.585631: Current learning rate: 0.00991\n","2025-05-07 12:15:54.672556: train_loss 0.0953\n","2025-05-07 12:15:54.676374: val_loss 0.1014\n","2025-05-07 12:15:54.678471: Pseudo dice [0.0101, 0.0]\n","2025-05-07 12:15:54.680495: Epoch time: 187.09 s\n","2025-05-07 12:15:54.682522: Yayy! New best EMA pseudo Dice: 0.0005\n","2025-05-07 12:15:56.697930: \n","2025-05-07 12:15:56.700837: Epoch 4\n","2025-05-07 12:15:56.703084: Current learning rate: 0.00988\n","2025-05-07 12:19:03.783090: train_loss 0.0918\n","2025-05-07 12:19:03.786823: val_loss 0.0974\n","2025-05-07 12:19:03.788969: Pseudo dice [0.147, 0.0]\n","2025-05-07 12:19:03.790939: Epoch time: 187.09 s\n","2025-05-07 12:19:03.793082: Yayy! New best EMA pseudo Dice: 0.0078\n","2025-05-07 12:19:05.800287: \n","2025-05-07 12:19:05.803368: Epoch 5\n","2025-05-07 12:19:06.436075: Current learning rate: 0.00985\n","2025-05-07 12:22:13.395595: train_loss 0.0833\n","2025-05-07 12:22:13.399159: val_loss 0.0817\n","2025-05-07 12:22:13.401238: Pseudo dice [0.4006, 0.0]\n","2025-05-07 12:22:13.403219: Epoch time: 187.6 s\n","2025-05-07 12:22:13.405170: Yayy! New best EMA pseudo Dice: 0.0271\n","2025-05-07 12:22:15.432252: \n","2025-05-07 12:22:15.435214: Epoch 6\n","2025-05-07 12:22:15.437483: Current learning rate: 0.00982\n","2025-05-07 12:25:22.613899: train_loss 0.0768\n","2025-05-07 12:25:22.618138: val_loss 0.076\n","2025-05-07 12:25:22.621432: Pseudo dice [0.4353, 0.0013]\n","2025-05-07 12:25:22.623926: Epoch time: 187.18 s\n","2025-05-07 12:25:22.626127: Yayy! New best EMA pseudo Dice: 0.0462\n","2025-05-07 12:25:24.581399: \n","2025-05-07 12:25:24.584167: Epoch 7\n","2025-05-07 12:25:24.586464: Current learning rate: 0.00979\n","2025-05-07 12:28:31.405761: train_loss 0.0711\n","2025-05-07 12:28:31.409579: val_loss 0.0692\n","2025-05-07 12:28:31.411898: Pseudo dice [0.4184, 0.0017]\n","2025-05-07 12:28:31.414175: Epoch time: 186.83 s\n","2025-05-07 12:28:31.416189: Yayy! New best EMA pseudo Dice: 0.0626\n","2025-05-07 12:28:33.860816: \n","2025-05-07 12:28:33.863469: Epoch 8\n","2025-05-07 12:28:33.865587: Current learning rate: 0.00976\n","2025-05-07 12:31:41.253547: train_loss 0.0694\n","2025-05-07 12:31:41.257065: val_loss 0.0699\n","2025-05-07 12:31:41.259119: Pseudo dice [0.5494, 0.0186]\n","2025-05-07 12:31:41.275848: Epoch time: 187.39 s\n","2025-05-07 12:31:41.277965: Yayy! New best EMA pseudo Dice: 0.0847\n","2025-05-07 12:31:43.248601: \n","2025-05-07 12:31:43.251460: Epoch 9\n","2025-05-07 12:31:43.253577: Current learning rate: 0.00973\n","2025-05-07 12:34:50.793545: train_loss 0.0665\n","2025-05-07 12:34:50.797144: val_loss 0.065\n","2025-05-07 12:34:50.799699: Pseudo dice [0.5652, 0.0422]\n","2025-05-07 12:34:50.802760: Epoch time: 187.55 s\n","2025-05-07 12:34:50.804768: Yayy! New best EMA pseudo Dice: 0.1066\n","2025-05-07 12:34:52.789021: \n","2025-05-07 12:34:52.791898: Epoch 10\n","2025-05-07 12:34:52.794194: Current learning rate: 0.0097\n","2025-05-07 12:38:00.108958: train_loss 0.0656\n","2025-05-07 12:38:00.112610: val_loss 0.0634\n","2025-05-07 12:38:00.114686: Pseudo dice [0.5806, 0.1185]\n","2025-05-07 12:38:00.116709: Epoch time: 187.32 s\n","2025-05-07 12:38:00.118739: Yayy! New best EMA pseudo Dice: 0.1309\n","2025-05-07 12:38:02.456989: \n","2025-05-07 12:38:02.459735: Epoch 11\n","2025-05-07 12:38:02.461892: Current learning rate: 0.00967\n","2025-05-07 12:41:09.786282: train_loss 0.0624\n","2025-05-07 12:41:09.790002: val_loss 0.0651\n","2025-05-07 12:41:09.792164: Pseudo dice [0.5673, 0.2786]\n","2025-05-07 12:41:09.794088: Epoch time: 187.33 s\n","2025-05-07 12:41:09.796430: Yayy! New best EMA pseudo Dice: 0.1601\n","2025-05-07 12:41:11.760953: \n","2025-05-07 12:41:11.763861: Epoch 12\n","2025-05-07 12:41:11.998975: Current learning rate: 0.00964\n","2025-05-07 12:44:19.478545: train_loss 0.0657\n","2025-05-07 12:44:19.482568: val_loss 0.0663\n","2025-05-07 12:44:19.484947: Pseudo dice [0.443, 0.4105]\n","2025-05-07 12:44:19.501305: Epoch time: 187.72 s\n","2025-05-07 12:44:19.505163: Yayy! New best EMA pseudo Dice: 0.1868\n","2025-05-07 12:44:21.516697: \n","2025-05-07 12:44:21.520077: Epoch 13\n","2025-05-07 12:44:21.522931: Current learning rate: 0.00961\n","2025-05-07 12:47:28.883381: train_loss 0.0604\n","2025-05-07 12:47:28.887071: val_loss 0.0577\n","2025-05-07 12:47:28.889127: Pseudo dice [0.4963, 0.3639]\n","2025-05-07 12:47:28.891120: Epoch time: 187.37 s\n","2025-05-07 12:47:28.893950: Yayy! New best EMA pseudo Dice: 0.2111\n","2025-05-07 12:47:31.186998: \n","2025-05-07 12:47:31.190103: Epoch 14\n","2025-05-07 12:47:31.192529: Current learning rate: 0.00958\n","2025-05-07 12:50:38.909615: train_loss 0.0592\n","2025-05-07 12:50:38.913382: val_loss 0.0556\n","2025-05-07 12:50:38.915527: Pseudo dice [0.4996, 0.4199]\n","2025-05-07 12:50:38.917609: Epoch time: 187.72 s\n","2025-05-07 12:50:38.919598: Yayy! New best EMA pseudo Dice: 0.236\n","2025-05-07 12:50:40.922917: \n","2025-05-07 12:50:40.925767: Epoch 15\n","2025-05-07 12:50:40.927819: Current learning rate: 0.00955\n","2025-05-07 12:53:48.897374: train_loss 0.0603\n","2025-05-07 12:53:48.901323: val_loss 0.0573\n","2025-05-07 12:53:48.904006: Pseudo dice [0.5482, 0.524]\n","2025-05-07 12:53:48.939933: Epoch time: 187.98 s\n","2025-05-07 12:53:48.942728: Yayy! New best EMA pseudo Dice: 0.266\n","2025-05-07 12:53:51.303694: \n","2025-05-07 12:53:51.315779: Epoch 16\n","2025-05-07 12:53:51.317899: Current learning rate: 0.00952\n","2025-05-07 12:56:59.526747: train_loss 0.0536\n","2025-05-07 12:56:59.531469: val_loss 0.0563\n","2025-05-07 12:56:59.534304: Pseudo dice [0.6109, 0.524]\n","2025-05-07 12:56:59.536312: Epoch time: 188.22 s\n","2025-05-07 12:56:59.538442: Yayy! New best EMA pseudo Dice: 0.2961\n","2025-05-07 12:57:01.600720: \n","2025-05-07 12:57:01.603565: Epoch 17\n","2025-05-07 12:57:01.605754: Current learning rate: 0.00949\n","2025-05-07 13:00:09.943494: train_loss 0.0552\n","2025-05-07 13:00:09.948221: val_loss 0.0497\n","2025-05-07 13:00:09.950526: Pseudo dice [0.6676, 0.5753]\n","2025-05-07 13:00:09.953905: Epoch time: 188.34 s\n","2025-05-07 13:00:09.956006: Yayy! New best EMA pseudo Dice: 0.3287\n","2025-05-07 13:00:11.967831: \n","2025-05-07 13:00:11.970703: Epoch 18\n","2025-05-07 13:00:11.973834: Current learning rate: 0.00946\n","2025-05-07 13:03:19.835236: train_loss 0.0545\n","2025-05-07 13:03:19.838988: val_loss 0.053\n","2025-05-07 13:03:19.841922: Pseudo dice [0.623, 0.5334]\n","2025-05-07 13:03:19.843760: Epoch time: 187.87 s\n","2025-05-07 13:03:19.845599: Yayy! New best EMA pseudo Dice: 0.3536\n","2025-05-07 13:03:22.503964: \n","2025-05-07 13:03:22.507233: Epoch 19\n","2025-05-07 13:03:22.509804: Current learning rate: 0.00943\n","2025-05-07 13:06:30.138812: train_loss 0.0524\n","2025-05-07 13:06:30.144306: val_loss 0.0502\n","2025-05-07 13:06:30.146698: Pseudo dice [0.6523, 0.5931]\n","2025-05-07 13:06:30.148957: Epoch time: 187.64 s\n","2025-05-07 13:06:30.151310: Yayy! New best EMA pseudo Dice: 0.3805\n","2025-05-07 13:06:32.224327: \n","2025-05-07 13:06:32.227603: Epoch 20\n","2025-05-07 13:06:32.231185: Current learning rate: 0.0094\n","2025-05-07 13:09:40.049981: train_loss 0.0517\n","2025-05-07 13:09:40.055162: val_loss 0.0528\n","2025-05-07 13:09:40.058769: Pseudo dice [0.6121, 0.5931]\n","2025-05-07 13:09:40.062079: Epoch time: 187.83 s\n","2025-05-07 13:09:40.065416: Yayy! New best EMA pseudo Dice: 0.4027\n","2025-05-07 13:09:42.521447: \n","2025-05-07 13:09:42.524561: Epoch 21\n","2025-05-07 13:09:42.526766: Current learning rate: 0.00937\n","2025-05-07 13:12:50.625251: train_loss 0.0529\n","2025-05-07 13:12:50.629389: val_loss 0.0475\n","2025-05-07 13:12:50.633520: Pseudo dice [0.6393, 0.5775]\n","2025-05-07 13:12:50.636088: Epoch time: 188.11 s\n","2025-05-07 13:12:50.638604: Yayy! New best EMA pseudo Dice: 0.4233\n","2025-05-07 13:12:52.719581: \n","2025-05-07 13:12:52.722512: Epoch 22\n","2025-05-07 13:12:52.724735: Current learning rate: 0.00934\n","2025-05-07 13:16:00.488807: train_loss 0.0551\n","2025-05-07 13:16:00.492463: val_loss 0.0494\n","2025-05-07 13:16:00.494560: Pseudo dice [0.6135, 0.5588]\n","2025-05-07 13:16:00.496936: Epoch time: 187.77 s\n","2025-05-07 13:16:00.499643: Yayy! New best EMA pseudo Dice: 0.4396\n","2025-05-07 13:16:02.749039: \n","2025-05-07 13:16:02.752927: Epoch 23\n","2025-05-07 13:16:02.755344: Current learning rate: 0.00931\n","2025-05-07 13:19:10.519581: train_loss 0.0531\n","2025-05-07 13:19:10.523746: val_loss 0.0482\n","2025-05-07 13:19:10.527088: Pseudo dice [0.6549, 0.5855]\n","2025-05-07 13:19:10.529172: Epoch time: 187.77 s\n","2025-05-07 13:19:10.531071: Yayy! New best EMA pseudo Dice: 0.4577\n","2025-05-07 13:19:12.635026: \n","2025-05-07 13:19:12.637688: Epoch 24\n","2025-05-07 13:19:12.639783: Current learning rate: 0.00928\n","2025-05-07 13:22:20.615305: train_loss 0.0512\n","2025-05-07 13:22:20.619106: val_loss 0.05\n","2025-05-07 13:22:20.639619: Pseudo dice [0.6723, 0.6045]\n","2025-05-07 13:22:20.642644: Epoch time: 187.98 s\n","2025-05-07 13:22:20.644720: Yayy! New best EMA pseudo Dice: 0.4757\n","2025-05-07 13:22:23.745370: \n","2025-05-07 13:22:23.748355: Epoch 25\n","2025-05-07 13:22:23.750472: Current learning rate: 0.00925\n","2025-05-07 13:25:32.232753: train_loss 0.0522\n","2025-05-07 13:25:32.237110: val_loss 0.0463\n","2025-05-07 13:25:32.240640: Pseudo dice [0.6624, 0.5928]\n","2025-05-07 13:25:32.244092: Epoch time: 188.49 s\n","2025-05-07 13:25:32.248096: Yayy! New best EMA pseudo Dice: 0.4909\n","2025-05-07 13:25:34.711267: \n","2025-05-07 13:25:35.340895: Epoch 26\n","2025-05-07 13:25:35.343998: Current learning rate: 0.00922\n","2025-05-07 13:28:44.163455: train_loss 0.0487\n","2025-05-07 13:28:44.167561: val_loss 0.0482\n","2025-05-07 13:28:44.169879: Pseudo dice [0.6729, 0.6128]\n","2025-05-07 13:28:44.172025: Epoch time: 189.45 s\n","2025-05-07 13:28:44.173945: Yayy! New best EMA pseudo Dice: 0.5061\n","2025-05-07 13:28:46.269079: \n","2025-05-07 13:28:46.271943: Epoch 27\n","2025-05-07 13:28:46.273931: Current learning rate: 0.00919\n","2025-05-07 13:31:54.400252: train_loss 0.0483\n","2025-05-07 13:31:54.404616: val_loss 0.0488\n","2025-05-07 13:31:54.408074: Pseudo dice [0.69, 0.6201]\n","2025-05-07 13:31:54.411121: Epoch time: 188.13 s\n","2025-05-07 13:31:54.414218: Yayy! New best EMA pseudo Dice: 0.521\n","2025-05-07 13:31:56.441311: \n","2025-05-07 13:31:56.444411: Epoch 28\n","2025-05-07 13:31:56.448035: Current learning rate: 0.00916\n","2025-05-07 13:35:04.623709: train_loss 0.0449\n","2025-05-07 13:35:04.627182: val_loss 0.0517\n","2025-05-07 13:35:04.629376: Pseudo dice [0.6123, 0.6249]\n","2025-05-07 13:35:04.631485: Epoch time: 188.18 s\n","2025-05-07 13:35:04.633455: Yayy! New best EMA pseudo Dice: 0.5308\n","2025-05-07 13:35:06.695490: \n","2025-05-07 13:35:06.698691: Epoch 29\n","2025-05-07 13:35:06.700970: Current learning rate: 0.00913\n","2025-05-07 13:38:15.729811: train_loss 0.0485\n","2025-05-07 13:38:15.751231: val_loss 0.0473\n","2025-05-07 13:38:15.754677: Pseudo dice [0.6792, 0.6304]\n","2025-05-07 13:38:15.756696: Epoch time: 189.04 s\n","2025-05-07 13:38:15.759523: Yayy! New best EMA pseudo Dice: 0.5432\n","2025-05-07 13:38:17.824870: \n","2025-05-07 13:38:17.827836: Epoch 30\n","2025-05-07 13:38:17.830150: Current learning rate: 0.0091\n","2025-05-07 13:41:26.902961: train_loss 0.0487\n","2025-05-07 13:41:26.907534: val_loss 0.045\n","2025-05-07 13:41:26.910101: Pseudo dice [0.7038, 0.6362]\n","2025-05-07 13:41:26.912624: Epoch time: 189.08 s\n","2025-05-07 13:41:26.914814: Yayy! New best EMA pseudo Dice: 0.5559\n","2025-05-07 13:41:29.838661: \n","2025-05-07 13:41:29.841558: Epoch 31\n","2025-05-07 13:41:29.843702: Current learning rate: 0.00907\n","2025-05-07 13:44:37.699981: train_loss 0.0501\n","2025-05-07 13:44:37.704212: val_loss 0.0477\n","2025-05-07 13:44:37.706753: Pseudo dice [0.6612, 0.5801]\n","2025-05-07 13:44:37.709577: Epoch time: 187.86 s\n","2025-05-07 13:44:37.711992: Yayy! New best EMA pseudo Dice: 0.5623\n","2025-05-07 13:44:40.158696: \n","2025-05-07 13:44:40.161624: Epoch 32\n","2025-05-07 13:44:40.500911: Current learning rate: 0.00903\n","2025-05-07 13:47:48.255589: train_loss 0.0487\n","2025-05-07 13:47:48.259837: val_loss 0.0423\n","2025-05-07 13:47:48.262332: Pseudo dice [0.7288, 0.6551]\n","2025-05-07 13:47:48.265450: Epoch time: 188.1 s\n","2025-05-07 13:47:48.268422: Yayy! New best EMA pseudo Dice: 0.5753\n","2025-05-07 13:47:50.565424: \n","2025-05-07 13:47:50.568558: Epoch 33\n","2025-05-07 13:47:50.571247: Current learning rate: 0.009\n","2025-05-07 13:50:58.657442: train_loss 0.0453\n","2025-05-07 13:50:58.661622: val_loss 0.0488\n","2025-05-07 13:50:58.664173: Pseudo dice [0.699, 0.6189]\n","2025-05-07 13:50:58.666298: Epoch time: 188.09 s\n","2025-05-07 13:50:58.668745: Yayy! New best EMA pseudo Dice: 0.5837\n","2025-05-07 13:51:00.998061: \n","2025-05-07 13:51:01.002066: Epoch 34\n","2025-05-07 13:51:01.004006: Current learning rate: 0.00897\n","2025-05-07 13:54:09.001863: train_loss 0.048\n","2025-05-07 13:54:09.005555: val_loss 0.0398\n","2025-05-07 13:54:09.007623: Pseudo dice [0.7403, 0.6551]\n","2025-05-07 13:54:09.009518: Epoch time: 188.0 s\n","2025-05-07 13:54:09.011497: Yayy! New best EMA pseudo Dice: 0.5951\n","2025-05-07 13:54:11.494063: \n","2025-05-07 13:54:11.496880: Epoch 35\n","2025-05-07 13:54:11.499902: Current learning rate: 0.00894\n","2025-05-07 13:57:19.809258: train_loss 0.0431\n","2025-05-07 13:57:19.840499: val_loss 0.0429\n","2025-05-07 13:57:19.843037: Pseudo dice [0.703, 0.619]\n","2025-05-07 13:57:19.845351: Epoch time: 188.32 s\n","2025-05-07 13:57:19.847576: Yayy! New best EMA pseudo Dice: 0.6017\n","2025-05-07 13:57:21.929121: \n","2025-05-07 13:57:21.932742: Epoch 36\n","2025-05-07 13:57:21.936527: Current learning rate: 0.00891\n","2025-05-07 14:00:30.720802: train_loss 0.0437\n","2025-05-07 14:00:30.724975: val_loss 0.0493\n","2025-05-07 14:00:30.727402: Pseudo dice [0.6913, 0.6351]\n","2025-05-07 14:00:30.729683: Epoch time: 188.79 s\n","2025-05-07 14:00:30.731829: Yayy! New best EMA pseudo Dice: 0.6078\n","2025-05-07 14:00:33.093868: \n","2025-05-07 14:00:33.097750: Epoch 37\n","2025-05-07 14:00:33.100583: Current learning rate: 0.00888\n","2025-05-07 14:03:41.086510: train_loss 0.0468\n","2025-05-07 14:03:41.095946: val_loss 0.0467\n","2025-05-07 14:03:41.098423: Pseudo dice [0.6958, 0.642]\n","2025-05-07 14:03:41.100970: Epoch time: 187.99 s\n","2025-05-07 14:03:41.103366: Yayy! New best EMA pseudo Dice: 0.6139\n","2025-05-07 14:03:43.814013: \n","2025-05-07 14:03:43.817749: Epoch 38\n","2025-05-07 14:03:43.820628: Current learning rate: 0.00885\n","2025-05-07 14:06:51.935385: train_loss 0.0468\n","2025-05-07 14:06:51.939813: val_loss 0.049\n","2025-05-07 14:06:51.942274: Pseudo dice [0.7245, 0.658]\n","2025-05-07 14:06:51.944553: Epoch time: 188.12 s\n","2025-05-07 14:06:51.963688: Yayy! New best EMA pseudo Dice: 0.6217\n","2025-05-07 14:06:54.266405: \n","2025-05-07 14:06:54.269354: Epoch 39\n","2025-05-07 14:06:54.271474: Current learning rate: 0.00882\n","2025-05-07 14:10:02.889870: train_loss 0.0434\n","2025-05-07 14:10:02.894355: val_loss 0.0473\n","2025-05-07 14:10:02.896603: Pseudo dice [0.7036, 0.6609]\n","2025-05-07 14:10:02.898728: Epoch time: 188.62 s\n","2025-05-07 14:10:02.900686: Yayy! New best EMA pseudo Dice: 0.6277\n","2025-05-07 14:10:05.059074: \n","2025-05-07 14:10:05.688471: Epoch 40\n","2025-05-07 14:10:05.690785: Current learning rate: 0.00879\n","2025-05-07 14:13:14.074882: train_loss 0.0417\n","2025-05-07 14:13:14.079067: val_loss 0.0493\n","2025-05-07 14:13:14.081708: Pseudo dice [0.6597, 0.5319]\n","2025-05-07 14:13:14.083727: Epoch time: 189.02 s\n","2025-05-07 14:13:15.545662: \n","2025-05-07 14:13:15.548793: Epoch 41\n","2025-05-07 14:13:15.551802: Current learning rate: 0.00876\n","2025-05-07 14:16:23.989284: train_loss 0.0468\n","2025-05-07 14:16:23.994253: val_loss 0.0439\n","2025-05-07 14:16:23.996983: Pseudo dice [0.6763, 0.6387]\n","2025-05-07 14:16:23.999580: Epoch time: 188.44 s\n","2025-05-07 14:16:24.002483: Yayy! New best EMA pseudo Dice: 0.6278\n","2025-05-07 14:16:26.295070: \n","2025-05-07 14:16:26.298608: Epoch 42\n","2025-05-07 14:16:26.302334: Current learning rate: 0.00873\n","2025-05-07 14:19:34.978400: train_loss 0.0446\n","2025-05-07 14:19:34.983397: val_loss 0.0431\n","2025-05-07 14:19:34.985918: Pseudo dice [0.701, 0.6683]\n","2025-05-07 14:19:34.989496: Epoch time: 188.68 s\n","2025-05-07 14:19:34.991936: Yayy! New best EMA pseudo Dice: 0.6335\n","2025-05-07 14:19:37.544210: \n","2025-05-07 14:19:37.547542: Epoch 43\n","2025-05-07 14:19:37.550869: Current learning rate: 0.0087\n","2025-05-07 14:22:45.603245: train_loss 0.0464\n","2025-05-07 14:22:45.608088: val_loss 0.049\n","2025-05-07 14:22:45.629715: Pseudo dice [0.6932, 0.6324]\n","2025-05-07 14:22:45.633170: Epoch time: 188.06 s\n","2025-05-07 14:22:45.637334: Yayy! New best EMA pseudo Dice: 0.6364\n","2025-05-07 14:22:48.099887: \n","2025-05-07 14:22:48.102856: Epoch 44\n","2025-05-07 14:22:48.105417: Current learning rate: 0.00867\n","2025-05-07 14:25:56.255510: train_loss 0.0435\n","2025-05-07 14:25:56.260242: val_loss 0.0487\n","2025-05-07 14:25:56.264031: Pseudo dice [0.7098, 0.663]\n","2025-05-07 14:25:56.268381: Epoch time: 188.16 s\n","2025-05-07 14:25:56.272519: Yayy! New best EMA pseudo Dice: 0.6414\n","2025-05-07 14:25:58.637782: \n","2025-05-07 14:25:58.640671: Epoch 45\n","2025-05-07 14:25:58.642910: Current learning rate: 0.00864\n","2025-05-07 14:29:06.946403: train_loss 0.0444\n","2025-05-07 14:29:06.957373: val_loss 0.05\n","2025-05-07 14:29:06.960442: Pseudo dice [0.7109, 0.6594]\n","2025-05-07 14:29:06.963395: Epoch time: 188.31 s\n","2025-05-07 14:29:06.965489: Yayy! New best EMA pseudo Dice: 0.6458\n","2025-05-07 14:29:09.264252: \n","2025-05-07 14:29:09.267093: Epoch 46\n","2025-05-07 14:29:09.269298: Current learning rate: 0.00861\n","2025-05-07 14:32:17.556138: train_loss 0.042\n","2025-05-07 14:32:17.560113: val_loss 0.0464\n","2025-05-07 14:32:17.562160: Pseudo dice [0.7053, 0.6377]\n","2025-05-07 14:32:17.564458: Epoch time: 188.29 s\n","2025-05-07 14:32:17.566958: Yayy! New best EMA pseudo Dice: 0.6484\n","2025-05-07 14:32:19.970284: \n","2025-05-07 14:32:19.973681: Epoch 47\n","2025-05-07 14:32:19.986648: Current learning rate: 0.00858\n","2025-05-07 14:35:28.357636: train_loss 0.0427\n","2025-05-07 14:35:28.361801: val_loss 0.0456\n","2025-05-07 14:35:28.364605: Pseudo dice [0.7173, 0.6442]\n","2025-05-07 14:35:28.367202: Epoch time: 188.4 s\n","2025-05-07 14:35:28.369987: Yayy! New best EMA pseudo Dice: 0.6516\n","2025-05-07 14:35:30.437090: \n","2025-05-07 14:35:30.439946: Epoch 48\n","2025-05-07 14:35:31.068738: Current learning rate: 0.00855\n","2025-05-07 14:38:39.756433: train_loss 0.0413\n","2025-05-07 14:38:39.760349: val_loss 0.0409\n","2025-05-07 14:38:39.762571: Pseudo dice [0.712, 0.6611]\n","2025-05-07 14:38:39.764840: Epoch time: 189.32 s\n","2025-05-07 14:38:39.767064: Yayy! New best EMA pseudo Dice: 0.6551\n","2025-05-07 14:38:42.033427: \n","2025-05-07 14:38:42.036629: Epoch 49\n","2025-05-07 14:38:42.038898: Current learning rate: 0.00852\n","2025-05-07 14:41:50.300135: train_loss 0.0438\n","2025-05-07 14:41:50.304593: val_loss 0.0369\n","2025-05-07 14:41:50.307675: Pseudo dice [0.7029, 0.6601]\n","2025-05-07 14:41:50.310493: Epoch time: 188.27 s\n","2025-05-07 14:41:51.064023: Yayy! New best EMA pseudo Dice: 0.6577\n","2025-05-07 14:41:54.592305: \n","2025-05-07 14:41:54.595543: Epoch 50\n","2025-05-07 14:41:54.598825: Current learning rate: 0.00849\n","2025-05-07 14:45:02.636824: train_loss 0.0437\n","2025-05-07 14:45:02.640882: val_loss 0.0461\n","2025-05-07 14:45:02.643770: Pseudo dice [0.6959, 0.6406]\n","2025-05-07 14:45:02.646598: Epoch time: 188.05 s\n","2025-05-07 14:45:02.649419: Yayy! New best EMA pseudo Dice: 0.6588\n","2025-05-07 14:45:04.943985: \n","2025-05-07 14:45:04.946811: Epoch 51\n","2025-05-07 14:45:04.948898: Current learning rate: 0.00846\n","2025-05-07 14:48:13.341493: train_loss 0.0407\n","2025-05-07 14:48:13.345239: val_loss 0.043\n","2025-05-07 14:48:13.347415: Pseudo dice [0.7412, 0.6894]\n","2025-05-07 14:48:13.350337: Epoch time: 188.4 s\n","2025-05-07 14:48:13.352343: Yayy! New best EMA pseudo Dice: 0.6644\n","2025-05-07 14:48:15.445632: \n","2025-05-07 14:48:15.448629: Epoch 52\n","2025-05-07 14:48:15.450955: Current learning rate: 0.00843\n","2025-05-07 14:51:23.649434: train_loss 0.0418\n","2025-05-07 14:51:23.653315: val_loss 0.042\n","2025-05-07 14:51:23.655854: Pseudo dice [0.7238, 0.685]\n","2025-05-07 14:51:23.658016: Epoch time: 188.21 s\n","2025-05-07 14:51:23.660004: Yayy! New best EMA pseudo Dice: 0.6684\n","2025-05-07 14:51:25.728114: \n","2025-05-07 14:51:25.731130: Epoch 53\n","2025-05-07 14:51:25.733389: Current learning rate: 0.00839\n","2025-05-07 14:54:34.465152: train_loss 0.0434\n","2025-05-07 14:54:34.469200: val_loss 0.0394\n","2025-05-07 14:54:34.471453: Pseudo dice [0.7291, 0.6942]\n","2025-05-07 14:54:34.473401: Epoch time: 188.74 s\n","2025-05-07 14:54:34.475264: Yayy! New best EMA pseudo Dice: 0.6728\n","2025-05-07 14:54:36.731948: \n","2025-05-07 14:54:36.735152: Epoch 54\n","2025-05-07 14:54:36.737372: Current learning rate: 0.00836\n","2025-05-07 14:57:45.437095: train_loss 0.04\n","2025-05-07 14:57:45.441053: val_loss 0.0437\n","2025-05-07 14:57:45.443179: Pseudo dice [0.719, 0.6937]\n","2025-05-07 14:57:45.445964: Epoch time: 188.71 s\n","2025-05-07 14:57:45.447944: Yayy! New best EMA pseudo Dice: 0.6761\n","2025-05-07 14:57:47.518862: \n","2025-05-07 14:57:47.521525: Epoch 55\n","2025-05-07 14:57:48.148016: Current learning rate: 0.00833\n","2025-05-07 15:00:57.622671: train_loss 0.0422\n","2025-05-07 15:00:57.642902: val_loss 0.0487\n","2025-05-07 15:00:57.645241: Pseudo dice [0.6997, 0.656]\n","2025-05-07 15:00:57.647404: Epoch time: 190.1 s\n","2025-05-07 15:00:57.649465: Yayy! New best EMA pseudo Dice: 0.6763\n","2025-05-07 15:00:59.693443: \n","2025-05-07 15:00:59.696272: Epoch 56\n","2025-05-07 15:00:59.698585: Current learning rate: 0.0083\n","2025-05-07 15:04:07.828844: train_loss 0.0415\n","2025-05-07 15:04:07.832800: val_loss 0.0479\n","2025-05-07 15:04:07.835706: Pseudo dice [0.6039, 0.634]\n","2025-05-07 15:04:07.838515: Epoch time: 188.14 s\n","2025-05-07 15:04:09.403536: \n","2025-05-07 15:04:09.406719: Epoch 57\n","2025-05-07 15:04:09.408718: Current learning rate: 0.00827\n","2025-05-07 15:07:17.480934: train_loss 0.0427\n","2025-05-07 15:07:17.486651: val_loss 0.0448\n","2025-05-07 15:07:17.489512: Pseudo dice [0.7589, 0.6819]\n","2025-05-07 15:07:17.492865: Epoch time: 188.08 s\n","2025-05-07 15:07:19.176659: \n","2025-05-07 15:07:19.179384: Epoch 58\n","2025-05-07 15:07:19.198081: Current learning rate: 0.00824\n","2025-05-07 15:10:27.408373: train_loss 0.0437\n","2025-05-07 15:10:27.412128: val_loss 0.0432\n","2025-05-07 15:10:27.414374: Pseudo dice [0.7186, 0.6753]\n","2025-05-07 15:10:27.416497: Epoch time: 188.23 s\n","2025-05-07 15:10:27.418603: Yayy! New best EMA pseudo Dice: 0.6777\n","2025-05-07 15:10:29.724322: \n","2025-05-07 15:10:29.727149: Epoch 59\n","2025-05-07 15:10:29.729652: Current learning rate: 0.00821\n","2025-05-07 15:13:38.197859: train_loss 0.0424\n","2025-05-07 15:13:38.203156: val_loss 0.0419\n","2025-05-07 15:13:38.205832: Pseudo dice [0.6925, 0.6387]\n","2025-05-07 15:13:38.208677: Epoch time: 188.47 s\n","2025-05-07 15:13:39.784488: \n","2025-05-07 15:13:39.787120: Epoch 60\n","2025-05-07 15:13:39.789143: Current learning rate: 0.00818\n","2025-05-07 15:16:47.869160: train_loss 0.0446\n","2025-05-07 15:16:47.873004: val_loss 0.0428\n","2025-05-07 15:16:47.875356: Pseudo dice [0.7219, 0.6483]\n","2025-05-07 15:16:47.877616: Epoch time: 188.09 s\n","2025-05-07 15:16:49.447994: \n","2025-05-07 15:16:49.450971: Epoch 61\n","2025-05-07 15:16:49.453393: Current learning rate: 0.00815\n","2025-05-07 15:19:57.697691: train_loss 0.0438\n","2025-05-07 15:19:57.701736: val_loss 0.041\n","2025-05-07 15:19:57.704086: Pseudo dice [0.7147, 0.6797]\n","2025-05-07 15:19:57.706581: Epoch time: 188.25 s\n","2025-05-07 15:19:57.708752: Yayy! New best EMA pseudo Dice: 0.6793\n","2025-05-07 15:20:00.184731: \n","2025-05-07 15:20:00.188920: Epoch 62\n","2025-05-07 15:20:00.192019: Current learning rate: 0.00812\n","2025-05-07 15:23:08.406692: train_loss 0.0401\n","2025-05-07 15:23:08.411414: val_loss 0.0404\n","2025-05-07 15:23:08.415246: Pseudo dice [0.7339, 0.6808]\n","2025-05-07 15:23:08.418169: Epoch time: 188.23 s\n","2025-05-07 15:23:08.421097: Yayy! New best EMA pseudo Dice: 0.6821\n","2025-05-07 15:23:10.785100: \n","2025-05-07 15:23:10.788122: Epoch 63\n","2025-05-07 15:23:10.790377: Current learning rate: 0.00809\n","2025-05-07 15:26:18.826226: train_loss 0.0395\n","2025-05-07 15:26:18.830532: val_loss 0.0429\n","2025-05-07 15:26:18.834346: Pseudo dice [0.7208, 0.6901]\n","2025-05-07 15:26:18.837260: Epoch time: 188.04 s\n","2025-05-07 15:26:18.841288: Yayy! New best EMA pseudo Dice: 0.6845\n","2025-05-07 15:26:21.251648: \n","2025-05-07 15:26:21.254422: Epoch 64\n","2025-05-07 15:26:21.256529: Current learning rate: 0.00806\n","2025-05-07 15:29:29.223354: train_loss 0.0392\n","2025-05-07 15:29:29.227389: val_loss 0.0412\n","2025-05-07 15:29:29.243797: Pseudo dice [0.7075, 0.6973]\n","2025-05-07 15:29:29.247530: Epoch time: 187.97 s\n","2025-05-07 15:29:29.249629: Yayy! New best EMA pseudo Dice: 0.6863\n","2025-05-07 15:29:31.619133: \n","2025-05-07 15:29:31.621974: Epoch 65\n","2025-05-07 15:29:31.624689: Current learning rate: 0.00803\n","2025-05-07 15:32:39.658173: train_loss 0.0404\n","2025-05-07 15:32:39.663058: val_loss 0.0438\n","2025-05-07 15:32:39.667146: Pseudo dice [0.7199, 0.6732]\n","2025-05-07 15:32:39.670791: Epoch time: 188.04 s\n","2025-05-07 15:32:39.689884: Yayy! New best EMA pseudo Dice: 0.6873\n","2025-05-07 15:32:42.086975: \n","2025-05-07 15:32:42.089699: Epoch 66\n","2025-05-07 15:32:42.091757: Current learning rate: 0.008\n","2025-05-07 15:35:50.428878: train_loss 0.0419\n","2025-05-07 15:35:50.495083: val_loss 0.0359\n","2025-05-07 15:35:50.498781: Pseudo dice [0.7341, 0.712]\n","2025-05-07 15:35:50.501065: Epoch time: 188.34 s\n","2025-05-07 15:35:50.503526: Yayy! New best EMA pseudo Dice: 0.6909\n","2025-05-07 15:35:52.863661: \n","2025-05-07 15:35:52.867037: Epoch 67\n","2025-05-07 15:35:52.869763: Current learning rate: 0.00797\n","2025-05-07 15:39:01.211671: train_loss 0.0393\n","2025-05-07 15:39:01.215574: val_loss 0.0439\n","2025-05-07 15:39:01.217770: Pseudo dice [0.7352, 0.6601]\n","2025-05-07 15:39:01.219918: Epoch time: 188.35 s\n","2025-05-07 15:39:01.221943: Yayy! New best EMA pseudo Dice: 0.6915\n","2025-05-07 15:39:03.569132: \n","2025-05-07 15:39:03.571829: Epoch 68\n","2025-05-07 15:39:03.574035: Current learning rate: 0.00793\n","2025-05-07 15:42:11.788919: train_loss 0.0391\n","2025-05-07 15:42:11.792552: val_loss 0.0435\n","2025-05-07 15:42:11.794791: Pseudo dice [0.6876, 0.6743]\n","2025-05-07 15:42:11.796910: Epoch time: 188.22 s\n","2025-05-07 15:42:13.149498: \n","2025-05-07 15:42:13.152233: Epoch 69\n","2025-05-07 15:42:13.154381: Current learning rate: 0.0079\n","2025-05-07 15:45:21.208714: train_loss 0.0392\n","2025-05-07 15:45:21.213297: val_loss 0.0389\n","2025-05-07 15:45:21.215840: Pseudo dice [0.7648, 0.6986]\n","2025-05-07 15:45:21.218031: Epoch time: 188.06 s\n","2025-05-07 15:45:21.220250: Yayy! New best EMA pseudo Dice: 0.6946\n","2025-05-07 15:45:23.540596: \n","2025-05-07 15:45:23.543436: Epoch 70\n","2025-05-07 15:45:23.545867: Current learning rate: 0.00787\n","2025-05-07 15:48:31.747841: train_loss 0.0401\n","2025-05-07 15:48:31.751734: val_loss 0.0427\n","2025-05-07 15:48:31.753859: Pseudo dice [0.729, 0.7013]\n","2025-05-07 15:48:31.756758: Epoch time: 188.21 s\n","2025-05-07 15:48:31.758780: Yayy! New best EMA pseudo Dice: 0.6967\n","2025-05-07 15:48:34.112898: \n","2025-05-07 15:48:34.116021: Epoch 71\n","2025-05-07 15:48:34.118155: Current learning rate: 0.00784\n","2025-05-07 15:51:42.628000: train_loss 0.038\n","2025-05-07 15:51:42.632240: val_loss 0.0452\n","2025-05-07 15:51:42.634675: Pseudo dice [0.7041, 0.6491]\n","2025-05-07 15:51:42.651780: Epoch time: 188.52 s\n","2025-05-07 15:51:44.030713: \n","2025-05-07 15:51:44.034149: Epoch 72\n","2025-05-07 15:51:44.036777: Current learning rate: 0.00781\n","2025-05-07 15:54:52.426980: train_loss 0.039\n","2025-05-07 15:54:52.431371: val_loss 0.0363\n","2025-05-07 15:54:52.434309: Pseudo dice [0.7398, 0.6765]\n","2025-05-07 15:54:52.436507: Epoch time: 188.4 s\n","2025-05-07 15:54:53.832777: \n","2025-05-07 15:54:53.835880: Epoch 73\n","2025-05-07 15:54:53.838603: Current learning rate: 0.00778\n","2025-05-07 15:58:01.788306: train_loss 0.0388\n","2025-05-07 15:58:01.791853: val_loss 0.0422\n","2025-05-07 15:58:01.793997: Pseudo dice [0.7608, 0.6979]\n","2025-05-07 15:58:01.796279: Epoch time: 187.96 s\n","2025-05-07 15:58:01.798439: Yayy! New best EMA pseudo Dice: 0.6993\n","2025-05-07 15:58:04.106804: \n","2025-05-07 15:58:04.109684: Epoch 74\n","2025-05-07 15:58:04.111841: Current learning rate: 0.00775\n","2025-05-07 16:01:12.095783: train_loss 0.0379\n","2025-05-07 16:01:12.099935: val_loss 0.0437\n","2025-05-07 16:01:12.102407: Pseudo dice [0.7169, 0.7021]\n","2025-05-07 16:01:12.104725: Epoch time: 187.99 s\n","2025-05-07 16:01:12.106989: Yayy! New best EMA pseudo Dice: 0.7003\n","2025-05-07 16:01:15.388892: \n","2025-05-07 16:01:15.392019: Epoch 75\n","2025-05-07 16:01:15.394389: Current learning rate: 0.00772\n","2025-05-07 16:04:24.091545: train_loss 0.0398\n","2025-05-07 16:04:24.143633: val_loss 0.0432\n","2025-05-07 16:04:24.147222: Pseudo dice [0.7113, 0.6909]\n","2025-05-07 16:04:24.171613: Epoch time: 188.7 s\n","2025-05-07 16:04:24.174906: Yayy! New best EMA pseudo Dice: 0.7004\n","2025-05-07 16:04:27.585589: \n","2025-05-07 16:04:27.588326: Epoch 76\n","2025-05-07 16:04:27.590350: Current learning rate: 0.00769\n","2025-05-07 16:07:35.673513: train_loss 0.0397\n","2025-05-07 16:07:35.677139: val_loss 0.0419\n","2025-05-07 16:07:35.680299: Pseudo dice [0.7265, 0.6853]\n","2025-05-07 16:07:35.682439: Epoch time: 188.09 s\n","2025-05-07 16:07:35.684453: Yayy! New best EMA pseudo Dice: 0.701\n","2025-05-07 16:07:37.822001: \n","2025-05-07 16:07:38.241282: Epoch 77\n","2025-05-07 16:07:38.243631: Current learning rate: 0.00766\n","2025-05-07 16:10:46.877515: train_loss 0.0386\n","2025-05-07 16:10:46.885654: val_loss 0.0417\n","2025-05-07 16:10:46.887831: Pseudo dice [0.7461, 0.7064]\n","2025-05-07 16:10:46.889892: Epoch time: 189.06 s\n","2025-05-07 16:10:46.891927: Yayy! New best EMA pseudo Dice: 0.7035\n","2025-05-07 16:10:48.944994: \n","2025-05-07 16:10:49.574841: Epoch 78\n","2025-05-07 16:10:49.577256: Current learning rate: 0.00763\n","2025-05-07 16:13:58.353914: train_loss 0.0419\n","2025-05-07 16:13:58.357331: val_loss 0.0406\n","2025-05-07 16:13:58.359328: Pseudo dice [0.743, 0.6691]\n","2025-05-07 16:13:58.361792: Epoch time: 189.41 s\n","2025-05-07 16:13:58.365214: Yayy! New best EMA pseudo Dice: 0.7038\n","2025-05-07 16:14:00.476185: \n","2025-05-07 16:14:01.089920: Epoch 79\n","2025-05-07 16:14:01.092674: Current learning rate: 0.0076\n","2025-05-07 16:17:09.308286: train_loss 0.0413\n","2025-05-07 16:17:09.311852: val_loss 0.0384\n","2025-05-07 16:17:09.313879: Pseudo dice [0.7291, 0.6995]\n","2025-05-07 16:17:09.315823: Epoch time: 188.83 s\n","2025-05-07 16:17:09.319004: Yayy! New best EMA pseudo Dice: 0.7048\n","2025-05-07 16:17:11.966865: \n","2025-05-07 16:17:11.969467: Epoch 80\n","2025-05-07 16:17:11.971489: Current learning rate: 0.00756\n","2025-05-07 16:20:20.152065: train_loss 0.0371\n","2025-05-07 16:20:20.155483: val_loss 0.0422\n","2025-05-07 16:20:20.157582: Pseudo dice [0.7073, 0.6724]\n","2025-05-07 16:20:20.159632: Epoch time: 188.19 s\n","2025-05-07 16:20:21.562678: \n","2025-05-07 16:20:21.565427: Epoch 81\n","2025-05-07 16:20:21.567582: Current learning rate: 0.00753\n","2025-05-07 16:23:29.735374: train_loss 0.0393\n","2025-05-07 16:23:29.738906: val_loss 0.0431\n","2025-05-07 16:23:29.740961: Pseudo dice [0.7566, 0.7101]\n","2025-05-07 16:23:29.743001: Epoch time: 188.17 s\n","2025-05-07 16:23:29.745175: Yayy! New best EMA pseudo Dice: 0.7063\n","2025-05-07 16:23:31.816929: \n","2025-05-07 16:23:31.820420: Epoch 82\n","2025-05-07 16:23:31.822770: Current learning rate: 0.0075\n","2025-05-07 16:26:40.517721: train_loss 0.0376\n","2025-05-07 16:26:40.521322: val_loss 0.0398\n","2025-05-07 16:26:40.523377: Pseudo dice [0.7007, 0.689]\n","2025-05-07 16:26:40.525256: Epoch time: 188.7 s\n","2025-05-07 16:26:41.873428: \n","2025-05-07 16:26:41.876065: Epoch 83\n","2025-05-07 16:26:41.878033: Current learning rate: 0.00747\n","2025-05-07 16:29:50.603506: train_loss 0.0389\n","2025-05-07 16:29:50.607931: val_loss 0.0392\n","2025-05-07 16:29:50.611282: Pseudo dice [0.7511, 0.6939]\n","2025-05-07 16:29:50.614572: Epoch time: 188.73 s\n","2025-05-07 16:29:50.617830: Yayy! New best EMA pseudo Dice: 0.7069\n","2025-05-07 16:29:52.974255: \n","2025-05-07 16:29:52.976897: Epoch 84\n","2025-05-07 16:29:52.980036: Current learning rate: 0.00744\n","2025-05-07 16:33:01.033359: train_loss 0.0385\n","2025-05-07 16:33:01.036743: val_loss 0.0387\n","2025-05-07 16:33:01.038824: Pseudo dice [0.7469, 0.7172]\n","2025-05-07 16:33:01.040803: Epoch time: 188.06 s\n","2025-05-07 16:33:01.042756: Yayy! New best EMA pseudo Dice: 0.7094\n","2025-05-07 16:33:03.248469: \n","2025-05-07 16:33:03.251297: Epoch 85\n","2025-05-07 16:33:03.253514: Current learning rate: 0.00741\n","2025-05-07 16:36:11.269983: train_loss 0.0391\n","2025-05-07 16:36:11.273510: val_loss 0.0441\n","2025-05-07 16:36:11.276454: Pseudo dice [0.6943, 0.6741]\n","2025-05-07 16:36:11.279941: Epoch time: 188.02 s\n","2025-05-07 16:36:12.589967: \n","2025-05-07 16:36:12.592653: Epoch 86\n","2025-05-07 16:36:12.607701: Current learning rate: 0.00738\n","2025-05-07 16:39:21.132039: train_loss 0.0398\n","2025-05-07 16:39:21.135236: val_loss 0.0354\n","2025-05-07 16:39:21.137266: Pseudo dice [0.7682, 0.702]\n","2025-05-07 16:39:21.139181: Epoch time: 188.54 s\n","2025-05-07 16:39:21.141005: Yayy! New best EMA pseudo Dice: 0.7097\n","2025-05-07 16:39:23.220961: \n","2025-05-07 16:39:23.223738: Epoch 87\n","2025-05-07 16:39:23.226080: Current learning rate: 0.00735\n","2025-05-07 16:42:31.747002: train_loss 0.0397\n","2025-05-07 16:42:31.751081: val_loss 0.0385\n","2025-05-07 16:42:31.753745: Pseudo dice [0.7534, 0.7015]\n","2025-05-07 16:42:31.756446: Epoch time: 188.53 s\n","2025-05-07 16:42:31.758965: Yayy! New best EMA pseudo Dice: 0.7115\n","2025-05-07 16:42:33.978674: \n","2025-05-07 16:42:33.981471: Epoch 88\n","2025-05-07 16:42:33.983538: Current learning rate: 0.00732\n","2025-05-07 16:45:42.230703: train_loss 0.0379\n","2025-05-07 16:45:42.242318: val_loss 0.0412\n","2025-05-07 16:45:42.244374: Pseudo dice [0.6685, 0.6676]\n","2025-05-07 16:45:42.246343: Epoch time: 188.25 s\n","2025-05-07 16:45:43.605181: \n","2025-05-07 16:45:43.608463: Epoch 89\n","2025-05-07 16:45:43.611135: Current learning rate: 0.00729\n","2025-05-07 16:48:51.757789: train_loss 0.0371\n","2025-05-07 16:48:51.768538: val_loss 0.0375\n","2025-05-07 16:48:51.771396: Pseudo dice [0.7366, 0.7051]\n","2025-05-07 16:48:51.774180: Epoch time: 188.15 s\n","2025-05-07 16:48:53.098587: \n","2025-05-07 16:48:53.101215: Epoch 90\n","2025-05-07 16:48:53.103227: Current learning rate: 0.00725\n","2025-05-07 16:52:01.138160: train_loss 0.0375\n","2025-05-07 16:52:01.141605: val_loss 0.0394\n","2025-05-07 16:52:01.143679: Pseudo dice [0.7322, 0.7016]\n","2025-05-07 16:52:01.145697: Epoch time: 188.04 s\n","2025-05-07 16:52:02.684813: \n","2025-05-07 16:52:02.687597: Epoch 91\n","2025-05-07 16:52:02.689732: Current learning rate: 0.00722\n","2025-05-07 16:55:10.861280: train_loss 0.0368\n","2025-05-07 16:55:10.865733: val_loss 0.04\n","2025-05-07 16:55:10.869428: Pseudo dice [0.7598, 0.7248]\n","2025-05-07 16:55:10.872805: Epoch time: 188.18 s\n","2025-05-07 16:55:10.876199: Yayy! New best EMA pseudo Dice: 0.7126\n","2025-05-07 16:55:13.161361: \n","2025-05-07 16:55:13.165291: Epoch 92\n","2025-05-07 16:55:13.168923: Current learning rate: 0.00719\n","2025-05-07 16:58:21.503576: train_loss 0.0412\n","2025-05-07 16:58:21.511609: val_loss 0.0388\n","2025-05-07 16:58:21.513945: Pseudo dice [0.7246, 0.6819]\n","2025-05-07 16:58:21.516366: Epoch time: 188.34 s\n","2025-05-07 16:58:22.908723: \n","2025-05-07 16:58:22.911697: Epoch 93\n","2025-05-07 16:58:22.913892: Current learning rate: 0.00716\n","2025-05-07 17:01:31.088464: train_loss 0.0383\n","2025-05-07 17:01:31.092129: val_loss 0.0408\n","2025-05-07 17:01:31.095074: Pseudo dice [0.754, 0.718]\n","2025-05-07 17:01:31.097889: Epoch time: 188.18 s\n","2025-05-07 17:01:31.100644: Yayy! New best EMA pseudo Dice: 0.7141\n","2025-05-07 17:01:33.454166: \n","2025-05-07 17:01:33.457295: Epoch 94\n","2025-05-07 17:01:33.460915: Current learning rate: 0.00713\n","2025-05-07 17:04:41.490748: train_loss 0.0382\n","2025-05-07 17:04:41.498837: val_loss 0.0386\n","2025-05-07 17:04:41.501158: Pseudo dice [0.7442, 0.71]\n","2025-05-07 17:04:41.503361: Epoch time: 188.04 s\n","2025-05-07 17:04:41.505431: Yayy! New best EMA pseudo Dice: 0.7154\n","2025-05-07 17:04:44.012036: \n","2025-05-07 17:04:44.014949: Epoch 95\n","2025-05-07 17:04:44.017139: Current learning rate: 0.0071\n","2025-05-07 17:07:52.006772: train_loss 0.0374\n","2025-05-07 17:07:52.011205: val_loss 0.0374\n","2025-05-07 17:07:52.015792: Pseudo dice [0.7617, 0.7239]\n","2025-05-07 17:07:52.019259: Epoch time: 188.0 s\n","2025-05-07 17:07:52.022158: Yayy! New best EMA pseudo Dice: 0.7182\n","2025-05-07 17:07:54.519482: \n","2025-05-07 17:07:54.522358: Epoch 96\n","2025-05-07 17:07:54.671487: Current learning rate: 0.00707\n","2025-05-07 17:11:02.633112: train_loss 0.0382\n","2025-05-07 17:11:02.637230: val_loss 0.0426\n","2025-05-07 17:11:02.654925: Pseudo dice [0.7366, 0.6964]\n","2025-05-07 17:11:02.658121: Epoch time: 188.11 s\n","2025-05-07 17:11:04.374113: \n","2025-05-07 17:11:04.377235: Epoch 97\n","2025-05-07 17:11:04.379392: Current learning rate: 0.00704\n","2025-05-07 17:14:12.460495: train_loss 0.0379\n","2025-05-07 17:14:12.464798: val_loss 0.0412\n","2025-05-07 17:14:12.467064: Pseudo dice [0.7457, 0.6975]\n","2025-05-07 17:14:12.469124: Epoch time: 188.09 s\n","2025-05-07 17:14:12.471167: Yayy! New best EMA pseudo Dice: 0.7184\n","2025-05-07 17:14:14.766549: \n","2025-05-07 17:14:14.769526: Epoch 98\n","2025-05-07 17:14:14.771965: Current learning rate: 0.007\n","2025-05-07 17:17:22.903304: train_loss 0.0383\n","2025-05-07 17:17:22.908574: val_loss 0.0356\n","2025-05-07 17:17:22.912023: Pseudo dice [0.7645, 0.713]\n","2025-05-07 17:17:22.915442: Epoch time: 188.14 s\n","2025-05-07 17:17:22.918934: Yayy! New best EMA pseudo Dice: 0.7204\n","2025-05-07 17:17:25.317720: \n","2025-05-07 17:17:25.320395: Epoch 99\n","2025-05-07 17:17:25.322330: Current learning rate: 0.00697\n","2025-05-07 17:20:33.368865: train_loss 0.0372\n","2025-05-07 17:20:33.374860: val_loss 0.039\n","2025-05-07 17:20:33.377537: Pseudo dice [0.7561, 0.7212]\n","2025-05-07 17:20:33.379877: Epoch time: 188.05 s\n","2025-05-07 17:20:34.016990: Yayy! New best EMA pseudo Dice: 0.7222\n","2025-05-07 17:20:39.123627: \n","2025-05-07 17:20:39.126624: Epoch 100\n","2025-05-07 17:20:39.128705: Current learning rate: 0.00694\n","2025-05-07 17:23:47.960821: train_loss 0.0375\n","2025-05-07 17:23:47.964426: val_loss 0.0392\n","2025-05-07 17:23:47.967631: Pseudo dice [0.7357, 0.6839]\n","2025-05-07 17:23:47.970475: Epoch time: 188.84 s\n","2025-05-07 17:23:49.333821: \n","2025-05-07 17:23:49.336539: Epoch 101\n","2025-05-07 17:23:49.338538: Current learning rate: 0.00691\n","2025-05-07 17:26:58.071151: train_loss 0.0416\n","2025-05-07 17:26:58.088629: val_loss 0.0428\n","2025-05-07 17:26:58.091998: Pseudo dice [0.7382, 0.6897]\n","2025-05-07 17:26:58.095068: Epoch time: 188.74 s\n","2025-05-07 17:26:59.464884: \n","2025-05-07 17:26:59.467528: Epoch 102\n","2025-05-07 17:26:59.469481: Current learning rate: 0.00688\n","2025-05-07 17:30:08.490257: train_loss 0.0392\n","2025-05-07 17:30:08.494097: val_loss 0.0367\n","2025-05-07 17:30:08.497394: Pseudo dice [0.7462, 0.696]\n","2025-05-07 17:30:08.513350: Epoch time: 189.03 s\n","2025-05-07 17:30:09.851829: \n","2025-05-07 17:30:09.855369: Epoch 103\n","2025-05-07 17:30:09.858009: Current learning rate: 0.00685\n","2025-05-07 17:33:18.641198: train_loss 0.0383\n","2025-05-07 17:33:18.644752: val_loss 0.0397\n","2025-05-07 17:33:18.646905: Pseudo dice [0.7228, 0.6914]\n","2025-05-07 17:33:18.649038: Epoch time: 188.79 s\n","2025-05-07 17:33:20.005438: \n","2025-05-07 17:33:20.008075: Epoch 104\n","2025-05-07 17:33:20.010006: Current learning rate: 0.00682\n","2025-05-07 17:36:29.124798: train_loss 0.0399\n","2025-05-07 17:36:29.132314: val_loss 0.0413\n","2025-05-07 17:36:29.147190: Pseudo dice [0.7651, 0.7099]\n","2025-05-07 17:36:29.150165: Epoch time: 189.12 s\n","2025-05-07 17:36:31.680881: \n","2025-05-07 17:36:31.683843: Epoch 105\n","2025-05-07 17:36:31.686201: Current learning rate: 0.00679\n","2025-05-07 17:39:40.724112: train_loss 0.0412\n","2025-05-07 17:39:40.728633: val_loss 0.0418\n","2025-05-07 17:39:40.731097: Pseudo dice [0.7448, 0.7078]\n","2025-05-07 17:39:40.734264: Epoch time: 189.04 s\n","2025-05-07 17:39:42.138881: \n","2025-05-07 17:39:42.141799: Epoch 106\n","2025-05-07 17:39:42.143830: Current learning rate: 0.00675\n","2025-05-07 17:42:51.122510: train_loss 0.0412\n","2025-05-07 17:42:51.140351: val_loss 0.0395\n","2025-05-07 17:42:51.143567: Pseudo dice [0.7258, 0.6915]\n","2025-05-07 17:42:51.146551: Epoch time: 188.99 s\n","2025-05-07 17:42:52.506554: \n","2025-05-07 17:42:52.509803: Epoch 107\n","2025-05-07 17:42:52.512394: Current learning rate: 0.00672\n","2025-05-07 17:46:01.610949: train_loss 0.0412\n","2025-05-07 17:46:01.614922: val_loss 0.0361\n","2025-05-07 17:46:01.617510: Pseudo dice [0.7417, 0.7144]\n","2025-05-07 17:46:01.619857: Epoch time: 189.11 s\n","2025-05-07 17:46:02.995854: \n","2025-05-07 17:46:02.999325: Epoch 108\n","2025-05-07 17:46:03.001714: Current learning rate: 0.00669\n","2025-05-07 17:49:11.843029: train_loss 0.0391\n","2025-05-07 17:49:11.846749: val_loss 0.037\n","2025-05-07 17:49:11.848969: Pseudo dice [0.7452, 0.7253]\n","2025-05-07 17:49:11.851936: Epoch time: 188.85 s\n","2025-05-07 17:49:11.854813: Yayy! New best EMA pseudo Dice: 0.7224\n","2025-05-07 17:49:14.046604: \n","2025-05-07 17:49:14.049337: Epoch 109\n","2025-05-07 17:49:14.051347: Current learning rate: 0.00666\n","2025-05-07 17:52:23.109663: train_loss 0.0385\n","2025-05-07 17:52:23.117292: val_loss 0.0394\n","2025-05-07 17:52:23.119763: Pseudo dice [0.7732, 0.7216]\n","2025-05-07 17:52:23.121861: Epoch time: 189.06 s\n","2025-05-07 17:52:23.123816: Yayy! New best EMA pseudo Dice: 0.7249\n","2025-05-07 17:52:25.212777: \n","2025-05-07 17:52:25.215571: Epoch 110\n","2025-05-07 17:52:25.217651: Current learning rate: 0.00663\n","2025-05-07 17:55:34.040344: train_loss 0.0382\n","2025-05-07 17:55:34.044451: val_loss 0.0376\n","2025-05-07 17:55:34.051758: Pseudo dice [0.7292, 0.71]\n","2025-05-07 17:55:34.054039: Epoch time: 188.83 s\n","2025-05-07 17:55:35.405560: \n","2025-05-07 17:55:35.408338: Epoch 111\n","2025-05-07 17:55:35.411270: Current learning rate: 0.0066\n","2025-05-07 17:58:44.331486: train_loss 0.0369\n","2025-05-07 17:58:44.336548: val_loss 0.0395\n","2025-05-07 17:58:44.338866: Pseudo dice [0.7404, 0.7268]\n","2025-05-07 17:58:44.340887: Epoch time: 188.93 s\n","2025-05-07 17:58:44.342827: Yayy! New best EMA pseudo Dice: 0.7253\n","2025-05-07 17:58:46.779128: \n","2025-05-07 17:58:46.781915: Epoch 112\n","2025-05-07 17:58:46.784330: Current learning rate: 0.00657\n","2025-05-07 18:01:54.967121: train_loss 0.0381\n","2025-05-07 18:01:54.971710: val_loss 0.0407\n","2025-05-07 18:01:54.974011: Pseudo dice [0.7327, 0.7178]\n","2025-05-07 18:01:54.976148: Epoch time: 188.2 s\n","2025-05-07 18:01:56.552871: \n","2025-05-07 18:01:56.555691: Epoch 113\n","2025-05-07 18:01:56.557765: Current learning rate: 0.00654\n","2025-05-07 18:05:04.601246: train_loss 0.0393\n","2025-05-07 18:05:04.604935: val_loss 0.0389\n","2025-05-07 18:05:04.608174: Pseudo dice [0.7423, 0.691]\n","2025-05-07 18:05:04.610471: Epoch time: 188.05 s\n","2025-05-07 18:05:06.308732: \n","2025-05-07 18:05:06.311742: Epoch 114\n","2025-05-07 18:05:06.313826: Current learning rate: 0.0065\n","2025-05-07 18:08:14.684132: train_loss 0.0361\n","2025-05-07 18:08:14.688010: val_loss 0.0367\n","2025-05-07 18:08:14.690202: Pseudo dice [0.7386, 0.6978]\n","2025-05-07 18:08:14.692104: Epoch time: 188.38 s\n","2025-05-07 18:08:16.270658: \n","2025-05-07 18:08:16.273423: Epoch 115\n","2025-05-07 18:08:16.288495: Current learning rate: 0.00647\n","2025-05-07 18:11:24.400387: train_loss 0.0377\n","2025-05-07 18:11:24.406355: val_loss 0.045\n","2025-05-07 18:11:24.409375: Pseudo dice [0.7364, 0.7025]\n","2025-05-07 18:11:24.411649: Epoch time: 188.13 s\n","2025-05-07 18:11:25.974139: \n","2025-05-07 18:11:25.977171: Epoch 116\n","2025-05-07 18:11:25.979332: Current learning rate: 0.00644\n","2025-05-07 18:14:34.037104: train_loss 0.0363\n","2025-05-07 18:14:34.040583: val_loss 0.0377\n","2025-05-07 18:14:34.044192: Pseudo dice [0.7178, 0.6875]\n","2025-05-07 18:14:34.046521: Epoch time: 188.06 s\n","2025-05-07 18:14:35.633011: \n","2025-05-07 18:14:35.635743: Epoch 117\n","2025-05-07 18:14:35.637776: Current learning rate: 0.00641\n","2025-05-07 18:17:43.754197: train_loss 0.0334\n","2025-05-07 18:17:43.759000: val_loss 0.0412\n","2025-05-07 18:17:43.762293: Pseudo dice [0.7517, 0.6947]\n","2025-05-07 18:17:43.765010: Epoch time: 188.12 s\n","2025-05-07 18:17:45.117301: \n","2025-05-07 18:17:45.120397: Epoch 118\n","2025-05-07 18:17:45.122419: Current learning rate: 0.00638\n","2025-05-07 18:20:53.612567: train_loss 0.0374\n","2025-05-07 18:20:53.616465: val_loss 0.0365\n","2025-05-07 18:20:53.618766: Pseudo dice [0.7406, 0.732]\n","2025-05-07 18:20:53.620786: Epoch time: 188.5 s\n","2025-05-07 18:20:55.192345: \n","2025-05-07 18:20:55.195134: Epoch 119\n","2025-05-07 18:20:55.197356: Current learning rate: 0.00635\n","2025-05-07 18:24:03.727002: train_loss 0.0349\n","2025-05-07 18:24:03.731965: val_loss 0.0378\n","2025-05-07 18:24:03.735595: Pseudo dice [0.7697, 0.729]\n","2025-05-07 18:24:03.738064: Epoch time: 188.54 s\n","2025-05-07 18:24:03.741323: Yayy! New best EMA pseudo Dice: 0.7256\n","2025-05-07 18:24:06.192252: \n","2025-05-07 18:24:06.276122: Epoch 120\n","2025-05-07 18:24:06.278850: Current learning rate: 0.00631\n","2025-05-07 18:27:14.695825: train_loss 0.0359\n","2025-05-07 18:27:14.714671: val_loss 0.0366\n","2025-05-07 18:27:14.717001: Pseudo dice [0.7542, 0.723]\n","2025-05-07 18:27:14.719419: Epoch time: 188.5 s\n","2025-05-07 18:27:14.721660: Yayy! New best EMA pseudo Dice: 0.7269\n","2025-05-07 18:27:16.988422: \n","2025-05-07 18:27:16.991316: Epoch 121\n","2025-05-07 18:27:16.993407: Current learning rate: 0.00628\n","2025-05-07 18:30:25.505094: train_loss 0.0365\n","2025-05-07 18:30:25.510092: val_loss 0.0378\n","2025-05-07 18:30:25.512369: Pseudo dice [0.7786, 0.7399]\n","2025-05-07 18:30:25.514538: Epoch time: 188.52 s\n","2025-05-07 18:30:25.516608: Yayy! New best EMA pseudo Dice: 0.7301\n","2025-05-07 18:30:27.832348: \n","2025-05-07 18:30:27.844596: Epoch 122\n","2025-05-07 18:30:27.848685: Current learning rate: 0.00625\n","2025-05-07 18:33:36.315145: train_loss 0.037\n","2025-05-07 18:33:36.320987: val_loss 0.0412\n","2025-05-07 18:33:36.323607: Pseudo dice [0.7623, 0.7146]\n","2025-05-07 18:33:36.326094: Epoch time: 188.48 s\n","2025-05-07 18:33:36.328286: Yayy! New best EMA pseudo Dice: 0.731\n","2025-05-07 18:33:38.655630: \n","2025-05-07 18:33:38.658625: Epoch 123\n","2025-05-07 18:33:38.661358: Current learning rate: 0.00622\n","2025-05-07 18:36:47.135284: train_loss 0.0369\n","2025-05-07 18:36:47.143186: val_loss 0.0361\n","2025-05-07 18:36:47.145362: Pseudo dice [0.7479, 0.7016]\n","2025-05-07 18:36:47.147373: Epoch time: 188.48 s\n","2025-05-07 18:36:48.760000: \n","2025-05-07 18:36:48.763005: Epoch 124\n","2025-05-07 18:36:48.765688: Current learning rate: 0.00619\n","2025-05-07 18:39:56.940959: train_loss 0.0367\n","2025-05-07 18:39:56.946524: val_loss 0.036\n","2025-05-07 18:39:56.948879: Pseudo dice [0.7472, 0.711]\n","2025-05-07 18:39:56.951110: Epoch time: 188.18 s\n","2025-05-07 18:40:00.662003: \n","2025-05-07 18:40:00.664872: Epoch 125\n","2025-05-07 18:40:00.667162: Current learning rate: 0.00616\n","2025-05-07 18:43:09.364653: train_loss 0.037\n","2025-05-07 18:43:09.368079: val_loss 0.037\n","2025-05-07 18:43:09.370242: Pseudo dice [0.761, 0.7314]\n","2025-05-07 18:43:09.372400: Epoch time: 188.7 s\n","2025-05-07 18:43:09.374418: Yayy! New best EMA pseudo Dice: 0.7318\n","2025-05-07 18:43:11.616727: \n","2025-05-07 18:43:11.620025: Epoch 126\n","2025-05-07 18:43:11.622355: Current learning rate: 0.00612\n","2025-05-07 18:46:20.071143: train_loss 0.0346\n","2025-05-07 18:46:20.075598: val_loss 0.039\n","2025-05-07 18:46:20.078424: Pseudo dice [0.7389, 0.7001]\n","2025-05-07 18:46:20.081269: Epoch time: 188.46 s\n","2025-05-07 18:46:21.496785: \n","2025-05-07 18:46:21.499734: Epoch 127\n","2025-05-07 18:46:21.501675: Current learning rate: 0.00609\n","2025-05-07 18:49:30.347884: train_loss 0.0337\n","2025-05-07 18:49:30.351484: val_loss 0.0406\n","2025-05-07 18:49:30.353535: Pseudo dice [0.7309, 0.7203]\n","2025-05-07 18:49:30.355633: Epoch time: 188.85 s\n","2025-05-07 18:49:31.732741: \n","2025-05-07 18:49:31.735751: Epoch 128\n","2025-05-07 18:49:31.738986: Current learning rate: 0.00606\n","2025-05-07 18:52:40.501106: train_loss 0.0363\n","2025-05-07 18:52:40.506402: val_loss 0.0389\n","2025-05-07 18:52:40.508753: Pseudo dice [0.7497, 0.7207]\n","2025-05-07 18:52:40.510967: Epoch time: 188.77 s\n","2025-05-07 18:52:41.889537: \n","2025-05-07 18:52:41.892376: Epoch 129\n","2025-05-07 18:52:41.894469: Current learning rate: 0.00603\n","2025-05-07 18:55:50.092872: train_loss 0.036\n","2025-05-07 18:55:50.096371: val_loss 0.0388\n","2025-05-07 18:55:50.099180: Pseudo dice [0.7416, 0.7335]\n","2025-05-07 18:55:50.101618: Epoch time: 188.2 s\n","2025-05-07 18:55:51.713517: \n","2025-05-07 18:55:51.716267: Epoch 130\n","2025-05-07 18:55:51.718442: Current learning rate: 0.006\n","2025-05-07 18:58:59.864607: train_loss 0.0368\n","2025-05-07 18:58:59.868304: val_loss 0.0385\n","2025-05-07 18:58:59.871067: Pseudo dice [0.7496, 0.7297]\n","2025-05-07 18:58:59.873780: Epoch time: 188.15 s\n","2025-05-07 18:58:59.876098: Yayy! New best EMA pseudo Dice: 0.7321\n","2025-05-07 18:59:02.172731: \n","2025-05-07 18:59:02.175694: Epoch 131\n","2025-05-07 18:59:02.178108: Current learning rate: 0.00597\n","2025-05-07 19:02:10.253760: train_loss 0.0363\n","2025-05-07 19:02:10.258602: val_loss 0.0371\n","2025-05-07 19:02:10.260928: Pseudo dice [0.7585, 0.7347]\n","2025-05-07 19:02:10.263161: Epoch time: 188.08 s\n","2025-05-07 19:02:10.265260: Yayy! New best EMA pseudo Dice: 0.7336\n","2025-05-07 19:02:12.651947: \n","2025-05-07 19:02:12.667655: Epoch 132\n","2025-05-07 19:02:12.671229: Current learning rate: 0.00593\n","2025-05-07 19:05:21.061937: train_loss 0.0373\n","2025-05-07 19:05:21.068503: val_loss 0.0369\n","2025-05-07 19:05:21.070688: Pseudo dice [0.7312, 0.7378]\n","2025-05-07 19:05:21.072720: Epoch time: 188.41 s\n","2025-05-07 19:05:21.074709: Yayy! New best EMA pseudo Dice: 0.7337\n","2025-05-07 19:05:23.335466: \n","2025-05-07 19:05:23.338791: Epoch 133\n","2025-05-07 19:05:23.341483: Current learning rate: 0.0059\n","2025-05-07 19:08:31.737256: train_loss 0.0337\n","2025-05-07 19:08:31.745086: val_loss 0.0379\n","2025-05-07 19:08:31.748510: Pseudo dice [0.7579, 0.7177]\n","2025-05-07 19:08:31.751676: Epoch time: 188.4 s\n","2025-05-07 19:08:31.754318: Yayy! New best EMA pseudo Dice: 0.7341\n","2025-05-07 19:08:34.146092: \n","2025-05-07 19:08:34.149004: Epoch 134\n","2025-05-07 19:08:34.151329: Current learning rate: 0.00587\n","2025-05-07 19:11:42.696744: train_loss 0.036\n","2025-05-07 19:11:42.709772: val_loss 0.0343\n","2025-05-07 19:11:42.712086: Pseudo dice [0.735, 0.7327]\n","2025-05-07 19:11:42.714232: Epoch time: 188.55 s\n","2025-05-07 19:11:44.130672: \n","2025-05-07 19:11:44.133673: Epoch 135\n","2025-05-07 19:11:44.135911: Current learning rate: 0.00584\n","2025-05-07 19:14:52.235184: train_loss 0.0343\n","2025-05-07 19:14:52.238787: val_loss 0.0377\n","2025-05-07 19:14:52.240758: Pseudo dice [0.7577, 0.7306]\n","2025-05-07 19:14:52.242631: Epoch time: 188.11 s\n","2025-05-07 19:14:52.244488: Yayy! New best EMA pseudo Dice: 0.7351\n","2025-05-07 19:14:54.576093: \n","2025-05-07 19:14:54.579021: Epoch 136\n","2025-05-07 19:14:54.581618: Current learning rate: 0.00581\n","2025-05-07 19:18:02.785890: train_loss 0.0383\n","2025-05-07 19:18:02.789730: val_loss 0.043\n","2025-05-07 19:18:02.791775: Pseudo dice [0.7303, 0.7318]\n","2025-05-07 19:18:02.793717: Epoch time: 188.21 s\n","2025-05-07 19:18:04.364671: \n","2025-05-07 19:18:04.367421: Epoch 137\n","2025-05-07 19:18:04.369649: Current learning rate: 0.00578\n","2025-05-07 19:21:12.709469: train_loss 0.035\n","2025-05-07 19:21:12.714019: val_loss 0.0365\n","2025-05-07 19:21:12.716851: Pseudo dice [0.7693, 0.7292]\n","2025-05-07 19:21:12.720585: Epoch time: 188.35 s\n","2025-05-07 19:21:12.724463: Yayy! New best EMA pseudo Dice: 0.7361\n","2025-05-07 19:21:15.196012: \n","2025-05-07 19:21:15.198722: Epoch 138\n","2025-05-07 19:21:15.200738: Current learning rate: 0.00574\n","2025-05-07 19:24:23.574987: train_loss 0.0356\n","2025-05-07 19:24:23.578611: val_loss 0.0397\n","2025-05-07 19:24:23.580592: Pseudo dice [0.7148, 0.7416]\n","2025-05-07 19:24:23.582884: Epoch time: 188.38 s\n","2025-05-07 19:24:25.156983: \n","2025-05-07 19:24:25.159880: Epoch 139\n","2025-05-07 19:24:25.161941: Current learning rate: 0.00571\n","2025-05-07 19:27:33.238935: train_loss 0.0332\n","2025-05-07 19:27:33.253397: val_loss 0.0372\n","2025-05-07 19:27:33.255569: Pseudo dice [0.7521, 0.7505]\n","2025-05-07 19:27:33.257542: Epoch time: 188.08 s\n","2025-05-07 19:27:33.259843: Yayy! New best EMA pseudo Dice: 0.7369\n","2025-05-07 19:27:35.641233: \n","2025-05-07 19:27:35.644512: Epoch 140\n","2025-05-07 19:27:35.647014: Current learning rate: 0.00568\n","2025-05-07 19:30:43.899135: train_loss 0.0369\n","2025-05-07 19:30:43.918824: val_loss 0.0401\n","2025-05-07 19:30:43.920976: Pseudo dice [0.7452, 0.7373]\n","2025-05-07 19:30:43.922966: Epoch time: 188.26 s\n","2025-05-07 19:30:43.925023: Yayy! New best EMA pseudo Dice: 0.7374\n","2025-05-07 19:30:46.302171: \n","2025-05-07 19:30:46.305566: Epoch 141\n","2025-05-07 19:30:46.308298: Current learning rate: 0.00565\n","2025-05-07 19:33:54.495449: train_loss 0.0361\n","2025-05-07 19:33:54.504856: val_loss 0.0378\n","2025-05-07 19:33:54.507121: Pseudo dice [0.7617, 0.7285]\n","2025-05-07 19:33:54.509223: Epoch time: 188.19 s\n","2025-05-07 19:33:54.511409: Yayy! New best EMA pseudo Dice: 0.7381\n","2025-05-07 19:33:56.986552: \n","2025-05-07 19:33:56.989802: Epoch 142\n","2025-05-07 19:33:56.992528: Current learning rate: 0.00562\n","2025-05-07 19:37:05.054647: train_loss 0.0363\n","2025-05-07 19:37:05.063855: val_loss 0.0387\n","2025-05-07 19:37:05.065949: Pseudo dice [0.7817, 0.7457]\n","2025-05-07 19:37:05.067838: Epoch time: 188.07 s\n","2025-05-07 19:37:05.069734: Yayy! New best EMA pseudo Dice: 0.7407\n","2025-05-07 19:37:07.847512: \n","2025-05-07 19:37:07.850646: Epoch 143\n","2025-05-07 19:37:07.852803: Current learning rate: 0.00558\n","2025-05-07 19:40:16.320277: train_loss 0.0352\n","2025-05-07 19:40:16.329680: val_loss 0.0377\n","2025-05-07 19:40:16.331761: Pseudo dice [0.7487, 0.7289]\n","2025-05-07 19:40:16.333726: Epoch time: 188.47 s\n","2025-05-07 19:40:17.949617: \n","2025-05-07 19:40:17.952331: Epoch 144\n","2025-05-07 19:40:17.955496: Current learning rate: 0.00555\n","2025-05-07 19:43:26.464383: train_loss 0.0348\n","2025-05-07 19:43:26.468879: val_loss 0.0425\n","2025-05-07 19:43:26.473036: Pseudo dice [0.7716, 0.7275]\n","2025-05-07 19:43:26.476943: Epoch time: 188.52 s\n","2025-05-07 19:43:26.480490: Yayy! New best EMA pseudo Dice: 0.7414\n","2025-05-07 19:43:28.937784: \n","2025-05-07 19:43:28.940749: Epoch 145\n","2025-05-07 19:43:28.942900: Current learning rate: 0.00552\n","2025-05-07 19:46:37.521529: train_loss 0.0349\n","2025-05-07 19:46:37.531164: val_loss 0.0381\n","2025-05-07 19:46:37.533449: Pseudo dice [0.7417, 0.7221]\n","2025-05-07 19:46:37.535585: Epoch time: 188.59 s\n","2025-05-07 19:46:38.895956: \n","2025-05-07 19:46:38.913518: Epoch 146\n","2025-05-07 19:46:38.915672: Current learning rate: 0.00549\n","2025-05-07 19:49:47.376001: train_loss 0.0363\n","2025-05-07 19:49:47.380390: val_loss 0.0366\n","2025-05-07 19:49:47.383269: Pseudo dice [0.7485, 0.7078]\n","2025-05-07 19:49:47.385860: Epoch time: 188.48 s\n","2025-05-07 19:49:49.103822: \n","2025-05-07 19:49:49.106524: Epoch 147\n","2025-05-07 19:49:49.109207: Current learning rate: 0.00546\n","2025-05-07 19:52:57.466502: train_loss 0.0353\n","2025-05-07 19:52:57.470456: val_loss 0.0366\n","2025-05-07 19:52:57.474703: Pseudo dice [0.7776, 0.72]\n","2025-05-07 19:52:57.478574: Epoch time: 188.36 s\n","2025-05-07 19:52:59.760415: \n","2025-05-07 19:52:59.763754: Epoch 148\n","2025-05-07 19:52:59.767175: Current learning rate: 0.00542\n","2025-05-07 19:56:08.243220: train_loss 0.0346\n","2025-05-07 19:56:08.252848: val_loss 0.0413\n","2025-05-07 19:56:08.256218: Pseudo dice [0.7556, 0.7241]\n","2025-05-07 19:56:08.258989: Epoch time: 188.48 s\n","2025-05-07 19:56:11.177744: \n","2025-05-07 19:56:11.180455: Epoch 149\n","2025-05-07 19:56:11.182535: Current learning rate: 0.00539\n","2025-05-07 19:59:20.159898: train_loss 0.0364\n","2025-05-07 19:59:20.164428: val_loss 0.0394\n","2025-05-07 19:59:20.166688: Pseudo dice [0.7616, 0.7315]\n","2025-05-07 19:59:20.168730: Epoch time: 188.98 s\n","2025-05-07 19:59:22.527210: \n","2025-05-07 19:59:22.529950: Epoch 150\n","2025-05-07 19:59:22.532147: Current learning rate: 0.00536\n","2025-05-07 20:02:30.854628: train_loss 0.0365\n","2025-05-07 20:02:30.859879: val_loss 0.0386\n","2025-05-07 20:02:30.862331: Pseudo dice [0.7465, 0.7181]\n","2025-05-07 20:02:30.864428: Epoch time: 188.33 s\n","2025-05-07 20:02:32.618894: \n","2025-05-07 20:02:32.621634: Epoch 151\n","2025-05-07 20:02:32.623774: Current learning rate: 0.00533\n","2025-05-07 20:05:41.114235: train_loss 0.0349\n","2025-05-07 20:05:41.120472: val_loss 0.0388\n","2025-05-07 20:05:41.122841: Pseudo dice [0.7278, 0.7327]\n","2025-05-07 20:05:41.125990: Epoch time: 188.5 s\n","2025-05-07 20:05:42.960402: \n","2025-05-07 20:05:42.963076: Epoch 152\n","2025-05-07 20:05:42.965096: Current learning rate: 0.00529\n","2025-05-07 20:08:51.264849: train_loss 0.0345\n","2025-05-07 20:08:51.268727: val_loss 0.0371\n","2025-05-07 20:08:51.270831: Pseudo dice [0.7495, 0.7225]\n","2025-05-07 20:08:51.272768: Epoch time: 188.31 s\n","2025-05-07 20:08:52.856136: \n","2025-05-07 20:08:52.858812: Epoch 153\n","2025-05-07 20:08:52.860791: Current learning rate: 0.00526\n","2025-05-07 20:12:00.977318: train_loss 0.0334\n","2025-05-07 20:12:00.982843: val_loss 0.0368\n","2025-05-07 20:12:00.986079: Pseudo dice [0.766, 0.7057]\n","2025-05-07 20:12:00.989429: Epoch time: 188.12 s\n","2025-05-07 20:12:02.765983: \n","2025-05-07 20:12:02.783163: Epoch 154\n","2025-05-07 20:12:02.785552: Current learning rate: 0.00523\n","2025-05-07 20:15:11.048969: train_loss 0.0327\n","2025-05-07 20:15:11.055519: val_loss 0.0389\n","2025-05-07 20:15:11.057840: Pseudo dice [0.7495, 0.7405]\n","2025-05-07 20:15:11.060101: Epoch time: 188.28 s\n","2025-05-07 20:15:12.670309: \n","2025-05-07 20:15:12.673054: Epoch 155\n","2025-05-07 20:15:12.675089: Current learning rate: 0.0052\n","2025-05-07 20:18:21.124067: train_loss 0.035\n","2025-05-07 20:18:21.128597: val_loss 0.0415\n","2025-05-07 20:18:21.131356: Pseudo dice [0.7472, 0.7223]\n","2025-05-07 20:18:21.134413: Epoch time: 188.45 s\n","2025-05-07 20:18:22.921000: \n","2025-05-07 20:18:22.923694: Epoch 156\n","2025-05-07 20:18:22.925990: Current learning rate: 0.00517\n","2025-05-07 20:21:31.424789: train_loss 0.0369\n","2025-05-07 20:21:31.428440: val_loss 0.0374\n","2025-05-07 20:21:31.430638: Pseudo dice [0.7826, 0.7371]\n","2025-05-07 20:21:31.432696: Epoch time: 188.5 s\n","2025-05-07 20:21:33.020618: \n","2025-05-07 20:21:33.023776: Epoch 157\n","2025-05-07 20:21:33.025937: Current learning rate: 0.00513\n","2025-05-07 20:24:41.401767: train_loss 0.0343\n","2025-05-07 20:24:41.409800: val_loss 0.0391\n","2025-05-07 20:24:41.413246: Pseudo dice [0.7499, 0.7266]\n","2025-05-07 20:24:41.416572: Epoch time: 188.38 s\n","2025-05-07 20:24:43.217412: \n","2025-05-07 20:24:43.234235: Epoch 158\n","2025-05-07 20:24:43.236188: Current learning rate: 0.0051\n","2025-05-07 20:27:51.700720: train_loss 0.0346\n","2025-05-07 20:27:51.708461: val_loss 0.0375\n","2025-05-07 20:27:51.713826: Pseudo dice [0.7333, 0.7123]\n","2025-05-07 20:27:51.717209: Epoch time: 188.48 s\n","2025-05-07 20:27:53.353235: \n","2025-05-07 20:27:53.355871: Epoch 159\n","2025-05-07 20:27:53.357936: Current learning rate: 0.00507\n","2025-05-07 20:31:01.711120: train_loss 0.033\n","2025-05-07 20:31:01.715862: val_loss 0.0365\n","2025-05-07 20:31:01.718652: Pseudo dice [0.7646, 0.7464]\n","2025-05-07 20:31:01.720902: Epoch time: 188.36 s\n","2025-05-07 20:31:03.341923: \n","2025-05-07 20:31:03.344707: Epoch 160\n","2025-05-07 20:31:03.346923: Current learning rate: 0.00504\n","2025-05-07 20:34:11.930375: train_loss 0.0335\n","2025-05-07 20:34:11.933942: val_loss 0.0338\n","2025-05-07 20:34:11.936127: Pseudo dice [0.7589, 0.7201]\n","2025-05-07 20:34:11.938119: Epoch time: 188.59 s\n","2025-05-07 20:34:13.506603: \n","2025-05-07 20:34:13.509440: Epoch 161\n","2025-05-07 20:34:13.511780: Current learning rate: 0.005\n","2025-05-07 20:37:22.446666: train_loss 0.0353\n","2025-05-07 20:37:22.450811: val_loss 0.0361\n","2025-05-07 20:37:22.454146: Pseudo dice [0.793, 0.7336]\n","2025-05-07 20:37:22.457270: Epoch time: 188.94 s\n","2025-05-07 20:37:22.460177: Yayy! New best EMA pseudo Dice: 0.7426\n","2025-05-07 20:37:25.000220: \n","2025-05-07 20:37:25.002944: Epoch 162\n","2025-05-07 20:37:25.005321: Current learning rate: 0.00497\n","2025-05-07 20:40:33.659204: train_loss 0.0349\n","2025-05-07 20:40:33.669518: val_loss 0.0346\n","2025-05-07 20:40:33.671927: Pseudo dice [0.7681, 0.7147]\n","2025-05-07 20:40:33.674592: Epoch time: 188.66 s\n","2025-05-07 20:40:35.291531: \n","2025-05-07 20:40:35.294228: Epoch 163\n","2025-05-07 20:40:35.296485: Current learning rate: 0.00494\n","2025-05-07 20:43:43.651417: train_loss 0.0333\n","2025-05-07 20:43:43.655079: val_loss 0.0372\n","2025-05-07 20:43:43.673179: Pseudo dice [0.7565, 0.7213]\n","2025-05-07 20:43:43.675451: Epoch time: 188.36 s\n","2025-05-07 20:43:45.264673: \n","2025-05-07 20:43:45.267286: Epoch 164\n","2025-05-07 20:43:45.269290: Current learning rate: 0.00491\n","2025-05-07 20:46:53.928643: train_loss 0.0315\n","2025-05-07 20:46:53.933138: val_loss 0.0391\n","2025-05-07 20:46:53.936511: Pseudo dice [0.7431, 0.7193]\n","2025-05-07 20:46:53.940238: Epoch time: 188.66 s\n","2025-05-07 20:46:55.543034: \n","2025-05-07 20:46:55.546709: Epoch 165\n","2025-05-07 20:46:55.548796: Current learning rate: 0.00487\n","2025-05-07 20:50:03.951575: train_loss 0.0336\n","2025-05-07 20:50:03.955406: val_loss 0.0376\n","2025-05-07 20:50:03.958059: Pseudo dice [0.7648, 0.7463]\n","2025-05-07 20:50:03.961096: Epoch time: 188.41 s\n","2025-05-07 20:50:05.528164: \n","2025-05-07 20:50:05.531232: Epoch 166\n","2025-05-07 20:50:05.533979: Current learning rate: 0.00484\n","2025-05-07 20:53:14.049464: train_loss 0.0349\n","2025-05-07 20:53:14.060155: val_loss 0.0378\n","2025-05-07 20:53:14.062246: Pseudo dice [0.7394, 0.7479]\n","2025-05-07 20:53:14.064220: Epoch time: 188.52 s\n","2025-05-07 20:53:15.420224: \n","2025-05-07 20:53:15.423023: Epoch 167\n","2025-05-07 20:53:15.438187: Current learning rate: 0.00481\n","2025-05-07 20:56:24.160226: train_loss 0.0308\n","2025-05-07 20:56:24.164035: val_loss 0.0386\n","2025-05-07 20:56:24.166261: Pseudo dice [0.7501, 0.7229]\n","2025-05-07 20:56:24.168390: Epoch time: 188.74 s\n","2025-05-07 20:56:25.779654: \n","2025-05-07 20:56:25.782610: Epoch 168\n","2025-05-07 20:56:25.784861: Current learning rate: 0.00478\n","2025-05-07 20:59:34.514363: train_loss 0.0332\n","2025-05-07 20:59:34.518203: val_loss 0.0374\n","2025-05-07 20:59:34.520344: Pseudo dice [0.7555, 0.7464]\n","2025-05-07 20:59:34.522434: Epoch time: 188.74 s\n","2025-05-07 20:59:34.524237: Yayy! New best EMA pseudo Dice: 0.7429\n","2025-05-07 20:59:36.868987: \n","2025-05-07 20:59:36.871777: Epoch 169\n","2025-05-07 20:59:36.874041: Current learning rate: 0.00474\n","2025-05-07 21:02:45.259178: train_loss 0.0342\n","2025-05-07 21:02:45.270204: val_loss 0.0374\n","2025-05-07 21:02:45.273666: Pseudo dice [0.7566, 0.7308]\n","2025-05-07 21:02:45.276852: Epoch time: 188.39 s\n","2025-05-07 21:02:45.279806: Yayy! New best EMA pseudo Dice: 0.743\n","2025-05-07 21:02:47.718192: \n","2025-05-07 21:02:47.720930: Epoch 170\n","2025-05-07 21:02:47.723073: Current learning rate: 0.00471\n","2025-05-07 21:05:55.991710: train_loss 0.0326\n","2025-05-07 21:05:55.996872: val_loss 0.037\n","2025-05-07 21:05:55.998982: Pseudo dice [0.7667, 0.7237]\n","2025-05-07 21:05:56.001319: Epoch time: 188.27 s\n","2025-05-07 21:05:56.004023: Yayy! New best EMA pseudo Dice: 0.7432\n","2025-05-07 21:05:58.474518: \n","2025-05-07 21:05:58.477412: Epoch 171\n","2025-05-07 21:05:58.479491: Current learning rate: 0.00468\n","2025-05-07 21:09:06.815415: train_loss 0.033\n","2025-05-07 21:09:06.824110: val_loss 0.0417\n","2025-05-07 21:09:06.826407: Pseudo dice [0.745, 0.7286]\n","2025-05-07 21:09:06.844568: Epoch time: 188.34 s\n","2025-05-07 21:09:08.501308: \n","2025-05-07 21:09:08.503974: Epoch 172\n","2025-05-07 21:09:08.506394: Current learning rate: 0.00465\n","2025-05-07 21:12:16.751802: train_loss 0.035\n","2025-05-07 21:12:16.761318: val_loss 0.0382\n","2025-05-07 21:12:16.765107: Pseudo dice [0.784, 0.7327]\n","2025-05-07 21:12:16.768752: Epoch time: 188.25 s\n","2025-05-07 21:12:16.786291: Yayy! New best EMA pseudo Dice: 0.7441\n","2025-05-07 21:12:20.509855: \n","2025-05-07 21:12:20.513384: Epoch 173\n","2025-05-07 21:12:20.515836: Current learning rate: 0.00461\n","2025-05-07 21:15:28.977990: train_loss 0.0344\n","2025-05-07 21:15:28.984440: val_loss 0.0372\n","2025-05-07 21:15:28.986496: Pseudo dice [0.7636, 0.735]\n","2025-05-07 21:15:28.988783: Epoch time: 188.47 s\n","2025-05-07 21:15:28.992133: Yayy! New best EMA pseudo Dice: 0.7447\n","2025-05-07 21:15:31.496355: \n","2025-05-07 21:15:31.499122: Epoch 174\n","2025-05-07 21:15:31.501143: Current learning rate: 0.00458\n","2025-05-07 21:18:39.680140: train_loss 0.0328\n","2025-05-07 21:18:39.687921: val_loss 0.0343\n","2025-05-07 21:18:39.690006: Pseudo dice [0.7728, 0.7573]\n","2025-05-07 21:18:39.691989: Epoch time: 188.18 s\n","2025-05-07 21:18:39.693894: Yayy! New best EMA pseudo Dice: 0.7467\n","2025-05-07 21:18:41.871464: \n","2025-05-07 21:18:41.874434: Epoch 175\n","2025-05-07 21:18:41.876657: Current learning rate: 0.00455\n","2025-05-07 21:21:49.991645: train_loss 0.0315\n","2025-05-07 21:21:49.997319: val_loss 0.038\n","2025-05-07 21:21:49.999853: Pseudo dice [0.7712, 0.733]\n","2025-05-07 21:21:50.002619: Epoch time: 188.12 s\n","2025-05-07 21:21:50.019846: Yayy! New best EMA pseudo Dice: 0.7472\n","2025-05-07 21:21:52.187820: \n","2025-05-07 21:21:52.191100: Epoch 176\n","2025-05-07 21:21:52.193734: Current learning rate: 0.00452\n","2025-05-07 21:25:00.362244: train_loss 0.033\n","2025-05-07 21:25:00.366114: val_loss 0.0369\n","2025-05-07 21:25:00.368245: Pseudo dice [0.7319, 0.7246]\n","2025-05-07 21:25:00.370265: Epoch time: 188.18 s\n","2025-05-07 21:25:01.771606: \n","2025-05-07 21:25:01.774535: Epoch 177\n","2025-05-07 21:25:01.776989: Current learning rate: 0.00448\n","2025-05-07 21:28:10.378811: train_loss 0.0312\n","2025-05-07 21:28:10.382526: val_loss 0.0347\n","2025-05-07 21:28:10.384842: Pseudo dice [0.7433, 0.7327]\n","2025-05-07 21:28:10.387239: Epoch time: 188.61 s\n","2025-05-07 21:28:11.785325: \n","2025-05-07 21:28:11.787959: Epoch 178\n","2025-05-07 21:28:11.790020: Current learning rate: 0.00445\n","2025-05-07 21:31:20.620975: train_loss 0.0326\n","2025-05-07 21:31:20.624942: val_loss 0.0383\n","2025-05-07 21:31:20.627424: Pseudo dice [0.7506, 0.7335]\n","2025-05-07 21:31:20.629796: Epoch time: 188.84 s\n","2025-05-07 21:31:22.042693: \n","2025-05-07 21:31:22.045730: Epoch 179\n","2025-05-07 21:31:22.048837: Current learning rate: 0.00442\n","2025-05-07 21:34:30.766348: train_loss 0.0347\n","2025-05-07 21:34:30.769783: val_loss 0.0352\n","2025-05-07 21:34:30.771901: Pseudo dice [0.7946, 0.7413]\n","2025-05-07 21:34:30.774154: Epoch time: 188.72 s\n","2025-05-07 21:34:32.173564: \n","2025-05-07 21:34:32.176345: Epoch 180\n","2025-05-07 21:34:32.178720: Current learning rate: 0.00438\n","2025-05-07 21:37:40.424911: train_loss 0.0332\n","2025-05-07 21:37:40.436920: val_loss 0.0355\n","2025-05-07 21:37:40.438978: Pseudo dice [0.7497, 0.721]\n","2025-05-07 21:37:40.441855: Epoch time: 188.25 s\n","2025-05-07 21:37:42.174551: \n","2025-05-07 21:37:42.177329: Epoch 181\n","2025-05-07 21:37:42.180007: Current learning rate: 0.00435\n","2025-05-07 21:40:50.474855: train_loss 0.0338\n","2025-05-07 21:40:50.480659: val_loss 0.0358\n","2025-05-07 21:40:50.482920: Pseudo dice [0.7579, 0.7186]\n","2025-05-07 21:40:50.486832: Epoch time: 188.3 s\n","2025-05-07 21:40:51.916324: \n","2025-05-07 21:40:51.919102: Epoch 182\n","2025-05-07 21:40:51.921152: Current learning rate: 0.00432\n","2025-05-07 21:44:00.571203: train_loss 0.0342\n","2025-05-07 21:44:00.574963: val_loss 0.0363\n","2025-05-07 21:44:00.577393: Pseudo dice [0.7693, 0.7341]\n","2025-05-07 21:44:00.579456: Epoch time: 188.66 s\n","2025-05-07 21:44:02.016469: \n","2025-05-07 21:44:02.019167: Epoch 183\n","2025-05-07 21:44:02.021217: Current learning rate: 0.00429\n","2025-05-07 21:47:10.819589: train_loss 0.0321\n","2025-05-07 21:47:10.824670: val_loss 0.0408\n","2025-05-07 21:47:10.827163: Pseudo dice [0.7521, 0.7298]\n","2025-05-07 21:47:10.829480: Epoch time: 188.8 s\n","2025-05-07 21:47:12.279631: \n","2025-05-07 21:47:12.282442: Epoch 184\n","2025-05-07 21:47:12.284487: Current learning rate: 0.00425\n","2025-05-07 21:50:20.628395: train_loss 0.0327\n","2025-05-07 21:50:20.633242: val_loss 0.0368\n","2025-05-07 21:50:20.635707: Pseudo dice [0.7791, 0.7542]\n","2025-05-07 21:50:20.638220: Epoch time: 188.35 s\n","2025-05-07 21:50:22.086473: \n","2025-05-07 21:50:22.089467: Epoch 185\n","2025-05-07 21:50:22.091820: Current learning rate: 0.00422\n","2025-05-07 21:53:30.233731: train_loss 0.0323\n","2025-05-07 21:53:30.237595: val_loss 0.0353\n","2025-05-07 21:53:30.240373: Pseudo dice [0.754, 0.7323]\n","2025-05-07 21:53:30.243948: Epoch time: 188.15 s\n","2025-05-07 21:53:31.687222: \n","2025-05-07 21:53:31.690549: Epoch 186\n","2025-05-07 21:53:31.693413: Current learning rate: 0.00419\n","2025-05-07 21:56:39.924411: train_loss 0.033\n","2025-05-07 21:56:39.929059: val_loss 0.0324\n","2025-05-07 21:56:39.931296: Pseudo dice [0.7471, 0.7158]\n","2025-05-07 21:56:39.933366: Epoch time: 188.24 s\n","2025-05-07 21:56:41.333083: \n","2025-05-07 21:56:41.335802: Epoch 187\n","2025-05-07 21:56:41.337955: Current learning rate: 0.00415\n","2025-05-07 21:59:49.514517: train_loss 0.0339\n","2025-05-07 21:59:49.520377: val_loss 0.0389\n","2025-05-07 21:59:49.522758: Pseudo dice [0.7368, 0.7419]\n","2025-05-07 21:59:49.525338: Epoch time: 188.18 s\n","2025-05-07 21:59:50.928696: \n","2025-05-07 21:59:50.931322: Epoch 188\n","2025-05-07 21:59:50.933244: Current learning rate: 0.00412\n","2025-05-07 22:02:59.072369: train_loss 0.0342\n","2025-05-07 22:02:59.080529: val_loss 0.0394\n","2025-05-07 22:02:59.082585: Pseudo dice [0.7485, 0.7225]\n","2025-05-07 22:02:59.085300: Epoch time: 188.14 s\n","2025-05-07 22:03:00.513906: \n","2025-05-07 22:03:00.516700: Epoch 189\n","2025-05-07 22:03:00.518752: Current learning rate: 0.00409\n","2025-05-07 22:06:08.854249: train_loss 0.0332\n","2025-05-07 22:06:08.858161: val_loss 0.038\n","2025-05-07 22:06:08.861372: Pseudo dice [0.7572, 0.7459]\n","2025-05-07 22:06:08.864337: Epoch time: 188.34 s\n","2025-05-07 22:06:10.268928: \n","2025-05-07 22:06:10.271881: Epoch 190\n","2025-05-07 22:06:10.274187: Current learning rate: 0.00405\n","2025-05-07 22:09:18.747162: train_loss 0.0327\n","2025-05-07 22:09:18.750774: val_loss 0.0395\n","2025-05-07 22:09:18.753037: Pseudo dice [0.7589, 0.7444]\n","2025-05-07 22:09:18.755098: Epoch time: 188.48 s\n","2025-05-07 22:09:20.150984: \n","2025-05-07 22:09:20.153712: Epoch 191\n","2025-05-07 22:09:20.156604: Current learning rate: 0.00402\n","2025-05-07 22:12:28.317987: train_loss 0.0323\n","2025-05-07 22:12:28.321715: val_loss 0.0361\n","2025-05-07 22:12:28.324534: Pseudo dice [0.7811, 0.7478]\n","2025-05-07 22:12:28.326650: Epoch time: 188.17 s\n","2025-05-07 22:12:29.718644: \n","2025-05-07 22:12:29.721334: Epoch 192\n","2025-05-07 22:12:29.723330: Current learning rate: 0.00399\n","2025-05-07 22:15:38.272082: train_loss 0.0329\n","2025-05-07 22:15:38.277399: val_loss 0.0401\n","2025-05-07 22:15:38.279547: Pseudo dice [0.7653, 0.7459]\n","2025-05-07 22:15:38.281623: Epoch time: 188.55 s\n","2025-05-07 22:15:38.283548: Yayy! New best EMA pseudo Dice: 0.748\n","2025-05-07 22:15:40.542576: \n","2025-05-07 22:15:40.545516: Epoch 193\n","2025-05-07 22:15:40.547768: Current learning rate: 0.00395\n","2025-05-07 22:18:48.937313: train_loss 0.0329\n","2025-05-07 22:18:48.944507: val_loss 0.0355\n","2025-05-07 22:18:48.946850: Pseudo dice [0.7781, 0.749]\n","2025-05-07 22:18:48.949083: Epoch time: 188.4 s\n","2025-05-07 22:18:48.951207: Yayy! New best EMA pseudo Dice: 0.7496\n","2025-05-07 22:18:51.194598: \n","2025-05-07 22:18:51.197372: Epoch 194\n","2025-05-07 22:18:51.199404: Current learning rate: 0.00392\n","2025-05-07 22:21:59.801509: train_loss 0.0342\n","2025-05-07 22:21:59.830901: val_loss 0.0384\n","2025-05-07 22:21:59.833403: Pseudo dice [0.7534, 0.7264]\n","2025-05-07 22:21:59.836354: Epoch time: 188.61 s\n","2025-05-07 22:22:01.253713: \n","2025-05-07 22:22:01.256722: Epoch 195\n","2025-05-07 22:22:01.258999: Current learning rate: 0.00389\n","2025-05-07 22:25:10.145503: train_loss 0.0312\n","2025-05-07 22:25:10.151468: val_loss 0.034\n","2025-05-07 22:25:10.153670: Pseudo dice [0.7672, 0.733]\n","2025-05-07 22:25:10.155504: Epoch time: 188.89 s\n","2025-05-07 22:25:11.579923: \n","2025-05-07 22:25:11.582860: Epoch 196\n","2025-05-07 22:25:11.585179: Current learning rate: 0.00385\n","2025-05-07 22:28:20.245946: train_loss 0.0311\n","2025-05-07 22:28:20.250449: val_loss 0.0372\n","2025-05-07 22:28:20.252578: Pseudo dice [0.7897, 0.7424]\n","2025-05-07 22:28:20.254601: Epoch time: 188.67 s\n","2025-05-07 22:28:20.256571: Yayy! New best EMA pseudo Dice: 0.7505\n","2025-05-07 22:28:23.799022: \n","2025-05-07 22:28:23.802203: Epoch 197\n","2025-05-07 22:28:23.804815: Current learning rate: 0.00382\n","2025-05-07 22:31:32.327188: train_loss 0.0333\n","2025-05-07 22:31:32.332149: val_loss 0.0346\n","2025-05-07 22:31:32.334477: Pseudo dice [0.7566, 0.7436]\n","2025-05-07 22:31:32.336536: Epoch time: 188.53 s\n","2025-05-07 22:31:33.751473: \n","2025-05-07 22:31:33.754080: Epoch 198\n","2025-05-07 22:31:33.756134: Current learning rate: 0.00379\n","2025-05-07 22:34:42.817797: train_loss 0.0324\n","2025-05-07 22:34:42.822190: val_loss 0.0333\n","2025-05-07 22:34:42.824917: Pseudo dice [0.7636, 0.7123]\n","2025-05-07 22:34:42.826966: Epoch time: 189.07 s\n","2025-05-07 22:34:44.252609: \n","2025-05-07 22:34:44.256144: Epoch 199\n","2025-05-07 22:34:44.258781: Current learning rate: 0.00375\n","2025-05-07 22:37:52.966653: train_loss 0.0327\n","2025-05-07 22:37:52.970238: val_loss 0.0349\n","2025-05-07 22:37:52.972250: Pseudo dice [0.7453, 0.7254]\n","2025-05-07 22:37:52.974170: Epoch time: 188.72 s\n","2025-05-07 22:37:55.487844: \n","2025-05-07 22:37:55.490923: Epoch 200\n","2025-05-07 22:37:55.492957: Current learning rate: 0.00372\n","2025-05-07 22:41:04.547630: train_loss 0.0324\n","2025-05-07 22:41:04.555589: val_loss 0.0372\n","2025-05-07 22:41:04.558690: Pseudo dice [0.7769, 0.7376]\n","2025-05-07 22:41:04.561766: Epoch time: 189.06 s\n","2025-05-07 22:41:05.985062: \n","2025-05-07 22:41:05.988343: Epoch 201\n","2025-05-07 22:41:05.990920: Current learning rate: 0.00369\n","2025-05-07 22:44:14.429878: train_loss 0.0326\n","2025-05-07 22:44:14.435275: val_loss 0.036\n","2025-05-07 22:44:14.437723: Pseudo dice [0.774, 0.7419]\n","2025-05-07 22:44:14.440202: Epoch time: 188.45 s\n","2025-05-07 22:44:16.157431: \n","2025-05-07 22:44:16.160220: Epoch 202\n","2025-05-07 22:44:16.162598: Current learning rate: 0.00365\n","2025-05-07 22:47:24.811697: train_loss 0.0317\n","2025-05-07 22:47:24.815240: val_loss 0.0359\n","2025-05-07 22:47:24.817296: Pseudo dice [0.7768, 0.7567]\n","2025-05-07 22:47:24.819206: Epoch time: 188.66 s\n","2025-05-07 22:47:24.821158: Yayy! New best EMA pseudo Dice: 0.7514\n","2025-05-07 22:47:26.997852: \n","2025-05-07 22:47:27.000708: Epoch 203\n","2025-05-07 22:47:27.002923: Current learning rate: 0.00362\n","2025-05-07 22:50:35.495085: train_loss 0.0311\n","2025-05-07 22:50:35.503452: val_loss 0.0376\n","2025-05-07 22:50:35.505624: Pseudo dice [0.7717, 0.7538]\n","2025-05-07 22:50:35.507728: Epoch time: 188.5 s\n","2025-05-07 22:50:35.509763: Yayy! New best EMA pseudo Dice: 0.7525\n","2025-05-07 22:50:37.886775: \n","2025-05-07 22:50:37.889720: Epoch 204\n","2025-05-07 22:50:37.891887: Current learning rate: 0.00359\n","2025-05-07 22:53:46.424538: train_loss 0.0303\n","2025-05-07 22:53:46.429509: val_loss 0.0377\n","2025-05-07 22:53:46.431882: Pseudo dice [0.7708, 0.7368]\n","2025-05-07 22:53:46.433990: Epoch time: 188.54 s\n","2025-05-07 22:53:46.435965: Yayy! New best EMA pseudo Dice: 0.7526\n","2025-05-07 22:53:48.570592: \n","2025-05-07 22:53:48.573915: Epoch 205\n","2025-05-07 22:53:48.577287: Current learning rate: 0.00355\n","2025-05-07 22:56:57.071769: train_loss 0.0319\n","2025-05-07 22:56:57.075509: val_loss 0.0345\n","2025-05-07 22:56:57.077422: Pseudo dice [0.7731, 0.7366]\n","2025-05-07 22:56:57.079344: Epoch time: 188.5 s\n","2025-05-07 22:56:57.081260: Yayy! New best EMA pseudo Dice: 0.7529\n","2025-05-07 22:56:59.291137: \n","2025-05-07 22:56:59.293893: Epoch 206\n","2025-05-07 22:56:59.296062: Current learning rate: 0.00352\n","2025-05-07 23:00:07.825835: train_loss 0.0333\n","2025-05-07 23:00:07.829660: val_loss 0.0339\n","2025-05-07 23:00:07.832823: Pseudo dice [0.7766, 0.748]\n","2025-05-07 23:00:07.834991: Epoch time: 188.54 s\n","2025-05-07 23:00:07.838068: Yayy! New best EMA pseudo Dice: 0.7538\n","2025-05-07 23:00:10.010332: \n","2025-05-07 23:00:10.013052: Epoch 207\n","2025-05-07 23:00:10.015128: Current learning rate: 0.00349\n","2025-05-07 23:03:18.855736: train_loss 0.0329\n","2025-05-07 23:03:18.859476: val_loss 0.0352\n","2025-05-07 23:03:18.861445: Pseudo dice [0.7701, 0.7458]\n","2025-05-07 23:03:18.863395: Epoch time: 188.85 s\n","2025-05-07 23:03:18.865290: Yayy! New best EMA pseudo Dice: 0.7542\n","2025-05-07 23:03:21.085551: \n","2025-05-07 23:03:21.088590: Epoch 208\n","2025-05-07 23:03:21.090974: Current learning rate: 0.00345\n","2025-05-07 23:06:30.021629: train_loss 0.0297\n","2025-05-07 23:06:30.025494: val_loss 0.0376\n","2025-05-07 23:06:30.028512: Pseudo dice [0.7686, 0.7379]\n","2025-05-07 23:06:30.031374: Epoch time: 188.94 s\n","2025-05-07 23:06:31.437061: \n","2025-05-07 23:06:31.439608: Epoch 209\n","2025-05-07 23:06:31.441538: Current learning rate: 0.00342\n","2025-05-07 23:09:40.314526: train_loss 0.0302\n","2025-05-07 23:09:40.318003: val_loss 0.0384\n","2025-05-07 23:09:40.320073: Pseudo dice [0.7399, 0.7409]\n","2025-05-07 23:09:40.322114: Epoch time: 188.88 s\n","2025-05-07 23:09:41.690401: \n","2025-05-07 23:09:41.693304: Epoch 210\n","2025-05-07 23:09:41.708386: Current learning rate: 0.00338\n","2025-05-07 23:12:49.896848: train_loss 0.0302\n","2025-05-07 23:12:49.900809: val_loss 0.0317\n","2025-05-07 23:12:49.902955: Pseudo dice [0.7888, 0.7619]\n","2025-05-07 23:12:49.904972: Epoch time: 188.21 s\n","2025-05-07 23:12:49.906941: Yayy! New best EMA pseudo Dice: 0.755\n","2025-05-07 23:12:52.045635: \n","2025-05-07 23:12:52.048548: Epoch 211\n","2025-05-07 23:12:52.050617: Current learning rate: 0.00335\n","2025-05-07 23:16:00.578349: train_loss 0.0308\n","2025-05-07 23:16:00.583510: val_loss 0.0368\n","2025-05-07 23:16:00.585735: Pseudo dice [0.7798, 0.7438]\n","2025-05-07 23:16:00.587729: Epoch time: 188.53 s\n","2025-05-07 23:16:00.589649: Yayy! New best EMA pseudo Dice: 0.7557\n","2025-05-07 23:16:02.769998: \n","2025-05-07 23:16:02.772692: Epoch 212\n","2025-05-07 23:16:02.774679: Current learning rate: 0.00332\n","2025-05-07 23:19:11.253220: train_loss 0.0316\n","2025-05-07 23:19:11.261957: val_loss 0.0368\n","2025-05-07 23:19:11.264097: Pseudo dice [0.7445, 0.7127]\n","2025-05-07 23:19:11.266021: Epoch time: 188.48 s\n","2025-05-07 23:19:12.703649: \n","2025-05-07 23:19:12.706566: Epoch 213\n","2025-05-07 23:19:12.708748: Current learning rate: 0.00328\n","2025-05-07 23:22:21.806847: train_loss 0.0319\n","2025-05-07 23:22:21.815527: val_loss 0.0368\n","2025-05-07 23:22:21.817713: Pseudo dice [0.7414, 0.718]\n","2025-05-07 23:22:21.819649: Epoch time: 189.1 s\n","2025-05-07 23:22:23.195603: \n","2025-05-07 23:22:23.198210: Epoch 214\n","2025-05-07 23:22:23.200335: Current learning rate: 0.00325\n","2025-05-07 23:25:31.889868: train_loss 0.0317\n","2025-05-07 23:25:31.893895: val_loss 0.0384\n","2025-05-07 23:25:31.897866: Pseudo dice [0.7573, 0.7381]\n","2025-05-07 23:25:31.901567: Epoch time: 188.7 s\n","2025-05-07 23:25:33.497637: \n","2025-05-07 23:25:33.500879: Epoch 215\n","2025-05-07 23:25:33.503958: Current learning rate: 0.00321\n","2025-05-07 23:28:41.677343: train_loss 0.0316\n","2025-05-07 23:28:41.687111: val_loss 0.0357\n","2025-05-07 23:28:41.689366: Pseudo dice [0.7734, 0.7387]\n","2025-05-07 23:28:41.691460: Epoch time: 188.18 s\n","2025-05-07 23:28:43.120551: \n","2025-05-07 23:28:43.123372: Epoch 216\n","2025-05-07 23:28:43.125620: Current learning rate: 0.00318\n","2025-05-07 23:31:51.486353: train_loss 0.0317\n","2025-05-07 23:31:51.494898: val_loss 0.0347\n","2025-05-07 23:31:51.497621: Pseudo dice [0.7728, 0.7426]\n","2025-05-07 23:31:51.500088: Epoch time: 188.37 s\n","2025-05-07 23:31:52.922323: \n","2025-05-07 23:31:52.925778: Epoch 217\n","2025-05-07 23:31:52.928237: Current learning rate: 0.00315\n","2025-05-07 23:35:01.340166: train_loss 0.0307\n","2025-05-07 23:35:01.345018: val_loss 0.0381\n","2025-05-07 23:35:01.348149: Pseudo dice [0.7552, 0.7218]\n","2025-05-07 23:35:01.350491: Epoch time: 188.42 s\n","2025-05-07 23:35:02.727247: \n","2025-05-07 23:35:02.729866: Epoch 218\n","2025-05-07 23:35:02.731860: Current learning rate: 0.00311\n","2025-05-07 23:38:10.808998: train_loss 0.0306\n","2025-05-07 23:38:10.814197: val_loss 0.0383\n","2025-05-07 23:38:10.817510: Pseudo dice [0.7656, 0.7508]\n","2025-05-07 23:38:10.820581: Epoch time: 188.08 s\n","2025-05-07 23:38:12.191336: \n","2025-05-07 23:38:12.194394: Epoch 219\n","2025-05-07 23:38:12.196784: Current learning rate: 0.00308\n","2025-05-07 23:41:20.459570: train_loss 0.0318\n","2025-05-07 23:41:20.466135: val_loss 0.0353\n","2025-05-07 23:41:20.469155: Pseudo dice [0.7766, 0.7567]\n","2025-05-07 23:41:20.471056: Epoch time: 188.27 s\n","2025-05-07 23:41:21.842744: \n","2025-05-07 23:41:21.845740: Epoch 220\n","2025-05-07 23:41:21.847976: Current learning rate: 0.00304\n","2025-05-07 23:44:29.962335: train_loss 0.0305\n","2025-05-07 23:44:29.967935: val_loss 0.0337\n","2025-05-07 23:44:29.969967: Pseudo dice [0.7771, 0.7455]\n","2025-05-07 23:44:29.971795: Epoch time: 188.12 s\n","2025-05-07 23:44:31.357834: \n","2025-05-07 23:44:31.360784: Epoch 221\n","2025-05-07 23:44:31.362772: Current learning rate: 0.00301\n","2025-05-07 23:47:39.619694: train_loss 0.0293\n","2025-05-07 23:47:39.624914: val_loss 0.0354\n","2025-05-07 23:47:39.627811: Pseudo dice [0.79, 0.7406]\n","2025-05-07 23:47:39.630957: Epoch time: 188.26 s\n","2025-05-07 23:47:42.421667: \n","2025-05-07 23:47:42.424513: Epoch 222\n","2025-05-07 23:47:42.426683: Current learning rate: 0.00297\n","2025-05-07 23:50:50.742282: train_loss 0.0314\n","2025-05-07 23:50:50.747456: val_loss 0.0354\n","2025-05-07 23:50:50.749781: Pseudo dice [0.7841, 0.7467]\n","2025-05-07 23:50:50.752038: Epoch time: 188.32 s\n","2025-05-07 23:50:50.754160: Yayy! New best EMA pseudo Dice: 0.7558\n","2025-05-07 23:50:52.961843: \n","2025-05-07 23:50:53.058408: Epoch 223\n","2025-05-07 23:50:53.060561: Current learning rate: 0.00294\n","2025-05-07 23:54:01.371847: train_loss 0.0321\n","2025-05-07 23:54:01.376623: val_loss 0.0343\n","2025-05-07 23:54:01.378925: Pseudo dice [0.7694, 0.7373]\n","2025-05-07 23:54:01.381840: Epoch time: 188.41 s\n","2025-05-07 23:54:02.764539: \n","2025-05-07 23:54:02.783789: Epoch 224\n","2025-05-07 23:54:02.787330: Current learning rate: 0.00291\n","2025-05-07 23:57:11.245368: train_loss 0.0329\n","2025-05-07 23:57:11.249470: val_loss 0.0401\n","2025-05-07 23:57:11.253098: Pseudo dice [0.7753, 0.7666]\n","2025-05-07 23:57:11.255448: Epoch time: 188.48 s\n","2025-05-07 23:57:11.257360: Yayy! New best EMA pseudo Dice: 0.7571\n","2025-05-07 23:57:13.450222: \n","2025-05-07 23:57:13.453053: Epoch 225\n","2025-05-07 23:57:13.455105: Current learning rate: 0.00287\n","2025-05-08 00:00:21.837358: train_loss 0.0324\n","2025-05-08 00:00:21.842495: val_loss 0.0378\n","2025-05-08 00:00:21.844929: Pseudo dice [0.778, 0.746]\n","2025-05-08 00:00:21.847248: Epoch time: 188.39 s\n","2025-05-08 00:00:21.849556: Yayy! New best EMA pseudo Dice: 0.7576\n","2025-05-08 00:00:24.051768: \n","2025-05-08 00:00:24.054424: Epoch 226\n","2025-05-08 00:00:24.056572: Current learning rate: 0.00284\n","2025-05-08 00:03:32.728950: train_loss 0.0311\n","2025-05-08 00:03:32.733840: val_loss 0.0398\n","2025-05-08 00:03:32.737142: Pseudo dice [0.7704, 0.741]\n","2025-05-08 00:03:32.739282: Epoch time: 188.68 s\n","2025-05-08 00:03:34.122612: \n","2025-05-08 00:03:34.125172: Epoch 227\n","2025-05-08 00:03:34.127244: Current learning rate: 0.0028\n","2025-05-08 00:06:42.442401: train_loss 0.0333\n","2025-05-08 00:06:42.449309: val_loss 0.0335\n","2025-05-08 00:06:42.451388: Pseudo dice [0.7641, 0.7563]\n","2025-05-08 00:06:42.453411: Epoch time: 188.32 s\n","2025-05-08 00:06:42.455327: Yayy! New best EMA pseudo Dice: 0.7577\n","2025-05-08 00:06:44.642498: \n","2025-05-08 00:06:44.645398: Epoch 228\n","2025-05-08 00:06:44.647550: Current learning rate: 0.00277\n","2025-05-08 00:09:52.939120: train_loss 0.0294\n","2025-05-08 00:09:52.944840: val_loss 0.0311\n","2025-05-08 00:09:52.946927: Pseudo dice [0.7753, 0.7378]\n","2025-05-08 00:09:52.948856: Epoch time: 188.3 s\n","2025-05-08 00:09:54.316118: \n","2025-05-08 00:09:54.318670: Epoch 229\n","2025-05-08 00:09:54.320587: Current learning rate: 0.00273\n","2025-05-08 00:13:02.732743: train_loss 0.0303\n","2025-05-08 00:13:02.738085: val_loss 0.0324\n","2025-05-08 00:13:02.740521: Pseudo dice [0.7901, 0.7549]\n","2025-05-08 00:13:02.742453: Epoch time: 188.42 s\n","2025-05-08 00:13:02.744461: Yayy! New best EMA pseudo Dice: 0.759\n","2025-05-08 00:13:05.350288: \n","2025-05-08 00:13:05.352922: Epoch 230\n","2025-05-08 00:13:05.354990: Current learning rate: 0.0027\n","2025-05-08 00:16:13.938428: train_loss 0.0317\n","2025-05-08 00:16:13.959445: val_loss 0.0326\n","2025-05-08 00:16:13.963014: Pseudo dice [0.7779, 0.7517]\n","2025-05-08 00:16:13.966430: Epoch time: 188.59 s\n","2025-05-08 00:16:13.968313: Yayy! New best EMA pseudo Dice: 0.7596\n","2025-05-08 00:16:16.122136: \n","2025-05-08 00:16:16.124781: Epoch 231\n","2025-05-08 00:16:16.126801: Current learning rate: 0.00266\n","2025-05-08 00:19:24.542720: train_loss 0.0321\n","2025-05-08 00:19:24.547054: val_loss 0.0367\n","2025-05-08 00:19:24.549108: Pseudo dice [0.7374, 0.7483]\n","2025-05-08 00:19:24.551101: Epoch time: 188.42 s\n","2025-05-08 00:19:25.921530: \n","2025-05-08 00:19:25.924562: Epoch 232\n","2025-05-08 00:19:25.927176: Current learning rate: 0.00263\n","2025-05-08 00:22:34.496175: train_loss 0.0296\n","2025-05-08 00:22:34.510155: val_loss 0.0368\n","2025-05-08 00:22:34.513077: Pseudo dice [0.7361, 0.7533]\n","2025-05-08 00:22:34.517704: Epoch time: 188.58 s\n","2025-05-08 00:22:35.910412: \n","2025-05-08 00:22:35.914151: Epoch 233\n","2025-05-08 00:22:35.916932: Current learning rate: 0.00259\n","2025-05-08 00:25:44.245429: train_loss 0.0318\n","2025-05-08 00:25:44.249957: val_loss 0.0328\n","2025-05-08 00:25:44.266686: Pseudo dice [0.7696, 0.7338]\n","2025-05-08 00:25:44.268901: Epoch time: 188.34 s\n","2025-05-08 00:25:45.641401: \n","2025-05-08 00:25:45.644068: Epoch 234\n","2025-05-08 00:25:45.646098: Current learning rate: 0.00256\n","2025-05-08 00:28:54.056715: train_loss 0.0324\n","2025-05-08 00:28:54.061914: val_loss 0.0331\n","2025-05-08 00:28:54.064152: Pseudo dice [0.7456, 0.7507]\n","2025-05-08 00:28:54.067012: Epoch time: 188.42 s\n","2025-05-08 00:28:55.447540: \n","2025-05-08 00:28:55.450234: Epoch 235\n","2025-05-08 00:28:55.452200: Current learning rate: 0.00252\n","2025-05-08 00:32:03.578038: train_loss 0.0287\n","2025-05-08 00:32:03.582738: val_loss 0.0343\n","2025-05-08 00:32:03.585016: Pseudo dice [0.7725, 0.7577]\n","2025-05-08 00:32:03.588156: Epoch time: 188.13 s\n","2025-05-08 00:32:04.976193: \n","2025-05-08 00:32:04.979005: Epoch 236\n","2025-05-08 00:32:04.981396: Current learning rate: 0.00249\n","2025-05-08 00:35:13.649414: train_loss 0.0305\n","2025-05-08 00:35:13.654311: val_loss 0.0363\n","2025-05-08 00:35:13.656651: Pseudo dice [0.7724, 0.7335]\n","2025-05-08 00:35:13.658651: Epoch time: 188.67 s\n","2025-05-08 00:35:15.039431: \n","2025-05-08 00:35:15.042094: Epoch 237\n","2025-05-08 00:35:15.044026: Current learning rate: 0.00245\n","2025-05-08 00:38:23.416073: train_loss 0.0319\n","2025-05-08 00:38:23.421518: val_loss 0.0373\n","2025-05-08 00:38:23.423871: Pseudo dice [0.7609, 0.7446]\n","2025-05-08 00:38:23.439787: Epoch time: 188.38 s\n","2025-05-08 00:38:24.793107: \n","2025-05-08 00:38:24.796137: Epoch 238\n","2025-05-08 00:38:24.798271: Current learning rate: 0.00242\n","2025-05-08 00:41:33.194350: train_loss 0.0314\n","2025-05-08 00:41:33.199636: val_loss 0.035\n","2025-05-08 00:41:33.202061: Pseudo dice [0.762, 0.7424]\n","2025-05-08 00:41:33.219492: Epoch time: 188.4 s\n","2025-05-08 00:41:34.599540: \n","2025-05-08 00:41:34.602805: Epoch 239\n","2025-05-08 00:41:34.605463: Current learning rate: 0.00238\n","2025-05-08 00:44:42.782672: train_loss 0.0326\n","2025-05-08 00:44:42.808501: val_loss 0.0355\n","2025-05-08 00:44:42.812147: Pseudo dice [0.7817, 0.7537]\n","2025-05-08 00:44:42.815120: Epoch time: 188.18 s\n","2025-05-08 00:44:44.514269: \n","2025-05-08 00:44:44.517068: Epoch 240\n","2025-05-08 00:44:44.519488: Current learning rate: 0.00235\n","2025-05-08 00:47:52.806117: train_loss 0.0317\n","2025-05-08 00:47:52.810896: val_loss 0.0396\n","2025-05-08 00:47:52.812948: Pseudo dice [0.7594, 0.7482]\n","2025-05-08 00:47:52.814877: Epoch time: 188.29 s\n","2025-05-08 00:47:54.239889: \n","2025-05-08 00:47:54.242671: Epoch 241\n","2025-05-08 00:47:54.244663: Current learning rate: 0.00231\n","2025-05-08 00:51:02.373646: train_loss 0.03\n","2025-05-08 00:51:02.382853: val_loss 0.032\n","2025-05-08 00:51:02.384861: Pseudo dice [0.7314, 0.7358]\n","2025-05-08 00:51:02.386854: Epoch time: 188.13 s\n","2025-05-08 00:51:03.815575: \n","2025-05-08 00:51:03.835255: Epoch 242\n","2025-05-08 00:51:03.837719: Current learning rate: 0.00228\n","2025-05-08 00:54:12.126734: train_loss 0.031\n","2025-05-08 00:54:12.137201: val_loss 0.0376\n","2025-05-08 00:54:12.140303: Pseudo dice [0.7706, 0.7328]\n","2025-05-08 00:54:12.142986: Epoch time: 188.31 s\n","2025-05-08 00:54:13.587695: \n","2025-05-08 00:54:13.590672: Epoch 243\n","2025-05-08 00:54:13.593002: Current learning rate: 0.00224\n","2025-05-08 00:57:21.705591: train_loss 0.0319\n","2025-05-08 00:57:21.713511: val_loss 0.0349\n","2025-05-08 00:57:21.715935: Pseudo dice [0.7955, 0.753]\n","2025-05-08 00:57:21.718275: Epoch time: 188.12 s\n","2025-05-08 00:57:23.229322: \n","2025-05-08 00:57:23.232221: Epoch 244\n","2025-05-08 00:57:23.234565: Current learning rate: 0.00221\n","2025-05-08 01:00:31.283757: train_loss 0.0307\n","2025-05-08 01:00:31.288808: val_loss 0.0365\n","2025-05-08 01:00:31.291074: Pseudo dice [0.7618, 0.7516]\n","2025-05-08 01:00:31.293229: Epoch time: 188.06 s\n","2025-05-08 01:00:32.727423: \n","2025-05-08 01:00:32.730136: Epoch 245\n","2025-05-08 01:00:32.743222: Current learning rate: 0.00217\n","2025-05-08 01:03:40.801169: train_loss 0.029\n","2025-05-08 01:03:40.810462: val_loss 0.0329\n","2025-05-08 01:03:40.812482: Pseudo dice [0.7741, 0.7418]\n","2025-05-08 01:03:40.815188: Epoch time: 188.08 s\n","2025-05-08 01:03:42.204011: \n","2025-05-08 01:03:42.206751: Epoch 246\n","2025-05-08 01:03:42.208675: Current learning rate: 0.00214\n","2025-05-08 01:06:50.231405: train_loss 0.0301\n","2025-05-08 01:06:50.236944: val_loss 0.0361\n","2025-05-08 01:06:50.239623: Pseudo dice [0.7571, 0.7551]\n","2025-05-08 01:06:50.241681: Epoch time: 188.03 s\n","2025-05-08 01:06:52.941484: \n","2025-05-08 01:06:52.944294: Epoch 247\n","2025-05-08 01:06:52.946531: Current learning rate: 0.0021\n","2025-05-08 01:10:01.245899: train_loss 0.0299\n","2025-05-08 01:10:01.252640: val_loss 0.0347\n","2025-05-08 01:10:01.254984: Pseudo dice [0.7971, 0.7546]\n","2025-05-08 01:10:01.271383: Epoch time: 188.31 s\n","2025-05-08 01:10:02.677454: \n","2025-05-08 01:10:02.680299: Epoch 248\n","2025-05-08 01:10:02.682682: Current learning rate: 0.00207\n","2025-05-08 01:13:10.852882: train_loss 0.03\n","2025-05-08 01:13:10.857056: val_loss 0.0373\n","2025-05-08 01:13:10.859405: Pseudo dice [0.7635, 0.7523]\n","2025-05-08 01:13:10.861718: Epoch time: 188.18 s\n","2025-05-08 01:13:12.265198: \n","2025-05-08 01:13:12.267949: Epoch 249\n","2025-05-08 01:13:12.270611: Current learning rate: 0.00203\n","2025-05-08 01:16:20.480239: train_loss 0.0303\n","2025-05-08 01:16:20.484596: val_loss 0.0323\n","2025-05-08 01:16:20.487020: Pseudo dice [0.7337, 0.7421]\n","2025-05-08 01:16:20.488992: Epoch time: 188.22 s\n","2025-05-08 01:16:22.806501: \n","2025-05-08 01:16:22.809160: Epoch 250\n","2025-05-08 01:16:22.811099: Current learning rate: 0.00199\n","2025-05-08 01:19:31.035380: train_loss 0.0284\n","2025-05-08 01:19:31.040495: val_loss 0.0305\n","2025-05-08 01:19:31.042746: Pseudo dice [0.7822, 0.7577]\n","2025-05-08 01:19:31.044843: Epoch time: 188.23 s\n","2025-05-08 01:19:32.446710: \n","2025-05-08 01:19:32.449597: Epoch 251\n","2025-05-08 01:19:32.452064: Current learning rate: 0.00196\n","2025-05-08 01:22:40.820314: train_loss 0.0295\n","2025-05-08 01:22:40.825464: val_loss 0.0363\n","2025-05-08 01:22:40.827541: Pseudo dice [0.7781, 0.7571]\n","2025-05-08 01:22:40.842724: Epoch time: 188.37 s\n","2025-05-08 01:22:42.256098: \n","2025-05-08 01:22:42.258838: Epoch 252\n","2025-05-08 01:22:42.261115: Current learning rate: 0.00192\n","2025-05-08 01:25:50.122543: train_loss 0.0291\n","2025-05-08 01:25:50.129571: val_loss 0.0336\n","2025-05-08 01:25:50.132021: Pseudo dice [0.7434, 0.737]\n","2025-05-08 01:25:50.134238: Epoch time: 187.87 s\n","2025-05-08 01:25:51.531799: \n","2025-05-08 01:25:51.534927: Epoch 253\n","2025-05-08 01:25:51.537161: Current learning rate: 0.00189\n","2025-05-08 01:28:59.296319: train_loss 0.0288\n","2025-05-08 01:28:59.301372: val_loss 0.0346\n","2025-05-08 01:28:59.303394: Pseudo dice [0.7724, 0.7549]\n","2025-05-08 01:28:59.305218: Epoch time: 187.77 s\n","2025-05-08 01:29:00.741738: \n","2025-05-08 01:29:00.745274: Epoch 254\n","2025-05-08 01:29:00.747495: Current learning rate: 0.00185\n","2025-05-08 01:32:08.477640: train_loss 0.0295\n","2025-05-08 01:32:08.482482: val_loss 0.033\n","2025-05-08 01:32:08.484445: Pseudo dice [0.797, 0.7624]\n","2025-05-08 01:32:08.486477: Epoch time: 187.74 s\n","2025-05-08 01:32:10.216084: \n","2025-05-08 01:32:10.219350: Epoch 255\n","2025-05-08 01:32:10.222317: Current learning rate: 0.00181\n","2025-05-08 01:35:17.921671: train_loss 0.0297\n","2025-05-08 01:35:17.930146: val_loss 0.0311\n","2025-05-08 01:35:17.932301: Pseudo dice [0.7903, 0.7603]\n","2025-05-08 01:35:17.934752: Epoch time: 187.71 s\n","2025-05-08 01:35:17.936668: Yayy! New best EMA pseudo Dice: 0.7611\n","2025-05-08 01:35:20.151381: \n","2025-05-08 01:35:20.154418: Epoch 256\n","2025-05-08 01:35:20.156678: Current learning rate: 0.00178\n","2025-05-08 01:38:27.938441: train_loss 0.0308\n","2025-05-08 01:38:27.943157: val_loss 0.0314\n","2025-05-08 01:38:27.945718: Pseudo dice [0.767, 0.7498]\n","2025-05-08 01:38:27.947909: Epoch time: 187.79 s\n","2025-05-08 01:38:29.380702: \n","2025-05-08 01:38:29.384307: Epoch 257\n","2025-05-08 01:38:29.387078: Current learning rate: 0.00174\n","2025-05-08 01:41:37.272974: train_loss 0.0309\n","2025-05-08 01:41:37.284096: val_loss 0.0341\n","2025-05-08 01:41:37.286598: Pseudo dice [0.7724, 0.744]\n","2025-05-08 01:41:37.288896: Epoch time: 187.89 s\n","2025-05-08 01:41:38.698133: \n","2025-05-08 01:41:38.700998: Epoch 258\n","2025-05-08 01:41:38.703314: Current learning rate: 0.0017\n","2025-05-08 01:44:46.733882: train_loss 0.0285\n","2025-05-08 01:44:46.740857: val_loss 0.0315\n","2025-05-08 01:44:46.743157: Pseudo dice [0.7994, 0.758]\n","2025-05-08 01:44:46.745136: Epoch time: 188.04 s\n","2025-05-08 01:44:46.747197: Yayy! New best EMA pseudo Dice: 0.7624\n","2025-05-08 01:44:48.919589: \n","2025-05-08 01:44:48.922492: Epoch 259\n","2025-05-08 01:44:48.924809: Current learning rate: 0.00167\n","2025-05-08 01:47:56.740921: train_loss 0.0305\n","2025-05-08 01:47:56.748014: val_loss 0.0326\n","2025-05-08 01:47:56.752402: Pseudo dice [0.7824, 0.736]\n","2025-05-08 01:47:56.754390: Epoch time: 187.82 s\n","2025-05-08 01:47:58.151256: \n","2025-05-08 01:47:58.154007: Epoch 260\n","2025-05-08 01:47:58.156621: Current learning rate: 0.00163\n","2025-05-08 01:51:06.009831: train_loss 0.0284\n","2025-05-08 01:51:06.016699: val_loss 0.041\n","2025-05-08 01:51:06.018690: Pseudo dice [0.7723, 0.7556]\n","2025-05-08 01:51:06.020572: Epoch time: 187.86 s\n","2025-05-08 01:51:07.379405: \n","2025-05-08 01:51:07.382089: Epoch 261\n","2025-05-08 01:51:07.384124: Current learning rate: 0.00159\n","2025-05-08 01:54:15.120250: train_loss 0.03\n","2025-05-08 01:54:15.127055: val_loss 0.036\n","2025-05-08 01:54:15.129223: Pseudo dice [0.7759, 0.7618]\n","2025-05-08 01:54:15.131371: Epoch time: 187.74 s\n","2025-05-08 01:54:15.133440: Yayy! New best EMA pseudo Dice: 0.7629\n","2025-05-08 01:54:17.318656: \n","2025-05-08 01:54:17.321393: Epoch 262\n","2025-05-08 01:54:17.323585: Current learning rate: 0.00156\n","2025-05-08 01:57:25.049489: train_loss 0.0298\n","2025-05-08 01:57:25.056397: val_loss 0.0356\n","2025-05-08 01:57:25.058631: Pseudo dice [0.7742, 0.7547]\n","2025-05-08 01:57:25.062554: Epoch time: 187.73 s\n","2025-05-08 01:57:25.064704: Yayy! New best EMA pseudo Dice: 0.7631\n","2025-05-08 01:57:27.264995: \n","2025-05-08 01:57:27.267703: Epoch 263\n","2025-05-08 01:57:27.269622: Current learning rate: 0.00152\n","2025-05-08 02:00:34.963460: train_loss 0.0303\n","2025-05-08 02:00:34.969944: val_loss 0.0334\n","2025-05-08 02:00:34.972169: Pseudo dice [0.7808, 0.7514]\n","2025-05-08 02:00:34.974750: Epoch time: 187.7 s\n","2025-05-08 02:00:34.977387: Yayy! New best EMA pseudo Dice: 0.7634\n","2025-05-08 02:00:37.194630: \n","2025-05-08 02:00:37.197348: Epoch 264\n","2025-05-08 02:00:37.199430: Current learning rate: 0.00148\n","2025-05-08 02:03:44.952981: train_loss 0.0307\n","2025-05-08 02:03:44.959644: val_loss 0.0367\n","2025-05-08 02:03:44.962369: Pseudo dice [0.761, 0.7509]\n","2025-05-08 02:03:44.964926: Epoch time: 187.76 s\n","2025-05-08 02:03:46.361260: \n","2025-05-08 02:03:46.364272: Epoch 265\n","2025-05-08 02:03:46.366630: Current learning rate: 0.00145\n","2025-05-08 02:06:54.339864: train_loss 0.0299\n","2025-05-08 02:06:54.353314: val_loss 0.0332\n","2025-05-08 02:06:54.355372: Pseudo dice [0.7785, 0.7544]\n","2025-05-08 02:06:54.357310: Epoch time: 187.98 s\n","2025-05-08 02:06:55.746672: \n","2025-05-08 02:06:55.749519: Epoch 266\n","2025-05-08 02:06:55.751565: Current learning rate: 0.00141\n","2025-05-08 02:10:03.495078: train_loss 0.0301\n","2025-05-08 02:10:03.506158: val_loss 0.0352\n","2025-05-08 02:10:03.508744: Pseudo dice [0.7678, 0.7671]\n","2025-05-08 02:10:03.510763: Epoch time: 187.75 s\n","2025-05-08 02:10:03.512879: Yayy! New best EMA pseudo Dice: 0.7635\n","2025-05-08 02:10:05.663734: \n","2025-05-08 02:10:05.736603: Epoch 267\n","2025-05-08 02:10:05.738611: Current learning rate: 0.00137\n","2025-05-08 02:13:13.363142: train_loss 0.0278\n","2025-05-08 02:13:13.383802: val_loss 0.0344\n","2025-05-08 02:13:13.387805: Pseudo dice [0.7911, 0.7607]\n","2025-05-08 02:13:13.391769: Epoch time: 187.7 s\n","2025-05-08 02:13:13.394453: Yayy! New best EMA pseudo Dice: 0.7647\n","2025-05-08 02:13:15.582005: \n","2025-05-08 02:13:15.584738: Epoch 268\n","2025-05-08 02:13:15.586849: Current learning rate: 0.00133\n","2025-05-08 02:16:23.262077: train_loss 0.0288\n","2025-05-08 02:16:23.269986: val_loss 0.0346\n","2025-05-08 02:16:23.272301: Pseudo dice [0.7845, 0.772]\n","2025-05-08 02:16:23.276131: Epoch time: 187.68 s\n","2025-05-08 02:16:23.279146: Yayy! New best EMA pseudo Dice: 0.7661\n","2025-05-08 02:16:25.452635: \n","2025-05-08 02:16:25.455560: Epoch 269\n","2025-05-08 02:16:25.457999: Current learning rate: 0.0013\n","2025-05-08 02:19:33.074582: train_loss 0.0282\n","2025-05-08 02:19:33.080036: val_loss 0.0356\n","2025-05-08 02:19:33.082397: Pseudo dice [0.771, 0.7518]\n","2025-05-08 02:19:33.084351: Epoch time: 187.62 s\n","2025-05-08 02:19:34.497895: \n","2025-05-08 02:19:34.500655: Epoch 270\n","2025-05-08 02:19:34.502860: Current learning rate: 0.00126\n","2025-05-08 02:22:42.165223: train_loss 0.0277\n","2025-05-08 02:22:42.175783: val_loss 0.0312\n","2025-05-08 02:22:42.178914: Pseudo dice [0.7834, 0.7599]\n","2025-05-08 02:22:42.181863: Epoch time: 187.67 s\n","2025-05-08 02:22:42.185212: Yayy! New best EMA pseudo Dice: 0.7662\n","2025-05-08 02:22:44.456176: \n","2025-05-08 02:22:44.459534: Epoch 271\n","2025-05-08 02:22:44.462141: Current learning rate: 0.00122\n","2025-05-08 02:25:52.097526: train_loss 0.0306\n","2025-05-08 02:25:52.105768: val_loss 0.0353\n","2025-05-08 02:25:52.108282: Pseudo dice [0.7684, 0.7356]\n","2025-05-08 02:25:52.110685: Epoch time: 187.64 s\n","2025-05-08 02:25:55.072559: \n","2025-05-08 02:25:55.075604: Epoch 272\n","2025-05-08 02:25:55.077869: Current learning rate: 0.00118\n","2025-05-08 02:29:02.765119: train_loss 0.0276\n","2025-05-08 02:29:02.771252: val_loss 0.033\n","2025-05-08 02:29:02.774039: Pseudo dice [0.7979, 0.7748]\n","2025-05-08 02:29:02.776262: Epoch time: 187.69 s\n","2025-05-08 02:29:02.778231: Yayy! New best EMA pseudo Dice: 0.7669\n","2025-05-08 02:29:05.232239: \n","2025-05-08 02:29:05.235006: Epoch 273\n","2025-05-08 02:29:05.237053: Current learning rate: 0.00115\n","2025-05-08 02:32:13.277282: train_loss 0.0289\n","2025-05-08 02:32:13.282283: val_loss 0.0347\n","2025-05-08 02:32:13.284797: Pseudo dice [0.7531, 0.7486]\n","2025-05-08 02:32:13.293354: Epoch time: 188.05 s\n","2025-05-08 02:32:14.678023: \n","2025-05-08 02:32:14.680716: Epoch 274\n","2025-05-08 02:32:14.682793: Current learning rate: 0.00111\n","2025-05-08 02:35:22.432369: train_loss 0.0294\n","2025-05-08 02:35:22.438220: val_loss 0.0369\n","2025-05-08 02:35:22.440468: Pseudo dice [0.7579, 0.7638]\n","2025-05-08 02:35:22.442469: Epoch time: 187.76 s\n","2025-05-08 02:35:23.821762: \n","2025-05-08 02:35:23.824462: Epoch 275\n","2025-05-08 02:35:23.826547: Current learning rate: 0.00107\n","2025-05-08 02:38:31.463186: train_loss 0.029\n","2025-05-08 02:38:31.468228: val_loss 0.0372\n","2025-05-08 02:38:31.485249: Pseudo dice [0.7584, 0.7642]\n","2025-05-08 02:38:31.487664: Epoch time: 187.64 s\n","2025-05-08 02:38:32.862801: \n","2025-05-08 02:38:32.865485: Epoch 276\n","2025-05-08 02:38:32.867548: Current learning rate: 0.00103\n","2025-05-08 02:41:40.624747: train_loss 0.0285\n","2025-05-08 02:41:40.639335: val_loss 0.0367\n","2025-05-08 02:41:40.641754: Pseudo dice [0.7402, 0.7428]\n","2025-05-08 02:41:40.644312: Epoch time: 187.76 s\n","2025-05-08 02:41:42.051566: \n","2025-05-08 02:41:42.054572: Epoch 277\n","2025-05-08 02:41:42.057024: Current learning rate: 0.00099\n","2025-05-08 02:44:49.745656: train_loss 0.0284\n","2025-05-08 02:44:49.750586: val_loss 0.0355\n","2025-05-08 02:44:49.752742: Pseudo dice [0.7856, 0.767]\n","2025-05-08 02:44:49.754800: Epoch time: 187.7 s\n","2025-05-08 02:44:51.135285: \n","2025-05-08 02:44:51.138105: Epoch 278\n","2025-05-08 02:44:51.140136: Current learning rate: 0.00095\n","2025-05-08 02:47:58.916582: train_loss 0.0298\n","2025-05-08 02:47:58.922281: val_loss 0.0356\n","2025-05-08 02:47:58.924695: Pseudo dice [0.7749, 0.7471]\n","2025-05-08 02:47:58.927343: Epoch time: 187.78 s\n","2025-05-08 02:48:00.311399: \n","2025-05-08 02:48:00.314148: Epoch 279\n","2025-05-08 02:48:00.316198: Current learning rate: 0.00091\n","2025-05-08 02:51:08.216344: train_loss 0.0285\n","2025-05-08 02:51:08.222300: val_loss 0.0324\n","2025-05-08 02:51:08.224630: Pseudo dice [0.8041, 0.7802]\n","2025-05-08 02:51:08.226811: Epoch time: 187.91 s\n","2025-05-08 02:51:09.620355: \n","2025-05-08 02:51:09.622929: Epoch 280\n","2025-05-08 02:51:09.625008: Current learning rate: 0.00087\n","2025-05-08 02:54:17.820734: train_loss 0.0279\n","2025-05-08 02:54:17.826518: val_loss 0.0338\n","2025-05-08 02:54:17.829264: Pseudo dice [0.8053, 0.7453]\n","2025-05-08 02:54:17.831476: Epoch time: 188.2 s\n","2025-05-08 02:54:17.833749: Yayy! New best EMA pseudo Dice: 0.7671\n","2025-05-08 02:54:19.967866: \n","2025-05-08 02:54:19.971107: Epoch 281\n","2025-05-08 02:54:19.973501: Current learning rate: 0.00083\n","2025-05-08 02:57:27.800168: train_loss 0.0285\n","2025-05-08 02:57:27.821322: val_loss 0.0313\n","2025-05-08 02:57:27.823699: Pseudo dice [0.7797, 0.7592]\n","2025-05-08 02:57:27.825883: Epoch time: 187.83 s\n","2025-05-08 02:57:27.827997: Yayy! New best EMA pseudo Dice: 0.7674\n","2025-05-08 02:57:30.357797: \n","2025-05-08 02:57:30.361232: Epoch 282\n","2025-05-08 02:57:30.363660: Current learning rate: 0.00079\n","2025-05-08 03:00:38.173576: train_loss 0.0288\n","2025-05-08 03:00:38.181327: val_loss 0.0333\n","2025-05-08 03:00:38.185877: Pseudo dice [0.785, 0.7546]\n","2025-05-08 03:00:38.189041: Epoch time: 187.82 s\n","2025-05-08 03:00:38.191991: Yayy! New best EMA pseudo Dice: 0.7676\n","2025-05-08 03:00:40.386667: \n","2025-05-08 03:00:40.389603: Epoch 283\n","2025-05-08 03:00:40.391845: Current learning rate: 0.00076\n","2025-05-08 03:03:48.120621: train_loss 0.0297\n","2025-05-08 03:03:48.126477: val_loss 0.0393\n","2025-05-08 03:03:48.129180: Pseudo dice [0.7891, 0.7726]\n","2025-05-08 03:03:48.131355: Epoch time: 187.73 s\n","2025-05-08 03:03:48.133315: Yayy! New best EMA pseudo Dice: 0.7689\n","2025-05-08 03:03:50.224157: \n","2025-05-08 03:03:50.227272: Epoch 284\n","2025-05-08 03:03:50.229714: Current learning rate: 0.00071\n","2025-05-08 03:06:57.958178: train_loss 0.0292\n","2025-05-08 03:06:57.964946: val_loss 0.0356\n","2025-05-08 03:06:57.967189: Pseudo dice [0.7896, 0.7494]\n","2025-05-08 03:06:57.969325: Epoch time: 187.74 s\n","2025-05-08 03:06:57.971435: Yayy! New best EMA pseudo Dice: 0.769\n","2025-05-08 03:07:00.149341: \n","2025-05-08 03:07:00.152548: Epoch 285\n","2025-05-08 03:07:00.155347: Current learning rate: 0.00067\n","2025-05-08 03:10:07.798915: train_loss 0.029\n","2025-05-08 03:10:07.809170: val_loss 0.0411\n","2025-05-08 03:10:07.811508: Pseudo dice [0.7673, 0.7547]\n","2025-05-08 03:10:07.813477: Epoch time: 187.65 s\n","2025-05-08 03:10:09.204095: \n","2025-05-08 03:10:09.206979: Epoch 286\n","2025-05-08 03:10:09.209245: Current learning rate: 0.00063\n","2025-05-08 03:13:17.034324: train_loss 0.0301\n","2025-05-08 03:13:17.041366: val_loss 0.0328\n","2025-05-08 03:13:17.044258: Pseudo dice [0.8009, 0.7501]\n","2025-05-08 03:13:17.046953: Epoch time: 187.83 s\n","2025-05-08 03:13:18.438873: \n","2025-05-08 03:13:18.441703: Epoch 287\n","2025-05-08 03:13:18.444040: Current learning rate: 0.00059\n","2025-05-08 03:16:26.742981: train_loss 0.0296\n","2025-05-08 03:16:26.749943: val_loss 0.0338\n","2025-05-08 03:16:26.752273: Pseudo dice [0.7753, 0.7636]\n","2025-05-08 03:16:26.754406: Epoch time: 188.31 s\n","2025-05-08 03:16:28.164917: \n","2025-05-08 03:16:28.167603: Epoch 288\n","2025-05-08 03:16:28.169674: Current learning rate: 0.00055\n","2025-05-08 03:19:36.218893: train_loss 0.0283\n","2025-05-08 03:19:36.227085: val_loss 0.0311\n","2025-05-08 03:19:36.229329: Pseudo dice [0.7919, 0.7478]\n","2025-05-08 03:19:36.231358: Epoch time: 188.06 s\n","2025-05-08 03:19:36.233292: Yayy! New best EMA pseudo Dice: 0.7691\n","2025-05-08 03:19:38.548198: \n","2025-05-08 03:19:38.551475: Epoch 289\n","2025-05-08 03:19:38.553897: Current learning rate: 0.00051\n","2025-05-08 03:22:46.312946: train_loss 0.028\n","2025-05-08 03:22:46.318908: val_loss 0.0349\n","2025-05-08 03:22:46.321127: Pseudo dice [0.7809, 0.7538]\n","2025-05-08 03:22:46.324650: Epoch time: 187.77 s\n","2025-05-08 03:22:47.790577: \n","2025-05-08 03:22:47.804817: Epoch 290\n","2025-05-08 03:22:47.808167: Current learning rate: 0.00047\n","2025-05-08 03:25:55.605546: train_loss 0.0287\n","2025-05-08 03:25:55.613259: val_loss 0.0364\n","2025-05-08 03:25:55.618205: Pseudo dice [0.7752, 0.7824]\n","2025-05-08 03:25:55.621133: Epoch time: 187.82 s\n","2025-05-08 03:25:55.623978: Yayy! New best EMA pseudo Dice: 0.7699\n","2025-05-08 03:25:57.924605: \n","2025-05-08 03:25:57.927333: Epoch 291\n","2025-05-08 03:25:57.929466: Current learning rate: 0.00043\n","2025-05-08 03:29:05.675878: train_loss 0.03\n","2025-05-08 03:29:05.695626: val_loss 0.0346\n","2025-05-08 03:29:05.699672: Pseudo dice [0.7588, 0.7508]\n","2025-05-08 03:29:05.703691: Epoch time: 187.75 s\n","2025-05-08 03:29:07.166707: \n","2025-05-08 03:29:07.169436: Epoch 292\n","2025-05-08 03:29:07.171592: Current learning rate: 0.00038\n","2025-05-08 03:32:15.066067: train_loss 0.0282\n","2025-05-08 03:32:15.078032: val_loss 0.0328\n","2025-05-08 03:32:15.080221: Pseudo dice [0.8031, 0.7649]\n","2025-05-08 03:32:15.083338: Epoch time: 187.9 s\n","2025-05-08 03:32:15.085643: Yayy! New best EMA pseudo Dice: 0.7699\n","2025-05-08 03:32:17.294134: \n","2025-05-08 03:32:17.296957: Epoch 293\n","2025-05-08 03:32:17.299211: Current learning rate: 0.00034\n","2025-05-08 03:35:25.095490: train_loss 0.0278\n","2025-05-08 03:35:25.101735: val_loss 0.0363\n","2025-05-08 03:35:25.104104: Pseudo dice [0.7715, 0.7671]\n","2025-05-08 03:35:25.106406: Epoch time: 187.8 s\n","2025-05-08 03:35:26.921657: \n","2025-05-08 03:35:26.924308: Epoch 294\n","2025-05-08 03:35:26.926335: Current learning rate: 0.0003\n","2025-05-08 03:38:34.651889: train_loss 0.0286\n","2025-05-08 03:38:34.671603: val_loss 0.0335\n","2025-05-08 03:38:34.675172: Pseudo dice [0.7916, 0.7708]\n","2025-05-08 03:38:34.678851: Epoch time: 187.73 s\n","2025-05-08 03:38:34.680773: Yayy! New best EMA pseudo Dice: 0.771\n","2025-05-08 03:38:36.933061: \n","2025-05-08 03:38:36.935798: Epoch 295\n","2025-05-08 03:38:36.937896: Current learning rate: 0.00025\n","2025-05-08 03:41:45.065112: train_loss 0.0277\n","2025-05-08 03:41:45.073434: val_loss 0.0357\n","2025-05-08 03:41:45.075763: Pseudo dice [0.7823, 0.7683]\n","2025-05-08 03:41:45.077817: Epoch time: 188.13 s\n","2025-05-08 03:41:45.079854: Yayy! New best EMA pseudo Dice: 0.7714\n","2025-05-08 03:41:47.306919: \n","2025-05-08 03:41:47.309598: Epoch 296\n","2025-05-08 03:41:47.311729: Current learning rate: 0.00021\n","2025-05-08 03:44:55.245266: train_loss 0.0277\n","2025-05-08 03:44:55.251331: val_loss 0.032\n","2025-05-08 03:44:55.253517: Pseudo dice [0.7885, 0.762]\n","2025-05-08 03:44:55.255478: Epoch time: 187.94 s\n","2025-05-08 03:44:55.257425: Yayy! New best EMA pseudo Dice: 0.7718\n","2025-05-08 03:44:59.151972: \n","2025-05-08 03:44:59.272129: Epoch 297\n","2025-05-08 03:44:59.274654: Current learning rate: 0.00016\n","2025-05-08 03:48:07.076197: train_loss 0.0304\n","2025-05-08 03:48:07.081938: val_loss 0.0339\n","2025-05-08 03:48:07.084182: Pseudo dice [0.7864, 0.7444]\n","2025-05-08 03:48:07.086277: Epoch time: 187.93 s\n","2025-05-08 03:48:08.492819: \n","2025-05-08 03:48:08.495489: Epoch 298\n","2025-05-08 03:48:08.497452: Current learning rate: 0.00011\n","2025-05-08 03:51:16.288244: train_loss 0.0287\n","2025-05-08 03:51:16.297830: val_loss 0.0309\n","2025-05-08 03:51:16.300107: Pseudo dice [0.7941, 0.7665]\n","2025-05-08 03:51:16.302195: Epoch time: 187.8 s\n","2025-05-08 03:51:16.304197: Yayy! New best EMA pseudo Dice: 0.7721\n","2025-05-08 03:51:18.518601: \n","2025-05-08 03:51:18.521167: Epoch 299\n","2025-05-08 03:51:18.523146: Current learning rate: 6e-05\n","2025-05-08 03:54:26.324405: train_loss 0.0274\n","2025-05-08 03:54:26.330610: val_loss 0.0335\n","2025-05-08 03:54:26.332997: Pseudo dice [0.791, 0.76]\n","2025-05-08 03:54:26.336533: Epoch time: 187.81 s\n","2025-05-08 03:54:26.338603: Yayy! New best EMA pseudo Dice: 0.7724\n","2025-05-08 03:54:29.821200: Training done.\n","2025-05-08 03:54:30.116807: Using splits from existing split file: data/nnUNet_preprocessed/Dataset002_hepaticvessel/splits_final.json\n","2025-05-08 03:54:30.134027: The split file contains 5 splits.\n","2025-05-08 03:54:30.137056: Desired fold for training: 0\n","2025-05-08 03:54:30.141171: This split has 254 training and 64 validation cases.\n","2025-05-08 03:54:30.148714: predicting hepaticvessel_00018\n","2025-05-08 03:54:31.037124: hepaticvessel_00018, shape torch.Size([1, 120, 459, 459]), rank 0\n","2025-05-08 03:55:18.731376: predicting hepaticvessel_00019\n","2025-05-08 03:55:18.986423: hepaticvessel_00019, shape torch.Size([1, 150, 499, 499]), rank 0\n","2025-05-08 03:56:05.017161: predicting hepaticvessel_00026\n","2025-05-08 03:56:05.306853: hepaticvessel_00026, shape torch.Size([1, 173, 525, 525]), rank 0\n","2025-05-08 03:57:03.169341: predicting hepaticvessel_00028\n","2025-05-08 03:57:03.390980: hepaticvessel_00028, shape torch.Size([1, 133, 506, 506]), rank 0\n","2025-05-08 03:57:49.846530: predicting hepaticvessel_00029\n","2025-05-08 03:57:50.177231: hepaticvessel_00029, shape torch.Size([1, 143, 631, 631]), rank 0\n","2025-05-08 03:58:57.034976: predicting hepaticvessel_00030\n","2025-05-08 03:58:57.322592: hepaticvessel_00030, shape torch.Size([1, 130, 613, 613]), rank 0\n","2025-05-08 04:00:04.325655: predicting hepaticvessel_00044\n","2025-05-08 04:00:04.563724: hepaticvessel_00044, shape torch.Size([1, 137, 523, 523]), rank 0\n","2025-05-08 04:00:50.996623: predicting hepaticvessel_00050\n","2025-05-08 04:00:51.258245: hepaticvessel_00050, shape torch.Size([1, 137, 564, 564]), rank 0\n","2025-05-08 04:01:38.122735: predicting hepaticvessel_00051\n","2025-05-08 04:01:38.270311: hepaticvessel_00051, shape torch.Size([1, 113, 455, 455]), rank 0\n","2025-05-08 04:02:00.851084: predicting hepaticvessel_00053\n","2025-05-08 04:02:01.097256: hepaticvessel_00053, shape torch.Size([1, 140, 549, 549]), rank 0\n","2025-05-08 04:02:47.523819: predicting hepaticvessel_00058\n","2025-05-08 04:02:47.648396: hepaticvessel_00058, shape torch.Size([1, 110, 429, 429]), rank 0\n","2025-05-08 04:03:10.064155: predicting hepaticvessel_00066\n","2025-05-08 04:03:10.339101: hepaticvessel_00066, shape torch.Size([1, 163, 504, 504]), rank 0\n","2025-05-08 04:04:09.807465: predicting hepaticvessel_00067\n","2025-05-08 04:04:10.079213: hepaticvessel_00067, shape torch.Size([1, 133, 566, 566]), rank 0\n","2025-05-08 04:04:57.286252: predicting hepaticvessel_00077\n","2025-05-08 04:04:57.473090: hepaticvessel_00077, shape torch.Size([1, 130, 445, 445]), rank 0\n","2025-05-08 04:05:27.490072: predicting hepaticvessel_00080\n","2025-05-08 04:05:27.841259: hepaticvessel_00080, shape torch.Size([1, 150, 631, 631]), rank 0\n","2025-05-08 04:06:35.173713: predicting hepaticvessel_00082\n","2025-05-08 04:06:35.573290: hepaticvessel_00082, shape torch.Size([1, 167, 608, 608]), rank 0\n","2025-05-08 04:07:59.832507: predicting hepaticvessel_00084\n","2025-05-08 04:08:00.112812: hepaticvessel_00084, shape torch.Size([1, 150, 530, 530]), rank 0\n","2025-05-08 04:08:46.987892: predicting hepaticvessel_00085\n","2025-05-08 04:08:47.192801: hepaticvessel_00085, shape torch.Size([1, 120, 479, 479]), rank 0\n","2025-05-08 04:09:09.687111: predicting hepaticvessel_00087\n","2025-05-08 04:09:09.936516: hepaticvessel_00087, shape torch.Size([1, 130, 544, 544]), rank 0\n","2025-05-08 04:09:56.622600: predicting hepaticvessel_00104\n","2025-05-08 04:09:57.027077: hepaticvessel_00104, shape torch.Size([1, 163, 631, 631]), rank 0\n","2025-05-08 04:11:21.233619: predicting hepaticvessel_00112\n","2025-05-08 04:11:21.590238: hepaticvessel_00112, shape torch.Size([1, 147, 602, 602]), rank 0\n","2025-05-08 04:12:29.151506: predicting hepaticvessel_00127\n","2025-05-08 04:12:29.446216: hepaticvessel_00127, shape torch.Size([1, 270, 393, 393]), rank 0\n","2025-05-08 04:13:29.334607: predicting hepaticvessel_00131\n","2025-05-08 04:13:29.663665: hepaticvessel_00131, shape torch.Size([1, 160, 586, 586]), rank 0\n","2025-05-08 04:14:37.067240: predicting hepaticvessel_00142\n","2025-05-08 04:14:37.361374: hepaticvessel_00142, shape torch.Size([1, 167, 532, 532]), rank 0\n","2025-05-08 04:15:35.930885: predicting hepaticvessel_00145\n","2025-05-08 04:15:36.235771: hepaticvessel_00145, shape torch.Size([1, 160, 557, 557]), rank 0\n","2025-05-08 04:16:22.893443: predicting hepaticvessel_00147\n","2025-05-08 04:16:23.304967: hepaticvessel_00147, shape torch.Size([1, 193, 617, 617]), rank 0\n","2025-05-08 04:18:03.550929: predicting hepaticvessel_00150\n","2025-05-08 04:18:04.162360: hepaticvessel_00150, shape torch.Size([1, 295, 530, 530]), rank 0\n","2025-05-08 04:19:49.938824: predicting hepaticvessel_00157\n","2025-05-08 04:19:50.395889: hepaticvessel_00157, shape torch.Size([1, 180, 631, 631]), rank 0\n","2025-05-08 04:21:14.383307: predicting hepaticvessel_00161\n","2025-05-08 04:21:14.553898: hepaticvessel_00161, shape torch.Size([1, 120, 454, 454]), rank 0\n","2025-05-08 04:21:37.042686: predicting hepaticvessel_00164\n","2025-05-08 04:21:37.276618: hepaticvessel_00164, shape torch.Size([1, 135, 464, 464]), rank 0\n","2025-05-08 04:22:07.121182: predicting hepaticvessel_00165\n","2025-05-08 04:22:07.450730: hepaticvessel_00165, shape torch.Size([1, 203, 511, 511]), rank 0\n","2025-05-08 04:23:17.957924: predicting hepaticvessel_00175\n","2025-05-08 04:23:18.214273: hepaticvessel_00175, shape torch.Size([1, 137, 454, 454]), rank 0\n","2025-05-08 04:23:48.234882: predicting hepaticvessel_00179\n","2025-05-08 04:23:48.335203: hepaticvessel_00179, shape torch.Size([1, 107, 395, 395]), rank 0\n","2025-05-08 04:24:10.880764: predicting hepaticvessel_00186\n","2025-05-08 04:24:11.097550: hepaticvessel_00186, shape torch.Size([1, 133, 533, 533]), rank 0\n","2025-05-08 04:24:57.629689: predicting hepaticvessel_00211\n","2025-05-08 04:24:57.954418: hepaticvessel_00211, shape torch.Size([1, 173, 588, 588]), rank 0\n","2025-05-08 04:26:21.534378: predicting hepaticvessel_00217\n","2025-05-08 04:26:21.893789: hepaticvessel_00217, shape torch.Size([1, 157, 631, 631]), rank 0\n","2025-05-08 04:27:28.768596: predicting hepaticvessel_00218\n","2025-05-08 04:27:28.981451: hepaticvessel_00218, shape torch.Size([1, 167, 473, 473]), rank 0\n","2025-05-08 04:28:06.495233: predicting hepaticvessel_00221\n","2025-05-08 04:28:06.775972: hepaticvessel_00221, shape torch.Size([1, 123, 631, 631]), rank 0\n","2025-05-08 04:28:57.651278: predicting hepaticvessel_00237\n","2025-05-08 04:28:57.935163: hepaticvessel_00237, shape torch.Size([1, 150, 574, 574]), rank 0\n","2025-05-08 04:29:44.708410: predicting hepaticvessel_00258\n","2025-05-08 04:29:45.029973: hepaticvessel_00258, shape torch.Size([1, 170, 541, 541]), rank 0\n","2025-05-08 04:30:43.825783: predicting hepaticvessel_00268\n","2025-05-08 04:30:44.117877: hepaticvessel_00268, shape torch.Size([1, 170, 520, 520]), rank 0\n","2025-05-08 04:31:42.701543: predicting hepaticvessel_00270\n","2025-05-08 04:31:42.965688: hepaticvessel_00270, shape torch.Size([1, 148, 416, 416]), rank 0\n","2025-05-08 04:32:12.967861: predicting hepaticvessel_00275\n","2025-05-08 04:32:13.244367: hepaticvessel_00275, shape torch.Size([1, 131, 508, 508]), rank 0\n","2025-05-08 04:32:59.912016: predicting hepaticvessel_00278\n","2025-05-08 04:33:00.225387: hepaticvessel_00278, shape torch.Size([1, 175, 567, 567]), rank 0\n","2025-05-08 04:33:58.664390: predicting hepaticvessel_00285\n","2025-05-08 04:33:58.879088: hepaticvessel_00285, shape torch.Size([1, 133, 515, 515]), rank 0\n","2025-05-08 04:34:45.896200: predicting hepaticvessel_00290\n","2025-05-08 04:34:46.136246: hepaticvessel_00290, shape torch.Size([1, 150, 528, 528]), rank 0\n","2025-05-08 04:35:32.686313: predicting hepaticvessel_00322\n","2025-05-08 04:35:32.925873: hepaticvessel_00322, shape torch.Size([1, 173, 457, 457]), rank 0\n","2025-05-08 04:36:10.300337: predicting hepaticvessel_00361\n","2025-05-08 04:36:10.610411: hepaticvessel_00361, shape torch.Size([1, 167, 580, 580]), rank 0\n","2025-05-08 04:37:34.453410: predicting hepaticvessel_00367\n","2025-05-08 04:37:34.674207: hepaticvessel_00367, shape torch.Size([1, 147, 508, 508]), rank 0\n","2025-05-08 04:38:21.536413: predicting hepaticvessel_00378\n","2025-05-08 04:38:21.726586: hepaticvessel_00378, shape torch.Size([1, 127, 489, 489]), rank 0\n","2025-05-08 04:38:56.619701: predicting hepaticvessel_00379\n","2025-05-08 04:38:56.978200: hepaticvessel_00379, shape torch.Size([1, 161, 502, 502]), rank 0\n","2025-05-08 04:39:55.413393: predicting hepaticvessel_00386\n","2025-05-08 04:39:55.634937: hepaticvessel_00386, shape torch.Size([1, 140, 454, 454]), rank 0\n","2025-05-08 04:40:25.552975: predicting hepaticvessel_00391\n","2025-05-08 04:40:25.835058: hepaticvessel_00391, shape torch.Size([1, 157, 552, 552]), rank 0\n","2025-05-08 04:41:12.858173: predicting hepaticvessel_00396\n","2025-05-08 04:41:13.203553: hepaticvessel_00396, shape torch.Size([1, 177, 552, 552]), rank 0\n","2025-05-08 04:42:11.757582: predicting hepaticvessel_00425\n","2025-05-08 04:42:11.955074: hepaticvessel_00425, shape torch.Size([1, 170, 454, 454]), rank 0\n","2025-05-08 04:42:49.440573: predicting hepaticvessel_00437\n","2025-05-08 04:42:49.846531: hepaticvessel_00437, shape torch.Size([1, 138, 627, 627]), rank 0\n","2025-05-08 04:43:56.950253: predicting hepaticvessel_00444\n","2025-05-08 04:43:57.203063: hepaticvessel_00444, shape torch.Size([1, 145, 458, 458]), rank 0\n","2025-05-08 04:44:27.142404: predicting hepaticvessel_00447\n","2025-05-08 04:44:27.330489: hepaticvessel_00447, shape torch.Size([1, 167, 443, 443]), rank 0\n","2025-05-08 04:45:04.571830: predicting hepaticvessel_00459\n","2025-05-08 04:45:04.763406: hepaticvessel_00459, shape torch.Size([1, 96, 444, 444]), rank 0\n","2025-05-08 04:45:19.778899: predicting hepaticvessel_00463\n","2025-05-08 04:45:20.008466: hepaticvessel_00463, shape torch.Size([1, 101, 488, 488]), rank 0\n","2025-05-08 04:45:55.166452: predicting hepaticvessel_00468\n","2025-05-08 04:45:55.425673: hepaticvessel_00468, shape torch.Size([1, 117, 448, 448]), rank 0\n","2025-05-08 04:46:17.892402: predicting hepaticvessel_00479\n","2025-05-08 04:46:18.281745: hepaticvessel_00479, shape torch.Size([1, 171, 504, 504]), rank 0\n","2025-05-08 04:47:16.945011: predicting hepaticvessel_00487\n","2025-05-08 04:47:17.187521: hepaticvessel_00487, shape torch.Size([1, 143, 441, 441]), rank 0\n","2025-05-08 04:47:47.090479: predicting hepaticvessel_00488\n","2025-05-08 04:47:47.474709: hepaticvessel_00488, shape torch.Size([1, 177, 473, 473]), rank 0\n","(36, 512, 512)\n","(52, 512, 512)\n","(43, 512, 512)\n","(36, 512, 512)\n","(52, 512, 512)\n","(41, 512, 512)\n","(34, 512, 512)\n","(33, 512, 512)\n","(45, 512, 512)\n","(40, 512, 512)\n","(43, 512, 512)\n","(41, 512, 512)\n","(34, 512, 512)\n","(45, 512, 512)\n","(40, 512, 512)\n","(33, 512, 512)\n","(45, 512, 512)\n","(40, 512, 512)\n","(39, 512, 512)\n","(41, 512, 512)\n","(42, 512, 512)\n","(49, 512, 512)\n","(39, 512, 512)\n","(39, 512, 512)\n","(40, 512, 512)\n","(50, 512, 512)\n","(45, 512, 512)\n","(39, 512, 512)\n","(42, 512, 512)\n","(41, 512, 512)\n","(45, 512, 512)\n","(49, 512, 512)\n","(39, 512, 512)\n","(44, 512, 512)\n","(48, 512, 512)\n","(50, 512, 512)\n","(48, 512, 512)\n","(45, 512, 512)\n","(36, 512, 512)\n","(44, 512, 512)\n","(39, 512, 512)\n","(36, 512, 512)\n","(61, 512, 512)\n","(48, 512, 512)\n","(177, 512, 512)\n","(48, 512, 512)\n","(81, 512, 512)\n","(36, 512, 512)\n","(49, 512, 512)\n","(81, 512, 512)\n","(61, 512, 512)\n","(36, 512, 512)\n","(58, 512, 512)\n","(50, 512, 512)\n","(49, 512, 512)\n","(32, 512, 512)\n","(58, 512, 512)\n","(50, 512, 512)\n","(82, 512, 512)\n","(81, 512, 512)\n","(52, 512, 512)\n","(32, 512, 512)\n","(50, 512, 512)\n","(45, 512, 512)\n","(52, 512, 512)\n","(81, 512, 512)\n","(50, 512, 512)\n","(45, 512, 512)\n","(40, 512, 512)\n","(47, 512, 512)\n","(82, 512, 512)\n","(51, 512, 512)\n","(40, 512, 512)\n","(37, 512, 512)\n","(47, 512, 512)\n","(51, 512, 512)\n","(40, 512, 512)\n","(37, 512, 512)\n","(52, 512, 512)\n","(177, 512, 512)\n","(131, 512, 512)\n","(51, 512, 512)\n","(40, 512, 512)\n","(44, 512, 512)\n","(51, 512, 512)\n","(52, 512, 512)\n","(45, 512, 512)\n","(44, 512, 512)\n","(47, 512, 512)\n","(148, 512, 512)\n","(45, 512, 512)\n","(161, 512, 512)\n","(50, 512, 512)\n","(38, 512, 512)\n","(34, 512, 512)\n","(47, 512, 512)\n","(50, 512, 512)\n","(54, 512, 512)\n","(38, 512, 512)\n","(131, 512, 512)\n","(34, 512, 512)\n","(53, 512, 512)\n","(87, 512, 512)\n","(96, 512, 512)\n","(54, 512, 512)\n","(53, 512, 512)\n","(138, 512, 512)\n","(110, 512, 512)\n","(148, 512, 512)\n","(35, 512, 512)\n","(161, 512, 512)\n","(96, 512, 512)\n","(35, 512, 512)\n","(214, 512, 512)\n","(87, 512, 512)\n","(95, 512, 512)\n","(138, 512, 512)\n","(110, 512, 512)\n","(50, 512, 512)\n","(42, 512, 512)\n","(50, 512, 512)\n","(95, 512, 512)\n","(257, 512, 512)\n","(42, 512, 512)\n","(214, 512, 512)\n","(266, 512, 512)\n","(257, 512, 512)\n","(266, 512, 512)\n","2025-05-08 04:49:29.086921: Validation complete\n","2025-05-08 04:49:29.089435: Mean Validation Dice:  0.7448727071143011\n"]}]},{"cell_type":"code","source":["!nnUNetv2_find_best_configuration 2 -c 3d_fullres --disable_ensembling -f 0 -tr nnUNetTrainerCEclCEloss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D0cY7T2NjtEl","executionInfo":{"status":"ok","timestamp":1746680555483,"user_tz":-180,"elapsed":213329,"user":{"displayName":"Mustafa Said KARTAL","userId":"14049951240735760192"}},"outputId":"236679e9-e2b1-48ab-8abd-475138b3a3e3"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["(36, 512, 512)\n","(52, 512, 512)\n","(36, 512, 512)\n","(43, 512, 512)\n","(41, 512, 512)\n","(33, 512, 512)\n","(34, 512, 512)\n","(40, 512, 512)\n","(45, 512, 512)\n","(43, 512, 512)\n","(34, 512, 512)\n","(45, 512, 512)\n","(41, 512, 512)\n","(33, 512, 512)\n","(40, 512, 512)\n","(45, 512, 512)\n","(52, 512, 512)\n","(39, 512, 512)\n","(42, 512, 512)\n","(45, 512, 512)\n","(41, 512, 512)\n","(49, 512, 512)\n","(42, 512, 512)\n","(39, 512, 512)\n","(50, 512, 512)\n","(39, 512, 512)\n","(40, 512, 512)\n","(39, 512, 512)\n","(39, 512, 512)\n","(45, 512, 512)\n","(41, 512, 512)\n","(40, 512, 512)\n","(49, 512, 512)\n","(44, 512, 512)\n","(50, 512, 512)\n","(48, 512, 512)\n","(48, 512, 512)\n","(45, 512, 512)\n","(44, 512, 512)\n","(39, 512, 512)\n","(36, 512, 512)\n","(48, 512, 512)\n","(48, 512, 512)\n","(61, 512, 512)\n","(36, 512, 512)\n","(36, 512, 512)\n","(49, 512, 512)\n","(177, 512, 512)\n","(81, 512, 512)\n","(50, 512, 512)\n","(58, 512, 512)\n","(36, 512, 512)\n","(61, 512, 512)\n","(49, 512, 512)\n","(81, 512, 512)\n","(32, 512, 512)\n","(58, 512, 512)\n","(50, 512, 512)\n","(52, 512, 512)\n","(81, 512, 512)\n","(32, 512, 512)\n","(50, 512, 512)\n","(82, 512, 512)\n","(45, 512, 512)\n","(40, 512, 512)\n","(50, 512, 512)\n","(51, 512, 512)\n","(45, 512, 512)\n","(52, 512, 512)\n","(40, 512, 512)\n","(81, 512, 512)\n","(37, 512, 512)\n","(51, 512, 512)\n","(51, 512, 512)\n","(47, 512, 512)\n","(37, 512, 512)\n","(131, 512, 512)\n","(51, 512, 512)\n","(40, 512, 512)\n","(82, 512, 512)\n","(52, 512, 512)\n","(47, 512, 512)\n","(40, 512, 512)\n","(177, 512, 512)\n","(44, 512, 512)\n","(148, 512, 512)\n","(52, 512, 512)\n","(45, 512, 512)\n","(47, 512, 512)\n","(44, 512, 512)\n","(161, 512, 512)\n","(38, 512, 512)\n","(50, 512, 512)\n","(45, 512, 512)\n","(47, 512, 512)\n","(131, 512, 512)\n","(50, 512, 512)\n","(53, 512, 512)\n","(38, 512, 512)\n","(34, 512, 512)\n","(54, 512, 512)\n","(53, 512, 512)\n","(34, 512, 512)\n","(87, 512, 512)\n","(96, 512, 512)\n","(148, 512, 512)\n","(110, 512, 512)\n","(54, 512, 512)\n","(35, 512, 512)\n","(138, 512, 512)\n","(96, 512, 512)\n","(161, 512, 512)\n","(35, 512, 512)\n","(214, 512, 512)\n","(87, 512, 512)\n","(110, 512, 512)\n","(138, 512, 512)\n","(95, 512, 512)\n","(50, 512, 512)\n","(42, 512, 512)\n","(50, 512, 512)\n","(42, 512, 512)\n","(257, 512, 512)\n","(95, 512, 512)\n","(214, 512, 512)\n","(257, 512, 512)\n","(266, 512, 512)\n","(266, 512, 512)\n","\n","***All results:***\n","nnUNetTrainerCEclCEloss__nnUNetPlans__3d_fullres: 0.7448727071143011\n","\n","*Best*: nnUNetTrainerCEclCEloss__nnUNetPlans__3d_fullres: 0.7448727071143011\n","\n","***Determining postprocessing for best model/ensemble***\n","WARNING: Not all files in folder_ref were found in folder_predictions. Determining postprocessing should always be done on the entire dataset!\n","(36, 512, 512)\n","(33, 512, 512)\n","(34, 512, 512)\n","(41, 512, 512)\n","(43, 512, 512)\n","(52, 512, 512)\n","(40, 512, 512)\n","(45, 512, 512)\n","(33, 512, 512)\n","(43, 512, 512)\n","(34, 512, 512)\n","(40, 512, 512)\n","(52, 512, 512)\n","(41, 512, 512)\n","(45, 512, 512)\n","(49, 512, 512)\n","(39, 512, 512)\n","(36, 512, 512)\n","(39, 512, 512)\n","(42, 512, 512)\n","(40, 512, 512)\n","(39, 512, 512)\n","(41, 512, 512)\n","(39, 512, 512)\n","(50, 512, 512)\n","(42, 512, 512)\n","(45, 512, 512)\n","(49, 512, 512)\n","(40, 512, 512)\n","(45, 512, 512)\n","(41, 512, 512)\n","(39, 512, 512)\n","(44, 512, 512)\n","(48, 512, 512)\n","(50, 512, 512)\n","(45, 512, 512)\n","(48, 512, 512)\n","(45, 512, 512)\n","/content/drive/MyDrive/Liver Vessel/nnunet/nnUNet/nnunetv2/evaluation/evaluate_predictions.py:105: RuntimeWarning: invalid value encountered in scalar divide\n","  return 2*tprec*tsens/(tprec+tsens)\n","/content/drive/MyDrive/Liver Vessel/nnunet/nnUNet/nnunetv2/evaluation/evaluate_predictions.py:91: RuntimeWarning: invalid value encountered in scalar divide\n","  return np.sum(v*s)/np.sum(s)\n","(44, 512, 512)\n","(48, 512, 512)\n","(39, 512, 512)\n","(36, 512, 512)\n","(36, 512, 512)\n","(61, 512, 512)\n","(48, 512, 512)\n","(177, 512, 512)\n","(49, 512, 512)\n","(50, 512, 512)\n","(81, 512, 512)\n","(36, 512, 512)\n","(58, 512, 512)\n","(36, 512, 512)\n","(49, 512, 512)\n","(32, 512, 512)\n","(61, 512, 512)\n","(50, 512, 512)\n","(52, 512, 512)\n","(32, 512, 512)\n","(58, 512, 512)\n","(81, 512, 512)\n","(81, 512, 512)\n","(82, 512, 512)\n","(50, 512, 512)\n","(40, 512, 512)\n","(52, 512, 512)\n","(45, 512, 512)\n","(45, 512, 512)\n","(177, 512, 512)\n","(40, 512, 512)\n","(50, 512, 512)\n","(81, 512, 512)\n","(47, 512, 512)\n","(51, 512, 512)\n","(51, 512, 512)\n","(82, 512, 512)\n","(47, 512, 512)\n","(37, 512, 512)\n","(131, 512, 512)\n","(51, 512, 512)\n","/content/drive/MyDrive/Liver Vessel/nnunet/nnUNet/nnunetv2/evaluation/evaluate_predictions.py:91: RuntimeWarning: invalid value encountered in scalar divide\n","  return np.sum(v*s)/np.sum(s)\n","(40, 512, 512)\n","(52, 512, 512)\n","(37, 512, 512)\n","(51, 512, 512)\n","(44, 512, 512)\n","(40, 512, 512)\n","(52, 512, 512)\n","(148, 512, 512)\n","(44, 512, 512)\n","(47, 512, 512)\n","(161, 512, 512)\n","(45, 512, 512)\n","(50, 512, 512)\n","(54, 512, 512)\n","(38, 512, 512)\n","(47, 512, 512)\n","(50, 512, 512)\n","(45, 512, 512)\n","(38, 512, 512)\n","(53, 512, 512)\n","(34, 512, 512)\n","(131, 512, 512)\n","(54, 512, 512)\n","/content/drive/MyDrive/Liver Vessel/nnunet/nnUNet/nnunetv2/evaluation/evaluate_predictions.py:91: RuntimeWarning: invalid value encountered in scalar divide\n","  return np.sum(v*s)/np.sum(s)\n","(34, 512, 512)\n","(96, 512, 512)\n","(87, 512, 512)\n","(110, 512, 512)\n","(53, 512, 512)\n","(148, 512, 512)\n","(138, 512, 512)\n","(161, 512, 512)\n","(35, 512, 512)\n","(35, 512, 512)\n","(214, 512, 512)\n","(96, 512, 512)\n","(87, 512, 512)\n","(42, 512, 512)\n","(138, 512, 512)\n","(110, 512, 512)\n","(95, 512, 512)\n","(42, 512, 512)\n","(50, 512, 512)\n","(257, 512, 512)\n","(95, 512, 512)\n","(50, 512, 512)\n","(214, 512, 512)\n","(257, 512, 512)\n","(266, 512, 512)\n","/content/drive/MyDrive/Liver Vessel/nnunet/nnUNet/nnunetv2/evaluation/evaluate_predictions.py:105: RuntimeWarning: invalid value encountered in scalar divide\n","  return 2*tprec*tsens/(tprec+tsens)\n","(266, 512, 512)\n","/content/drive/MyDrive/Liver Vessel/nnunet/nnUNet/nnunetv2/evaluation/evaluate_predictions.py:91: RuntimeWarning: invalid value encountered in scalar divide\n","  return np.sum(v*s)/np.sum(s)\n","Removing all but the largest foreground region did not improve results!\n","(36, 512, 512)\n","(52, 512, 512)\n","(43, 512, 512)\n","(34, 512, 512)\n","(41, 512, 512)\n","(33, 512, 512)\n","(40, 512, 512)\n","(45, 512, 512)\n","(43, 512, 512)\n","(36, 512, 512)\n","(40, 512, 512)\n","(45, 512, 512)\n","(33, 512, 512)\n","(34, 512, 512)\n","(52, 512, 512)\n","(41, 512, 512)\n","(39, 512, 512)\n","(45, 512, 512)\n","(39, 512, 512)\n","(50, 512, 512)\n","(42, 512, 512)\n","(49, 512, 512)\n","(39, 512, 512)\n","(40, 512, 512)\n","(41, 512, 512)\n","(45, 512, 512)\n","(39, 512, 512)\n","(50, 512, 512)\n","(40, 512, 512)\n","(42, 512, 512)\n","(49, 512, 512)\n","(39, 512, 512)\n","(45, 512, 512)\n","(41, 512, 512)\n","(44, 512, 512)\n","(48, 512, 512)\n","(48, 512, 512)\n","(39, 512, 512)\n","(36, 512, 512)\n","(44, 512, 512)\n","(45, 512, 512)\n","(61, 512, 512)\n","(36, 512, 512)\n","(49, 512, 512)\n","(48, 512, 512)\n","(177, 512, 512)\n","(48, 512, 512)\n","(81, 512, 512)\n","(49, 512, 512)\n","(61, 512, 512)\n","(36, 512, 512)\n","(81, 512, 512)\n","(50, 512, 512)\n","(58, 512, 512)\n","(32, 512, 512)\n","(82, 512, 512)\n","(36, 512, 512)\n","(58, 512, 512)\n","(81, 512, 512)\n","(32, 512, 512)\n","(50, 512, 512)\n","(52, 512, 512)\n","(50, 512, 512)\n","(40, 512, 512)\n","(81, 512, 512)\n","(45, 512, 512)\n","(40, 512, 512)\n","(52, 512, 512)\n","(51, 512, 512)\n","(82, 512, 512)\n","(50, 512, 512)\n","(45, 512, 512)\n","(47, 512, 512)\n","(177, 512, 512)\n","(40, 512, 512)\n","(131, 512, 512)\n","(37, 512, 512)\n","(51, 512, 512)\n","(47, 512, 512)\n","(51, 512, 512)\n","(52, 512, 512)\n","(40, 512, 512)\n","(37, 512, 512)\n","(44, 512, 512)\n","(51, 512, 512)\n","(45, 512, 512)\n","(52, 512, 512)\n","(148, 512, 512)\n","(44, 512, 512)\n","(47, 512, 512)\n","(161, 512, 512)\n","(45, 512, 512)\n","(50, 512, 512)\n","(47, 512, 512)\n","(38, 512, 512)\n","(50, 512, 512)\n","(131, 512, 512)\n","(34, 512, 512)\n","(53, 512, 512)\n","(54, 512, 512)\n","(34, 512, 512)\n","(38, 512, 512)\n","(53, 512, 512)\n","(87, 512, 512)\n","(54, 512, 512)\n","(138, 512, 512)\n","(96, 512, 512)\n","(110, 512, 512)\n","(161, 512, 512)\n","(214, 512, 512)\n","(35, 512, 512)\n","(148, 512, 512)\n","(87, 512, 512)\n","(96, 512, 512)\n","(35, 512, 512)\n","(50, 512, 512)\n","(95, 512, 512)\n","(42, 512, 512)\n","(138, 512, 512)\n","(50, 512, 512)\n","(110, 512, 512)\n","(42, 512, 512)\n","(95, 512, 512)\n","(257, 512, 512)\n","(214, 512, 512)\n","(266, 512, 512)\n","(257, 512, 512)\n","(266, 512, 512)\n","Removing all but the largest component for 1 did not improve results! Dice before: 0.75625 after: 0.75522\n","(36, 512, 512)\n","(43, 512, 512)\n","(41, 512, 512)\n","(52, 512, 512)\n","(33, 512, 512)\n","(34, 512, 512)\n","(40, 512, 512)\n","(45, 512, 512)\n","(43, 512, 512)\n","(33, 512, 512)\n","(52, 512, 512)\n","(40, 512, 512)\n","(34, 512, 512)\n","(36, 512, 512)\n","(41, 512, 512)\n","(39, 512, 512)\n","(49, 512, 512)\n","(45, 512, 512)\n","(39, 512, 512)\n","(40, 512, 512)\n","(42, 512, 512)\n","(45, 512, 512)\n","(39, 512, 512)\n","(50, 512, 512)\n","(41, 512, 512)\n","(39, 512, 512)\n","(49, 512, 512)\n","(45, 512, 512)\n","(40, 512, 512)\n","(45, 512, 512)\n","(42, 512, 512)\n","(39, 512, 512)\n","(50, 512, 512)\n","(41, 512, 512)\n","(45, 512, 512)\n","(39, 512, 512)\n","(44, 512, 512)\n","(48, 512, 512)\n","(48, 512, 512)\n","(36, 512, 512)\n","(61, 512, 512)\n","(49, 512, 512)\n","(48, 512, 512)\n","(48, 512, 512)\n","(36, 512, 512)\n","(36, 512, 512)\n","(177, 512, 512)\n","(44, 512, 512)\n","(49, 512, 512)\n","(61, 512, 512)\n","(58, 512, 512)\n","(50, 512, 512)\n","(36, 512, 512)\n","(32, 512, 512)\n","(81, 512, 512)\n","(81, 512, 512)\n","(58, 512, 512)\n","(50, 512, 512)\n","(52, 512, 512)\n","(32, 512, 512)\n","(82, 512, 512)\n","(40, 512, 512)\n","(81, 512, 512)\n","(50, 512, 512)\n","(52, 512, 512)\n","(45, 512, 512)\n","(40, 512, 512)\n","(47, 512, 512)\n","(50, 512, 512)\n","(81, 512, 512)\n","(45, 512, 512)\n","(51, 512, 512)\n","(177, 512, 512)\n","(47, 512, 512)\n","(51, 512, 512)\n","(37, 512, 512)\n","(131, 512, 512)\n","(51, 512, 512)\n","(82, 512, 512)\n","(40, 512, 512)\n","(37, 512, 512)\n","(52, 512, 512)\n","(51, 512, 512)\n","(44, 512, 512)\n","(40, 512, 512)\n","(47, 512, 512)\n","(148, 512, 512)\n","(52, 512, 512)\n","(44, 512, 512)\n","(161, 512, 512)\n","(45, 512, 512)\n","(54, 512, 512)\n","(47, 512, 512)\n","(50, 512, 512)\n","(45, 512, 512)\n","(38, 512, 512)\n","(50, 512, 512)\n","(34, 512, 512)\n","(131, 512, 512)\n","(54, 512, 512)\n","(38, 512, 512)\n","(53, 512, 512)\n","(34, 512, 512)\n","(87, 512, 512)\n","(96, 512, 512)\n","(148, 512, 512)\n","(110, 512, 512)\n","(53, 512, 512)\n","(35, 512, 512)\n","(161, 512, 512)\n","(138, 512, 512)\n","(35, 512, 512)\n","(87, 512, 512)\n","(214, 512, 512)\n","(96, 512, 512)\n","(42, 512, 512)\n","(110, 512, 512)\n","(138, 512, 512)\n","(42, 512, 512)\n","(95, 512, 512)\n","(50, 512, 512)\n","(50, 512, 512)\n","(257, 512, 512)\n","(95, 512, 512)\n","(214, 512, 512)\n","(257, 512, 512)\n","(266, 512, 512)\n","(266, 512, 512)\n","Results were improved by removing all but the largest component for 2. Dice before: 0.7335 after: 0.73521\n","\n","***Run inference like this:***\n","\n","nnUNetv2_predict -d Dataset002_hepaticvessel -i INPUT_FOLDER -o OUTPUT_FOLDER -f  0 -tr nnUNetTrainerCEclCEloss -c 3d_fullres -p nnUNetPlans\n","\n","***Once inference is completed, run postprocessing like this:***\n","\n","nnUNetv2_apply_postprocessing -i OUTPUT_FOLDER -o OUTPUT_FOLDER_PP -pp_pkl_file data/nnUNet_results/Dataset002_hepaticvessel/nnUNetTrainerCEclCEloss__nnUNetPlans__3d_fullres/crossval_results_folds_0/postprocessing.pkl -np 8 -plans_json data/nnUNet_results/Dataset002_hepaticvessel/nnUNetTrainerCEclCEloss__nnUNetPlans__3d_fullres/crossval_results_folds_0/plans.json\n"]}]},{"cell_type":"code","source":["!nnUNetv2_predict -d Dataset002_hepaticvessel -i data/VEELATestCT -o data/VEELATestPred_1.1.1 -f  0 -tr nnUNetTrainerCEclCEloss -c 3d_fullres -p nnUNetPlans"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xTEtlnMPWtu2","executionInfo":{"status":"ok","timestamp":1746683242045,"user_tz":-180,"elapsed":903310,"user":{"displayName":"Mustafa Said KARTAL","userId":"14049951240735760192"}},"outputId":"f5b00bf2-ce1a-4b52-86dc-a62ee96a8835"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","#######################################################################\n","Please cite the following paper when using nnU-Net:\n","Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n","#######################################################################\n","\n","2025-05-08 05:32:27.444417: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2025-05-08 05:32:27.470986: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1746682347.494948  627784 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1746682347.502201  627784 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-05-08 05:32:27.530733: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","There are 20 cases in the source folder\n","I am process 0 out of 1 (max process ID is 0, we start counting with 0!)\n","There are 20 cases that I would like to predict\n","\n","Predicting hepaticvessel_00003:\n","perform_everything_on_device: True\n","100% 48/48 [00:27<00:00,  1.74it/s]\n","sending off prediction to background worker for resampling and export\n","done with hepaticvessel_00003\n","\n","Predicting hepaticvessel_00004:\n","perform_everything_on_device: True\n","100% 27/27 [00:14<00:00,  1.87it/s]\n","sending off prediction to background worker for resampling and export\n","done with hepaticvessel_00004\n","\n","Predicting hepaticvessel_00007:\n","perform_everything_on_device: True\n","100% 75/75 [00:40<00:00,  1.83it/s]\n","sending off prediction to background worker for resampling and export\n","done with hepaticvessel_00007\n","\n","Predicting hepaticvessel_00009:\n","perform_everything_on_device: True\n","100% 48/48 [00:26<00:00,  1.82it/s]\n","sending off prediction to background worker for resampling and export\n","done with hepaticvessel_00009\n","\n","Predicting hepaticvessel_00011:\n","perform_everything_on_device: True\n","100% 48/48 [00:26<00:00,  1.81it/s]\n","sending off prediction to background worker for resampling and export\n","done with hepaticvessel_00011\n","\n","Predicting hepaticvessel_00012:\n","perform_everything_on_device: True\n","100% 48/48 [00:26<00:00,  1.81it/s]\n","sending off prediction to background worker for resampling and export\n","done with hepaticvessel_00012\n","\n","Predicting hepaticvessel_00013:\n","perform_everything_on_device: True\n","100% 32/32 [00:17<00:00,  1.81it/s]\n","sending off prediction to background worker for resampling and export\n","done with hepaticvessel_00013\n","\n","Predicting hepaticvessel_00015:\n","perform_everything_on_device: True\n","100% 48/48 [00:26<00:00,  1.79it/s]\n","sending off prediction to background worker for resampling and export\n","done with hepaticvessel_00015\n","\n","Predicting hepaticvessel_00017:\n","perform_everything_on_device: True\n","100% 75/75 [00:42<00:00,  1.78it/s]\n","sending off prediction to background worker for resampling and export\n","done with hepaticvessel_00017\n","\n","Predicting hepaticvessel_00020:\n","perform_everything_on_device: True\n","100% 48/48 [00:26<00:00,  1.78it/s]\n","sending off prediction to background worker for resampling and export\n","done with hepaticvessel_00020\n","\n","Predicting hepaticvessel_00031:\n","perform_everything_on_device: True\n","100% 80/80 [00:45<00:00,  1.77it/s]\n","sending off prediction to background worker for resampling and export\n","done with hepaticvessel_00031\n","\n","Predicting hepaticvessel_00032:\n","perform_everything_on_device: True\n","100% 64/64 [00:36<00:00,  1.77it/s]\n","sending off prediction to background worker for resampling and export\n","done with hepaticvessel_00032\n","\n","Predicting hepaticvessel_00033:\n","perform_everything_on_device: True\n","100% 80/80 [00:45<00:00,  1.76it/s]\n","sending off prediction to background worker for resampling and export\n","done with hepaticvessel_00033\n","\n","Predicting hepaticvessel_00034:\n","perform_everything_on_device: True\n","100% 64/64 [00:36<00:00,  1.76it/s]\n","sending off prediction to background worker for resampling and export\n","done with hepaticvessel_00034\n","\n","Predicting hepaticvessel_00035:\n","perform_everything_on_device: True\n","100% 80/80 [00:45<00:00,  1.77it/s]\n","sending off prediction to background worker for resampling and export\n","done with hepaticvessel_00035\n","\n","Predicting hepaticvessel_00036:\n","perform_everything_on_device: True\n","100% 80/80 [00:45<00:00,  1.75it/s]\n","sending off prediction to background worker for resampling and export\n","done with hepaticvessel_00036\n","\n","Predicting hepaticvessel_00037:\n","perform_everything_on_device: True\n","100% 80/80 [00:45<00:00,  1.74it/s]\n","sending off prediction to background worker for resampling and export\n","done with hepaticvessel_00037\n","\n","Predicting hepaticvessel_00038:\n","perform_everything_on_device: True\n","100% 150/150 [01:26<00:00,  1.74it/s]\n","sending off prediction to background worker for resampling and export\n","done with hepaticvessel_00038\n","\n","Predicting hepaticvessel_00039:\n","perform_everything_on_device: True\n","100% 225/225 [02:08<00:00,  1.76it/s]\n","sending off prediction to background worker for resampling and export\n","done with hepaticvessel_00039\n","\n","Predicting hepaticvessel_00040:\n","perform_everything_on_device: True\n","100% 80/80 [00:45<00:00,  1.76it/s]\n","sending off prediction to background worker for resampling and export\n","done with hepaticvessel_00040\n"]}]},{"cell_type":"code","source":["!nnUNetv2_apply_postprocessing -i data/VEELATestPred_1.1.1 -o data/VEELATestPredPP!_1.1.1 -pp_pkl_file data/nnUNet_results/Dataset002_hepaticvessel/nnUNetTrainerCEclCEloss__nnUNetPlans__3d_fullres/crossval_results_folds_0/postprocessing.pkl -np 8 -plans_json data/nnUNet_results/Dataset002_hepaticvessel/nnUNetTrainerCEclCEloss__nnUNetPlans__3d_fullres/crossval_results_folds_0/plans.json"],"metadata":{"id":"dObY1BUaQuTH","executionInfo":{"status":"ok","timestamp":1746685183204,"user_tz":-180,"elapsed":14847,"user":{"displayName":"Mustafa Said KARTAL","userId":"14049951240735760192"}}},"execution_count":29,"outputs":[]}]}